I0630 16:50:46.400898 28406 caffe.cpp:204] Using GPUs 0
I0630 16:50:46.426023 28406 caffe.cpp:209] GPU 0: GeForce GTX 1070
I0630 16:50:46.671497 28406 solver.cpp:45] Initializing solver from parameters: 
test_iter: 100
test_interval: 100
base_lr: 0.0001
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
snapshot: 1000
snapshot_prefix: "models/mobilenet_finetune"
solver_mode: GPU
device_id: 0
net: "mobilenet_train.prototxt"
train_state {
  level: 0
  stage: ""
}
momentum2: 0.999
type: "Adam"
weights: "./mobilenet.caffemodel"
I0630 16:50:46.674731 28406 solver.cpp:102] Creating training net from net file: mobilenet_train.prototxt
I0630 16:50:46.675428 28406 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: mobilenet_train.prototxt
I0630 16:50:46.675441 28406 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0630 16:50:46.675588 28406 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0630 16:50:46.676214 28406 net.cpp:53] Initializing net from parameters: 
name: "mouth"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "clc-label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 96
    mean_value: 104.008
    mean_value: 116.669
    mean_value: 122.675
    min_side_min: 96
    min_side_max: 128
  }
  image_data_param {
    source: "all_shuffle_train.txt"
    batch_size: 64
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "Convolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "Convolution"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "Convolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "Convolution"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "Convolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "Convolution"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "Convolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "Convolution"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "Convolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "Convolution"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "Convolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "Convolution"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "Convolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "Convolution"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "Convolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "Convolution"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "Convolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "Convolution"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "Convolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "Convolution"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "Convolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv5_5/sep"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc7-mouth"
  type: "Convolution"
  bottom: "pool6"
  top: "fc7-mouth"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc7-mouth"
  bottom: "clc-label"
  top: "loss"
}
layer {
  name: "acc"
  type: "Accuracy"
  bottom: "fc7-mouth"
  bottom: "clc-label"
  top: "acc"
  include {
    phase: TRAIN
  }
  include {
    phase: TEST
  }
}
I0630 16:50:46.676723 28406 layer_factory.hpp:77] Creating layer data
I0630 16:50:46.676762 28406 net.cpp:86] Creating Layer data
I0630 16:50:46.676780 28406 net.cpp:382] data -> data
I0630 16:50:46.676812 28406 net.cpp:382] data -> clc-label
I0630 16:50:46.676899 28406 image_data_layer.cpp:38] Opening file all_shuffle_train.txt
I0630 16:50:46.681514 28406 image_data_layer.cpp:53] Shuffling data
I0630 16:50:46.683982 28406 image_data_layer.cpp:63] A total of 13596 images.
I0630 16:50:46.687383 28406 image_data_layer.cpp:90] output data size: 64,3,96,96
I0630 16:50:46.705593 28406 net.cpp:124] Setting up data
I0630 16:50:46.705639 28406 net.cpp:131] Top shape: 64 3 96 96 (1769472)
I0630 16:50:46.705646 28406 net.cpp:131] Top shape: 64 (64)
I0630 16:50:46.705651 28406 net.cpp:139] Memory required for data: 7078144
I0630 16:50:46.705659 28406 layer_factory.hpp:77] Creating layer clc-label_data_1_split
I0630 16:50:46.705682 28406 net.cpp:86] Creating Layer clc-label_data_1_split
I0630 16:50:46.705688 28406 net.cpp:408] clc-label_data_1_split <- clc-label
I0630 16:50:46.705703 28406 net.cpp:382] clc-label_data_1_split -> clc-label_data_1_split_0
I0630 16:50:46.705730 28406 net.cpp:382] clc-label_data_1_split -> clc-label_data_1_split_1
I0630 16:50:46.705917 28406 net.cpp:124] Setting up clc-label_data_1_split
I0630 16:50:46.705953 28406 net.cpp:131] Top shape: 64 (64)
I0630 16:50:46.705960 28406 net.cpp:131] Top shape: 64 (64)
I0630 16:50:46.705965 28406 net.cpp:139] Memory required for data: 7078656
I0630 16:50:46.705968 28406 layer_factory.hpp:77] Creating layer conv1
I0630 16:50:46.705991 28406 net.cpp:86] Creating Layer conv1
I0630 16:50:46.706001 28406 net.cpp:408] conv1 <- data
I0630 16:50:46.706010 28406 net.cpp:382] conv1 -> conv1
I0630 16:50:47.318622 28406 net.cpp:124] Setting up conv1
I0630 16:50:47.318662 28406 net.cpp:131] Top shape: 64 32 48 48 (4718592)
I0630 16:50:47.318667 28406 net.cpp:139] Memory required for data: 25953024
I0630 16:50:47.318688 28406 layer_factory.hpp:77] Creating layer conv1/bn
I0630 16:50:47.318713 28406 net.cpp:86] Creating Layer conv1/bn
I0630 16:50:47.318722 28406 net.cpp:408] conv1/bn <- conv1
I0630 16:50:47.318743 28406 net.cpp:369] conv1/bn -> conv1 (in-place)
I0630 16:50:47.319806 28406 net.cpp:124] Setting up conv1/bn
I0630 16:50:47.319819 28406 net.cpp:131] Top shape: 64 32 48 48 (4718592)
I0630 16:50:47.319823 28406 net.cpp:139] Memory required for data: 44827392
I0630 16:50:47.319835 28406 layer_factory.hpp:77] Creating layer conv1/scale
I0630 16:50:47.319846 28406 net.cpp:86] Creating Layer conv1/scale
I0630 16:50:47.319851 28406 net.cpp:408] conv1/scale <- conv1
I0630 16:50:47.319860 28406 net.cpp:369] conv1/scale -> conv1 (in-place)
I0630 16:50:47.319927 28406 layer_factory.hpp:77] Creating layer conv1/scale
I0630 16:50:47.320077 28406 net.cpp:124] Setting up conv1/scale
I0630 16:50:47.320086 28406 net.cpp:131] Top shape: 64 32 48 48 (4718592)
I0630 16:50:47.320091 28406 net.cpp:139] Memory required for data: 63701760
I0630 16:50:47.320099 28406 layer_factory.hpp:77] Creating layer relu1
I0630 16:50:47.320124 28406 net.cpp:86] Creating Layer relu1
I0630 16:50:47.320132 28406 net.cpp:408] relu1 <- conv1
I0630 16:50:47.320147 28406 net.cpp:369] relu1 -> conv1 (in-place)
I0630 16:50:47.320578 28406 net.cpp:124] Setting up relu1
I0630 16:50:47.320590 28406 net.cpp:131] Top shape: 64 32 48 48 (4718592)
I0630 16:50:47.320593 28406 net.cpp:139] Memory required for data: 82576128
I0630 16:50:47.320597 28406 layer_factory.hpp:77] Creating layer conv2_1/dw
I0630 16:50:47.320608 28406 net.cpp:86] Creating Layer conv2_1/dw
I0630 16:50:47.320613 28406 net.cpp:408] conv2_1/dw <- conv1
I0630 16:50:47.320621 28406 net.cpp:382] conv2_1/dw -> conv2_1/dw
I0630 16:50:47.320812 28406 net.cpp:124] Setting up conv2_1/dw
I0630 16:50:47.320822 28406 net.cpp:131] Top shape: 64 32 48 48 (4718592)
I0630 16:50:47.320827 28406 net.cpp:139] Memory required for data: 101450496
I0630 16:50:47.320832 28406 layer_factory.hpp:77] Creating layer conv2_1/dw/bn
I0630 16:50:47.320838 28406 net.cpp:86] Creating Layer conv2_1/dw/bn
I0630 16:50:47.320843 28406 net.cpp:408] conv2_1/dw/bn <- conv2_1/dw
I0630 16:50:47.320848 28406 net.cpp:369] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0630 16:50:47.321024 28406 net.cpp:124] Setting up conv2_1/dw/bn
I0630 16:50:47.321034 28406 net.cpp:131] Top shape: 64 32 48 48 (4718592)
I0630 16:50:47.321038 28406 net.cpp:139] Memory required for data: 120324864
I0630 16:50:47.321048 28406 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0630 16:50:47.321056 28406 net.cpp:86] Creating Layer conv2_1/dw/scale
I0630 16:50:47.321060 28406 net.cpp:408] conv2_1/dw/scale <- conv2_1/dw
I0630 16:50:47.321066 28406 net.cpp:369] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0630 16:50:47.321125 28406 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0630 16:50:47.321282 28406 net.cpp:124] Setting up conv2_1/dw/scale
I0630 16:50:47.321292 28406 net.cpp:131] Top shape: 64 32 48 48 (4718592)
I0630 16:50:47.321297 28406 net.cpp:139] Memory required for data: 139199232
I0630 16:50:47.321305 28406 layer_factory.hpp:77] Creating layer relu2_1/dw
I0630 16:50:47.321310 28406 net.cpp:86] Creating Layer relu2_1/dw
I0630 16:50:47.321314 28406 net.cpp:408] relu2_1/dw <- conv2_1/dw
I0630 16:50:47.321321 28406 net.cpp:369] relu2_1/dw -> conv2_1/dw (in-place)
I0630 16:50:47.322044 28406 net.cpp:124] Setting up relu2_1/dw
I0630 16:50:47.322057 28406 net.cpp:131] Top shape: 64 32 48 48 (4718592)
I0630 16:50:47.322062 28406 net.cpp:139] Memory required for data: 158073600
I0630 16:50:47.322067 28406 layer_factory.hpp:77] Creating layer conv2_1/sep
I0630 16:50:47.322075 28406 net.cpp:86] Creating Layer conv2_1/sep
I0630 16:50:47.322080 28406 net.cpp:408] conv2_1/sep <- conv2_1/dw
I0630 16:50:47.322088 28406 net.cpp:382] conv2_1/sep -> conv2_1/sep
I0630 16:50:47.323823 28406 net.cpp:124] Setting up conv2_1/sep
I0630 16:50:47.323837 28406 net.cpp:131] Top shape: 64 64 48 48 (9437184)
I0630 16:50:47.323841 28406 net.cpp:139] Memory required for data: 195822336
I0630 16:50:47.323848 28406 layer_factory.hpp:77] Creating layer conv2_1/sep/bn
I0630 16:50:47.323855 28406 net.cpp:86] Creating Layer conv2_1/sep/bn
I0630 16:50:47.323860 28406 net.cpp:408] conv2_1/sep/bn <- conv2_1/sep
I0630 16:50:47.323866 28406 net.cpp:369] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0630 16:50:47.324023 28406 net.cpp:124] Setting up conv2_1/sep/bn
I0630 16:50:47.324033 28406 net.cpp:131] Top shape: 64 64 48 48 (9437184)
I0630 16:50:47.324036 28406 net.cpp:139] Memory required for data: 233571072
I0630 16:50:47.324044 28406 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0630 16:50:47.324052 28406 net.cpp:86] Creating Layer conv2_1/sep/scale
I0630 16:50:47.324056 28406 net.cpp:408] conv2_1/sep/scale <- conv2_1/sep
I0630 16:50:47.324062 28406 net.cpp:369] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0630 16:50:47.324097 28406 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0630 16:50:47.324209 28406 net.cpp:124] Setting up conv2_1/sep/scale
I0630 16:50:47.324219 28406 net.cpp:131] Top shape: 64 64 48 48 (9437184)
I0630 16:50:47.324223 28406 net.cpp:139] Memory required for data: 271319808
I0630 16:50:47.324244 28406 layer_factory.hpp:77] Creating layer relu2_1/sep
I0630 16:50:47.324250 28406 net.cpp:86] Creating Layer relu2_1/sep
I0630 16:50:47.324255 28406 net.cpp:408] relu2_1/sep <- conv2_1/sep
I0630 16:50:47.324260 28406 net.cpp:369] relu2_1/sep -> conv2_1/sep (in-place)
I0630 16:50:47.325002 28406 net.cpp:124] Setting up relu2_1/sep
I0630 16:50:47.325016 28406 net.cpp:131] Top shape: 64 64 48 48 (9437184)
I0630 16:50:47.325019 28406 net.cpp:139] Memory required for data: 309068544
I0630 16:50:47.325024 28406 layer_factory.hpp:77] Creating layer conv2_2/dw
I0630 16:50:47.325033 28406 net.cpp:86] Creating Layer conv2_2/dw
I0630 16:50:47.325037 28406 net.cpp:408] conv2_2/dw <- conv2_1/sep
I0630 16:50:47.325045 28406 net.cpp:382] conv2_2/dw -> conv2_2/dw
I0630 16:50:47.325220 28406 net.cpp:124] Setting up conv2_2/dw
I0630 16:50:47.325232 28406 net.cpp:131] Top shape: 64 64 24 24 (2359296)
I0630 16:50:47.325237 28406 net.cpp:139] Memory required for data: 318505728
I0630 16:50:47.325242 28406 layer_factory.hpp:77] Creating layer conv2_2/dw/bn
I0630 16:50:47.325248 28406 net.cpp:86] Creating Layer conv2_2/dw/bn
I0630 16:50:47.325253 28406 net.cpp:408] conv2_2/dw/bn <- conv2_2/dw
I0630 16:50:47.325259 28406 net.cpp:369] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0630 16:50:47.325417 28406 net.cpp:124] Setting up conv2_2/dw/bn
I0630 16:50:47.325428 28406 net.cpp:131] Top shape: 64 64 24 24 (2359296)
I0630 16:50:47.325431 28406 net.cpp:139] Memory required for data: 327942912
I0630 16:50:47.325439 28406 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0630 16:50:47.325448 28406 net.cpp:86] Creating Layer conv2_2/dw/scale
I0630 16:50:47.325453 28406 net.cpp:408] conv2_2/dw/scale <- conv2_2/dw
I0630 16:50:47.325459 28406 net.cpp:369] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0630 16:50:47.325493 28406 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0630 16:50:47.325610 28406 net.cpp:124] Setting up conv2_2/dw/scale
I0630 16:50:47.325619 28406 net.cpp:131] Top shape: 64 64 24 24 (2359296)
I0630 16:50:47.325624 28406 net.cpp:139] Memory required for data: 337380096
I0630 16:50:47.325630 28406 layer_factory.hpp:77] Creating layer relu2_2/dw
I0630 16:50:47.325636 28406 net.cpp:86] Creating Layer relu2_2/dw
I0630 16:50:47.325640 28406 net.cpp:408] relu2_2/dw <- conv2_2/dw
I0630 16:50:47.325646 28406 net.cpp:369] relu2_2/dw -> conv2_2/dw (in-place)
I0630 16:50:47.326050 28406 net.cpp:124] Setting up relu2_2/dw
I0630 16:50:47.326061 28406 net.cpp:131] Top shape: 64 64 24 24 (2359296)
I0630 16:50:47.326066 28406 net.cpp:139] Memory required for data: 346817280
I0630 16:50:47.326078 28406 layer_factory.hpp:77] Creating layer conv2_2/sep
I0630 16:50:47.326090 28406 net.cpp:86] Creating Layer conv2_2/sep
I0630 16:50:47.326097 28406 net.cpp:408] conv2_2/sep <- conv2_2/dw
I0630 16:50:47.326104 28406 net.cpp:382] conv2_2/sep -> conv2_2/sep
I0630 16:50:47.329056 28406 net.cpp:124] Setting up conv2_2/sep
I0630 16:50:47.329073 28406 net.cpp:131] Top shape: 64 128 24 24 (4718592)
I0630 16:50:47.329078 28406 net.cpp:139] Memory required for data: 365691648
I0630 16:50:47.329085 28406 layer_factory.hpp:77] Creating layer conv2_2/sep/bn
I0630 16:50:47.329094 28406 net.cpp:86] Creating Layer conv2_2/sep/bn
I0630 16:50:47.329099 28406 net.cpp:408] conv2_2/sep/bn <- conv2_2/sep
I0630 16:50:47.329107 28406 net.cpp:369] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0630 16:50:47.329290 28406 net.cpp:124] Setting up conv2_2/sep/bn
I0630 16:50:47.329300 28406 net.cpp:131] Top shape: 64 128 24 24 (4718592)
I0630 16:50:47.329305 28406 net.cpp:139] Memory required for data: 384566016
I0630 16:50:47.329313 28406 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0630 16:50:47.329320 28406 net.cpp:86] Creating Layer conv2_2/sep/scale
I0630 16:50:47.329325 28406 net.cpp:408] conv2_2/sep/scale <- conv2_2/sep
I0630 16:50:47.329332 28406 net.cpp:369] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0630 16:50:47.329389 28406 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0630 16:50:47.329530 28406 net.cpp:124] Setting up conv2_2/sep/scale
I0630 16:50:47.329540 28406 net.cpp:131] Top shape: 64 128 24 24 (4718592)
I0630 16:50:47.329545 28406 net.cpp:139] Memory required for data: 403440384
I0630 16:50:47.329551 28406 layer_factory.hpp:77] Creating layer relu2_2/sep
I0630 16:50:47.329558 28406 net.cpp:86] Creating Layer relu2_2/sep
I0630 16:50:47.329565 28406 net.cpp:408] relu2_2/sep <- conv2_2/sep
I0630 16:50:47.329571 28406 net.cpp:369] relu2_2/sep -> conv2_2/sep (in-place)
I0630 16:50:47.330381 28406 net.cpp:124] Setting up relu2_2/sep
I0630 16:50:47.330394 28406 net.cpp:131] Top shape: 64 128 24 24 (4718592)
I0630 16:50:47.330399 28406 net.cpp:139] Memory required for data: 422314752
I0630 16:50:47.330404 28406 layer_factory.hpp:77] Creating layer conv3_1/dw
I0630 16:50:47.330415 28406 net.cpp:86] Creating Layer conv3_1/dw
I0630 16:50:47.330420 28406 net.cpp:408] conv3_1/dw <- conv2_2/sep
I0630 16:50:47.330427 28406 net.cpp:382] conv3_1/dw -> conv3_1/dw
I0630 16:50:47.330618 28406 net.cpp:124] Setting up conv3_1/dw
I0630 16:50:47.330628 28406 net.cpp:131] Top shape: 64 128 24 24 (4718592)
I0630 16:50:47.330632 28406 net.cpp:139] Memory required for data: 441189120
I0630 16:50:47.330638 28406 layer_factory.hpp:77] Creating layer conv3_1/dw/bn
I0630 16:50:47.330644 28406 net.cpp:86] Creating Layer conv3_1/dw/bn
I0630 16:50:47.330648 28406 net.cpp:408] conv3_1/dw/bn <- conv3_1/dw
I0630 16:50:47.330658 28406 net.cpp:369] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0630 16:50:47.330842 28406 net.cpp:124] Setting up conv3_1/dw/bn
I0630 16:50:47.330858 28406 net.cpp:131] Top shape: 64 128 24 24 (4718592)
I0630 16:50:47.330862 28406 net.cpp:139] Memory required for data: 460063488
I0630 16:50:47.330880 28406 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0630 16:50:47.330907 28406 net.cpp:86] Creating Layer conv3_1/dw/scale
I0630 16:50:47.330914 28406 net.cpp:408] conv3_1/dw/scale <- conv3_1/dw
I0630 16:50:47.330930 28406 net.cpp:369] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0630 16:50:47.331001 28406 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0630 16:50:47.331126 28406 net.cpp:124] Setting up conv3_1/dw/scale
I0630 16:50:47.331143 28406 net.cpp:131] Top shape: 64 128 24 24 (4718592)
I0630 16:50:47.331148 28406 net.cpp:139] Memory required for data: 478937856
I0630 16:50:47.331159 28406 layer_factory.hpp:77] Creating layer relu3_1/dw
I0630 16:50:47.331177 28406 net.cpp:86] Creating Layer relu3_1/dw
I0630 16:50:47.331190 28406 net.cpp:408] relu3_1/dw <- conv3_1/dw
I0630 16:50:47.331199 28406 net.cpp:369] relu3_1/dw -> conv3_1/dw (in-place)
I0630 16:50:47.331676 28406 net.cpp:124] Setting up relu3_1/dw
I0630 16:50:47.331691 28406 net.cpp:131] Top shape: 64 128 24 24 (4718592)
I0630 16:50:47.331698 28406 net.cpp:139] Memory required for data: 497812224
I0630 16:50:47.331703 28406 layer_factory.hpp:77] Creating layer conv3_1/sep
I0630 16:50:47.331717 28406 net.cpp:86] Creating Layer conv3_1/sep
I0630 16:50:47.331724 28406 net.cpp:408] conv3_1/sep <- conv3_1/dw
I0630 16:50:47.331734 28406 net.cpp:382] conv3_1/sep -> conv3_1/sep
I0630 16:50:47.334167 28406 net.cpp:124] Setting up conv3_1/sep
I0630 16:50:47.334184 28406 net.cpp:131] Top shape: 64 128 24 24 (4718592)
I0630 16:50:47.334189 28406 net.cpp:139] Memory required for data: 516686592
I0630 16:50:47.334197 28406 layer_factory.hpp:77] Creating layer conv3_1/sep/bn
I0630 16:50:47.334206 28406 net.cpp:86] Creating Layer conv3_1/sep/bn
I0630 16:50:47.334214 28406 net.cpp:408] conv3_1/sep/bn <- conv3_1/sep
I0630 16:50:47.334236 28406 net.cpp:369] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0630 16:50:47.334430 28406 net.cpp:124] Setting up conv3_1/sep/bn
I0630 16:50:47.334439 28406 net.cpp:131] Top shape: 64 128 24 24 (4718592)
I0630 16:50:47.334444 28406 net.cpp:139] Memory required for data: 535560960
I0630 16:50:47.334452 28406 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0630 16:50:47.334460 28406 net.cpp:86] Creating Layer conv3_1/sep/scale
I0630 16:50:47.334467 28406 net.cpp:408] conv3_1/sep/scale <- conv3_1/sep
I0630 16:50:47.334516 28406 net.cpp:369] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0630 16:50:47.334573 28406 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0630 16:50:47.334725 28406 net.cpp:124] Setting up conv3_1/sep/scale
I0630 16:50:47.334735 28406 net.cpp:131] Top shape: 64 128 24 24 (4718592)
I0630 16:50:47.334751 28406 net.cpp:139] Memory required for data: 554435328
I0630 16:50:47.334764 28406 layer_factory.hpp:77] Creating layer relu3_1/sep
I0630 16:50:47.334774 28406 net.cpp:86] Creating Layer relu3_1/sep
I0630 16:50:47.334782 28406 net.cpp:408] relu3_1/sep <- conv3_1/sep
I0630 16:50:47.334797 28406 net.cpp:369] relu3_1/sep -> conv3_1/sep (in-place)
I0630 16:50:47.335721 28406 net.cpp:124] Setting up relu3_1/sep
I0630 16:50:47.335737 28406 net.cpp:131] Top shape: 64 128 24 24 (4718592)
I0630 16:50:47.335747 28406 net.cpp:139] Memory required for data: 573309696
I0630 16:50:47.335755 28406 layer_factory.hpp:77] Creating layer conv3_2/dw
I0630 16:50:47.335772 28406 net.cpp:86] Creating Layer conv3_2/dw
I0630 16:50:47.335778 28406 net.cpp:408] conv3_2/dw <- conv3_1/sep
I0630 16:50:47.335791 28406 net.cpp:382] conv3_2/dw -> conv3_2/dw
I0630 16:50:47.335999 28406 net.cpp:124] Setting up conv3_2/dw
I0630 16:50:47.336009 28406 net.cpp:131] Top shape: 64 128 12 12 (1179648)
I0630 16:50:47.336015 28406 net.cpp:139] Memory required for data: 578028288
I0630 16:50:47.336027 28406 layer_factory.hpp:77] Creating layer conv3_2/dw/bn
I0630 16:50:47.336041 28406 net.cpp:86] Creating Layer conv3_2/dw/bn
I0630 16:50:47.336052 28406 net.cpp:408] conv3_2/dw/bn <- conv3_2/dw
I0630 16:50:47.336064 28406 net.cpp:369] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0630 16:50:47.336259 28406 net.cpp:124] Setting up conv3_2/dw/bn
I0630 16:50:47.336271 28406 net.cpp:131] Top shape: 64 128 12 12 (1179648)
I0630 16:50:47.336278 28406 net.cpp:139] Memory required for data: 582746880
I0630 16:50:47.336294 28406 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0630 16:50:47.336310 28406 net.cpp:86] Creating Layer conv3_2/dw/scale
I0630 16:50:47.336318 28406 net.cpp:408] conv3_2/dw/scale <- conv3_2/dw
I0630 16:50:47.336328 28406 net.cpp:369] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0630 16:50:47.336374 28406 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0630 16:50:47.336486 28406 net.cpp:124] Setting up conv3_2/dw/scale
I0630 16:50:47.336496 28406 net.cpp:131] Top shape: 64 128 12 12 (1179648)
I0630 16:50:47.336504 28406 net.cpp:139] Memory required for data: 587465472
I0630 16:50:47.336519 28406 layer_factory.hpp:77] Creating layer relu3_2/dw
I0630 16:50:47.336529 28406 net.cpp:86] Creating Layer relu3_2/dw
I0630 16:50:47.336536 28406 net.cpp:408] relu3_2/dw <- conv3_2/dw
I0630 16:50:47.336547 28406 net.cpp:369] relu3_2/dw -> conv3_2/dw (in-place)
I0630 16:50:47.337100 28406 net.cpp:124] Setting up relu3_2/dw
I0630 16:50:47.337116 28406 net.cpp:131] Top shape: 64 128 12 12 (1179648)
I0630 16:50:47.337123 28406 net.cpp:139] Memory required for data: 592184064
I0630 16:50:47.337133 28406 layer_factory.hpp:77] Creating layer conv3_2/sep
I0630 16:50:47.337149 28406 net.cpp:86] Creating Layer conv3_2/sep
I0630 16:50:47.337157 28406 net.cpp:408] conv3_2/sep <- conv3_2/dw
I0630 16:50:47.337168 28406 net.cpp:382] conv3_2/sep -> conv3_2/sep
I0630 16:50:47.340819 28406 net.cpp:124] Setting up conv3_2/sep
I0630 16:50:47.340837 28406 net.cpp:131] Top shape: 64 256 12 12 (2359296)
I0630 16:50:47.340844 28406 net.cpp:139] Memory required for data: 601621248
I0630 16:50:47.340855 28406 layer_factory.hpp:77] Creating layer conv3_2/sep/bn
I0630 16:50:47.340869 28406 net.cpp:86] Creating Layer conv3_2/sep/bn
I0630 16:50:47.340876 28406 net.cpp:408] conv3_2/sep/bn <- conv3_2/sep
I0630 16:50:47.340884 28406 net.cpp:369] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0630 16:50:47.341068 28406 net.cpp:124] Setting up conv3_2/sep/bn
I0630 16:50:47.341078 28406 net.cpp:131] Top shape: 64 256 12 12 (2359296)
I0630 16:50:47.341081 28406 net.cpp:139] Memory required for data: 611058432
I0630 16:50:47.341097 28406 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0630 16:50:47.341121 28406 net.cpp:86] Creating Layer conv3_2/sep/scale
I0630 16:50:47.341127 28406 net.cpp:408] conv3_2/sep/scale <- conv3_2/sep
I0630 16:50:47.341133 28406 net.cpp:369] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0630 16:50:47.341192 28406 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0630 16:50:47.341333 28406 net.cpp:124] Setting up conv3_2/sep/scale
I0630 16:50:47.341342 28406 net.cpp:131] Top shape: 64 256 12 12 (2359296)
I0630 16:50:47.341346 28406 net.cpp:139] Memory required for data: 620495616
I0630 16:50:47.341361 28406 layer_factory.hpp:77] Creating layer relu3_2/sep
I0630 16:50:47.341370 28406 net.cpp:86] Creating Layer relu3_2/sep
I0630 16:50:47.341377 28406 net.cpp:408] relu3_2/sep <- conv3_2/sep
I0630 16:50:47.341382 28406 net.cpp:369] relu3_2/sep -> conv3_2/sep (in-place)
I0630 16:50:47.342159 28406 net.cpp:124] Setting up relu3_2/sep
I0630 16:50:47.342173 28406 net.cpp:131] Top shape: 64 256 12 12 (2359296)
I0630 16:50:47.342186 28406 net.cpp:139] Memory required for data: 629932800
I0630 16:50:47.342191 28406 layer_factory.hpp:77] Creating layer conv4_1/dw
I0630 16:50:47.342200 28406 net.cpp:86] Creating Layer conv4_1/dw
I0630 16:50:47.342207 28406 net.cpp:408] conv4_1/dw <- conv3_2/sep
I0630 16:50:47.342216 28406 net.cpp:382] conv4_1/dw -> conv4_1/dw
I0630 16:50:47.342427 28406 net.cpp:124] Setting up conv4_1/dw
I0630 16:50:47.342437 28406 net.cpp:131] Top shape: 64 256 12 12 (2359296)
I0630 16:50:47.342442 28406 net.cpp:139] Memory required for data: 639369984
I0630 16:50:47.342447 28406 layer_factory.hpp:77] Creating layer conv4_1/dw/bn
I0630 16:50:47.342454 28406 net.cpp:86] Creating Layer conv4_1/dw/bn
I0630 16:50:47.342458 28406 net.cpp:408] conv4_1/dw/bn <- conv4_1/dw
I0630 16:50:47.342464 28406 net.cpp:369] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0630 16:50:47.342633 28406 net.cpp:124] Setting up conv4_1/dw/bn
I0630 16:50:47.342641 28406 net.cpp:131] Top shape: 64 256 12 12 (2359296)
I0630 16:50:47.342645 28406 net.cpp:139] Memory required for data: 648807168
I0630 16:50:47.342653 28406 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0630 16:50:47.342661 28406 net.cpp:86] Creating Layer conv4_1/dw/scale
I0630 16:50:47.342667 28406 net.cpp:408] conv4_1/dw/scale <- conv4_1/dw
I0630 16:50:47.342674 28406 net.cpp:369] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0630 16:50:47.342712 28406 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0630 16:50:47.342814 28406 net.cpp:124] Setting up conv4_1/dw/scale
I0630 16:50:47.342823 28406 net.cpp:131] Top shape: 64 256 12 12 (2359296)
I0630 16:50:47.342828 28406 net.cpp:139] Memory required for data: 658244352
I0630 16:50:47.342833 28406 layer_factory.hpp:77] Creating layer relu4_1/dw
I0630 16:50:47.342839 28406 net.cpp:86] Creating Layer relu4_1/dw
I0630 16:50:47.342844 28406 net.cpp:408] relu4_1/dw <- conv4_1/dw
I0630 16:50:47.342850 28406 net.cpp:369] relu4_1/dw -> conv4_1/dw (in-place)
I0630 16:50:47.343330 28406 net.cpp:124] Setting up relu4_1/dw
I0630 16:50:47.343343 28406 net.cpp:131] Top shape: 64 256 12 12 (2359296)
I0630 16:50:47.343346 28406 net.cpp:139] Memory required for data: 667681536
I0630 16:50:47.343350 28406 layer_factory.hpp:77] Creating layer conv4_1/sep
I0630 16:50:47.343360 28406 net.cpp:86] Creating Layer conv4_1/sep
I0630 16:50:47.343365 28406 net.cpp:408] conv4_1/sep <- conv4_1/dw
I0630 16:50:47.343374 28406 net.cpp:382] conv4_1/sep -> conv4_1/sep
I0630 16:50:47.346544 28406 net.cpp:124] Setting up conv4_1/sep
I0630 16:50:47.346571 28406 net.cpp:131] Top shape: 64 256 12 12 (2359296)
I0630 16:50:47.346580 28406 net.cpp:139] Memory required for data: 677118720
I0630 16:50:47.346586 28406 layer_factory.hpp:77] Creating layer conv4_1/sep/bn
I0630 16:50:47.346594 28406 net.cpp:86] Creating Layer conv4_1/sep/bn
I0630 16:50:47.346598 28406 net.cpp:408] conv4_1/sep/bn <- conv4_1/sep
I0630 16:50:47.346606 28406 net.cpp:369] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0630 16:50:47.346851 28406 net.cpp:124] Setting up conv4_1/sep/bn
I0630 16:50:47.346866 28406 net.cpp:131] Top shape: 64 256 12 12 (2359296)
I0630 16:50:47.346897 28406 net.cpp:139] Memory required for data: 686555904
I0630 16:50:47.346913 28406 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0630 16:50:47.346927 28406 net.cpp:86] Creating Layer conv4_1/sep/scale
I0630 16:50:47.346935 28406 net.cpp:408] conv4_1/sep/scale <- conv4_1/sep
I0630 16:50:47.346951 28406 net.cpp:369] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0630 16:50:47.347019 28406 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0630 16:50:47.347214 28406 net.cpp:124] Setting up conv4_1/sep/scale
I0630 16:50:47.347226 28406 net.cpp:131] Top shape: 64 256 12 12 (2359296)
I0630 16:50:47.347239 28406 net.cpp:139] Memory required for data: 695993088
I0630 16:50:47.347259 28406 layer_factory.hpp:77] Creating layer relu4_1/sep
I0630 16:50:47.347276 28406 net.cpp:86] Creating Layer relu4_1/sep
I0630 16:50:47.347290 28406 net.cpp:408] relu4_1/sep <- conv4_1/sep
I0630 16:50:47.347296 28406 net.cpp:369] relu4_1/sep -> conv4_1/sep (in-place)
I0630 16:50:47.348016 28406 net.cpp:124] Setting up relu4_1/sep
I0630 16:50:47.348032 28406 net.cpp:131] Top shape: 64 256 12 12 (2359296)
I0630 16:50:47.348039 28406 net.cpp:139] Memory required for data: 705430272
I0630 16:50:47.348048 28406 layer_factory.hpp:77] Creating layer conv4_2/dw
I0630 16:50:47.348064 28406 net.cpp:86] Creating Layer conv4_2/dw
I0630 16:50:47.348075 28406 net.cpp:408] conv4_2/dw <- conv4_1/sep
I0630 16:50:47.348088 28406 net.cpp:382] conv4_2/dw -> conv4_2/dw
I0630 16:50:47.348418 28406 net.cpp:124] Setting up conv4_2/dw
I0630 16:50:47.348433 28406 net.cpp:131] Top shape: 64 256 6 6 (589824)
I0630 16:50:47.348441 28406 net.cpp:139] Memory required for data: 707789568
I0630 16:50:47.348453 28406 layer_factory.hpp:77] Creating layer conv4_2/dw/bn
I0630 16:50:47.348464 28406 net.cpp:86] Creating Layer conv4_2/dw/bn
I0630 16:50:47.348474 28406 net.cpp:408] conv4_2/dw/bn <- conv4_2/dw
I0630 16:50:47.348489 28406 net.cpp:369] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0630 16:50:47.348723 28406 net.cpp:124] Setting up conv4_2/dw/bn
I0630 16:50:47.348733 28406 net.cpp:131] Top shape: 64 256 6 6 (589824)
I0630 16:50:47.348739 28406 net.cpp:139] Memory required for data: 710148864
I0630 16:50:47.348747 28406 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0630 16:50:47.348757 28406 net.cpp:86] Creating Layer conv4_2/dw/scale
I0630 16:50:47.348773 28406 net.cpp:408] conv4_2/dw/scale <- conv4_2/dw
I0630 16:50:47.348795 28406 net.cpp:369] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0630 16:50:47.348839 28406 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0630 16:50:47.348953 28406 net.cpp:124] Setting up conv4_2/dw/scale
I0630 16:50:47.348963 28406 net.cpp:131] Top shape: 64 256 6 6 (589824)
I0630 16:50:47.348971 28406 net.cpp:139] Memory required for data: 712508160
I0630 16:50:47.348984 28406 layer_factory.hpp:77] Creating layer relu4_2/dw
I0630 16:50:47.348994 28406 net.cpp:86] Creating Layer relu4_2/dw
I0630 16:50:47.349001 28406 net.cpp:408] relu4_2/dw <- conv4_2/dw
I0630 16:50:47.349012 28406 net.cpp:369] relu4_2/dw -> conv4_2/dw (in-place)
I0630 16:50:47.349573 28406 net.cpp:124] Setting up relu4_2/dw
I0630 16:50:47.349586 28406 net.cpp:131] Top shape: 64 256 6 6 (589824)
I0630 16:50:47.349593 28406 net.cpp:139] Memory required for data: 714867456
I0630 16:50:47.349602 28406 layer_factory.hpp:77] Creating layer conv4_2/sep
I0630 16:50:47.349627 28406 net.cpp:86] Creating Layer conv4_2/sep
I0630 16:50:47.349642 28406 net.cpp:408] conv4_2/sep <- conv4_2/dw
I0630 16:50:47.349656 28406 net.cpp:382] conv4_2/sep -> conv4_2/sep
I0630 16:50:47.354506 28406 net.cpp:124] Setting up conv4_2/sep
I0630 16:50:47.354532 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.354539 28406 net.cpp:139] Memory required for data: 719586048
I0630 16:50:47.354554 28406 layer_factory.hpp:77] Creating layer conv4_2/sep/bn
I0630 16:50:47.354568 28406 net.cpp:86] Creating Layer conv4_2/sep/bn
I0630 16:50:47.354576 28406 net.cpp:408] conv4_2/sep/bn <- conv4_2/sep
I0630 16:50:47.354591 28406 net.cpp:369] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0630 16:50:47.354807 28406 net.cpp:124] Setting up conv4_2/sep/bn
I0630 16:50:47.354818 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.354826 28406 net.cpp:139] Memory required for data: 724304640
I0630 16:50:47.354841 28406 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0630 16:50:47.354852 28406 net.cpp:86] Creating Layer conv4_2/sep/scale
I0630 16:50:47.354861 28406 net.cpp:408] conv4_2/sep/scale <- conv4_2/sep
I0630 16:50:47.354873 28406 net.cpp:369] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0630 16:50:47.354918 28406 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0630 16:50:47.355041 28406 net.cpp:124] Setting up conv4_2/sep/scale
I0630 16:50:47.355051 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.355059 28406 net.cpp:139] Memory required for data: 729023232
I0630 16:50:47.355072 28406 layer_factory.hpp:77] Creating layer relu4_2/sep
I0630 16:50:47.355082 28406 net.cpp:86] Creating Layer relu4_2/sep
I0630 16:50:47.355090 28406 net.cpp:408] relu4_2/sep <- conv4_2/sep
I0630 16:50:47.355103 28406 net.cpp:369] relu4_2/sep -> conv4_2/sep (in-place)
I0630 16:50:47.355600 28406 net.cpp:124] Setting up relu4_2/sep
I0630 16:50:47.355612 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.355621 28406 net.cpp:139] Memory required for data: 733741824
I0630 16:50:47.355629 28406 layer_factory.hpp:77] Creating layer conv5_1/dw
I0630 16:50:47.355646 28406 net.cpp:86] Creating Layer conv5_1/dw
I0630 16:50:47.355654 28406 net.cpp:408] conv5_1/dw <- conv4_2/sep
I0630 16:50:47.355666 28406 net.cpp:382] conv5_1/dw -> conv5_1/dw
I0630 16:50:47.355909 28406 net.cpp:124] Setting up conv5_1/dw
I0630 16:50:47.355921 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.355928 28406 net.cpp:139] Memory required for data: 738460416
I0630 16:50:47.355938 28406 layer_factory.hpp:77] Creating layer conv5_1/dw/bn
I0630 16:50:47.355949 28406 net.cpp:86] Creating Layer conv5_1/dw/bn
I0630 16:50:47.355957 28406 net.cpp:408] conv5_1/dw/bn <- conv5_1/dw
I0630 16:50:47.355969 28406 net.cpp:369] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0630 16:50:47.356155 28406 net.cpp:124] Setting up conv5_1/dw/bn
I0630 16:50:47.356165 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.356174 28406 net.cpp:139] Memory required for data: 743179008
I0630 16:50:47.356189 28406 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0630 16:50:47.356199 28406 net.cpp:86] Creating Layer conv5_1/dw/scale
I0630 16:50:47.356206 28406 net.cpp:408] conv5_1/dw/scale <- conv5_1/dw
I0630 16:50:47.356218 28406 net.cpp:369] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0630 16:50:47.356261 28406 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0630 16:50:47.356379 28406 net.cpp:124] Setting up conv5_1/dw/scale
I0630 16:50:47.356391 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.356398 28406 net.cpp:139] Memory required for data: 747897600
I0630 16:50:47.356410 28406 layer_factory.hpp:77] Creating layer relu5_1/dw
I0630 16:50:47.356418 28406 net.cpp:86] Creating Layer relu5_1/dw
I0630 16:50:47.356426 28406 net.cpp:408] relu5_1/dw <- conv5_1/dw
I0630 16:50:47.356437 28406 net.cpp:369] relu5_1/dw -> conv5_1/dw (in-place)
I0630 16:50:47.356930 28406 net.cpp:124] Setting up relu5_1/dw
I0630 16:50:47.356945 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.356952 28406 net.cpp:139] Memory required for data: 752616192
I0630 16:50:47.356961 28406 layer_factory.hpp:77] Creating layer conv5_1/sep
I0630 16:50:47.356976 28406 net.cpp:86] Creating Layer conv5_1/sep
I0630 16:50:47.356981 28406 net.cpp:408] conv5_1/sep <- conv5_1/dw
I0630 16:50:47.356994 28406 net.cpp:382] conv5_1/sep -> conv5_1/sep
I0630 16:50:47.362099 28406 net.cpp:124] Setting up conv5_1/sep
I0630 16:50:47.362114 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.362123 28406 net.cpp:139] Memory required for data: 757334784
I0630 16:50:47.362141 28406 layer_factory.hpp:77] Creating layer conv5_1/sep/bn
I0630 16:50:47.362155 28406 net.cpp:86] Creating Layer conv5_1/sep/bn
I0630 16:50:47.362172 28406 net.cpp:408] conv5_1/sep/bn <- conv5_1/sep
I0630 16:50:47.362185 28406 net.cpp:369] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0630 16:50:47.362382 28406 net.cpp:124] Setting up conv5_1/sep/bn
I0630 16:50:47.362392 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.362401 28406 net.cpp:139] Memory required for data: 762053376
I0630 16:50:47.362423 28406 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0630 16:50:47.362437 28406 net.cpp:86] Creating Layer conv5_1/sep/scale
I0630 16:50:47.362443 28406 net.cpp:408] conv5_1/sep/scale <- conv5_1/sep
I0630 16:50:47.362453 28406 net.cpp:369] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0630 16:50:47.362515 28406 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0630 16:50:47.362645 28406 net.cpp:124] Setting up conv5_1/sep/scale
I0630 16:50:47.362655 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.362660 28406 net.cpp:139] Memory required for data: 766771968
I0630 16:50:47.362668 28406 layer_factory.hpp:77] Creating layer relu5_1/sep
I0630 16:50:47.362674 28406 net.cpp:86] Creating Layer relu5_1/sep
I0630 16:50:47.362679 28406 net.cpp:408] relu5_1/sep <- conv5_1/sep
I0630 16:50:47.362686 28406 net.cpp:369] relu5_1/sep -> conv5_1/sep (in-place)
I0630 16:50:47.363202 28406 net.cpp:124] Setting up relu5_1/sep
I0630 16:50:47.363214 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.363219 28406 net.cpp:139] Memory required for data: 771490560
I0630 16:50:47.363222 28406 layer_factory.hpp:77] Creating layer conv5_2/dw
I0630 16:50:47.363240 28406 net.cpp:86] Creating Layer conv5_2/dw
I0630 16:50:47.363246 28406 net.cpp:408] conv5_2/dw <- conv5_1/sep
I0630 16:50:47.363262 28406 net.cpp:382] conv5_2/dw -> conv5_2/dw
I0630 16:50:47.363505 28406 net.cpp:124] Setting up conv5_2/dw
I0630 16:50:47.363515 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.363521 28406 net.cpp:139] Memory required for data: 776209152
I0630 16:50:47.363526 28406 layer_factory.hpp:77] Creating layer conv5_2/dw/bn
I0630 16:50:47.363534 28406 net.cpp:86] Creating Layer conv5_2/dw/bn
I0630 16:50:47.363540 28406 net.cpp:408] conv5_2/dw/bn <- conv5_2/dw
I0630 16:50:47.363548 28406 net.cpp:369] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0630 16:50:47.363744 28406 net.cpp:124] Setting up conv5_2/dw/bn
I0630 16:50:47.363754 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.363762 28406 net.cpp:139] Memory required for data: 780927744
I0630 16:50:47.363777 28406 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0630 16:50:47.363797 28406 net.cpp:86] Creating Layer conv5_2/dw/scale
I0630 16:50:47.363804 28406 net.cpp:408] conv5_2/dw/scale <- conv5_2/dw
I0630 16:50:47.363814 28406 net.cpp:369] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0630 16:50:47.363862 28406 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0630 16:50:47.363982 28406 net.cpp:124] Setting up conv5_2/dw/scale
I0630 16:50:47.363993 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.364001 28406 net.cpp:139] Memory required for data: 785646336
I0630 16:50:47.364015 28406 layer_factory.hpp:77] Creating layer relu5_2/dw
I0630 16:50:47.364027 28406 net.cpp:86] Creating Layer relu5_2/dw
I0630 16:50:47.364034 28406 net.cpp:408] relu5_2/dw <- conv5_2/dw
I0630 16:50:47.364045 28406 net.cpp:369] relu5_2/dw -> conv5_2/dw (in-place)
I0630 16:50:47.364892 28406 net.cpp:124] Setting up relu5_2/dw
I0630 16:50:47.364905 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.364914 28406 net.cpp:139] Memory required for data: 790364928
I0630 16:50:47.364923 28406 layer_factory.hpp:77] Creating layer conv5_2/sep
I0630 16:50:47.364940 28406 net.cpp:86] Creating Layer conv5_2/sep
I0630 16:50:47.364948 28406 net.cpp:408] conv5_2/sep <- conv5_2/dw
I0630 16:50:47.364960 28406 net.cpp:382] conv5_2/sep -> conv5_2/sep
I0630 16:50:47.370602 28406 net.cpp:124] Setting up conv5_2/sep
I0630 16:50:47.370620 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.370626 28406 net.cpp:139] Memory required for data: 795083520
I0630 16:50:47.370658 28406 layer_factory.hpp:77] Creating layer conv5_2/sep/bn
I0630 16:50:47.370678 28406 net.cpp:86] Creating Layer conv5_2/sep/bn
I0630 16:50:47.370693 28406 net.cpp:408] conv5_2/sep/bn <- conv5_2/sep
I0630 16:50:47.370702 28406 net.cpp:369] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0630 16:50:47.370908 28406 net.cpp:124] Setting up conv5_2/sep/bn
I0630 16:50:47.370918 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.370921 28406 net.cpp:139] Memory required for data: 799802112
I0630 16:50:47.370929 28406 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0630 16:50:47.370946 28406 net.cpp:86] Creating Layer conv5_2/sep/scale
I0630 16:50:47.370951 28406 net.cpp:408] conv5_2/sep/scale <- conv5_2/sep
I0630 16:50:47.370967 28406 net.cpp:369] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0630 16:50:47.371026 28406 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0630 16:50:47.371155 28406 net.cpp:124] Setting up conv5_2/sep/scale
I0630 16:50:47.371165 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.371173 28406 net.cpp:139] Memory required for data: 804520704
I0630 16:50:47.371194 28406 layer_factory.hpp:77] Creating layer relu5_2/sep
I0630 16:50:47.371208 28406 net.cpp:86] Creating Layer relu5_2/sep
I0630 16:50:47.371215 28406 net.cpp:408] relu5_2/sep <- conv5_2/sep
I0630 16:50:47.371227 28406 net.cpp:369] relu5_2/sep -> conv5_2/sep (in-place)
I0630 16:50:47.371773 28406 net.cpp:124] Setting up relu5_2/sep
I0630 16:50:47.371784 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.371795 28406 net.cpp:139] Memory required for data: 809239296
I0630 16:50:47.371803 28406 layer_factory.hpp:77] Creating layer conv5_3/dw
I0630 16:50:47.371819 28406 net.cpp:86] Creating Layer conv5_3/dw
I0630 16:50:47.371825 28406 net.cpp:408] conv5_3/dw <- conv5_2/sep
I0630 16:50:47.371837 28406 net.cpp:382] conv5_3/dw -> conv5_3/dw
I0630 16:50:47.372086 28406 net.cpp:124] Setting up conv5_3/dw
I0630 16:50:47.372097 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.372104 28406 net.cpp:139] Memory required for data: 813957888
I0630 16:50:47.372115 28406 layer_factory.hpp:77] Creating layer conv5_3/dw/bn
I0630 16:50:47.372128 28406 net.cpp:86] Creating Layer conv5_3/dw/bn
I0630 16:50:47.372135 28406 net.cpp:408] conv5_3/dw/bn <- conv5_3/dw
I0630 16:50:47.372148 28406 net.cpp:369] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0630 16:50:47.372332 28406 net.cpp:124] Setting up conv5_3/dw/bn
I0630 16:50:47.372344 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.372351 28406 net.cpp:139] Memory required for data: 818676480
I0630 16:50:47.372366 28406 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0630 16:50:47.372378 28406 net.cpp:86] Creating Layer conv5_3/dw/scale
I0630 16:50:47.372386 28406 net.cpp:408] conv5_3/dw/scale <- conv5_3/dw
I0630 16:50:47.372395 28406 net.cpp:369] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0630 16:50:47.372440 28406 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0630 16:50:47.372565 28406 net.cpp:124] Setting up conv5_3/dw/scale
I0630 16:50:47.372575 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.372582 28406 net.cpp:139] Memory required for data: 823395072
I0630 16:50:47.372596 28406 layer_factory.hpp:77] Creating layer relu5_3/dw
I0630 16:50:47.372604 28406 net.cpp:86] Creating Layer relu5_3/dw
I0630 16:50:47.372612 28406 net.cpp:408] relu5_3/dw <- conv5_3/dw
I0630 16:50:47.372627 28406 net.cpp:369] relu5_3/dw -> conv5_3/dw (in-place)
I0630 16:50:47.373453 28406 net.cpp:124] Setting up relu5_3/dw
I0630 16:50:47.373466 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.373474 28406 net.cpp:139] Memory required for data: 828113664
I0630 16:50:47.373483 28406 layer_factory.hpp:77] Creating layer conv5_3/sep
I0630 16:50:47.373499 28406 net.cpp:86] Creating Layer conv5_3/sep
I0630 16:50:47.373507 28406 net.cpp:408] conv5_3/sep <- conv5_3/dw
I0630 16:50:47.373522 28406 net.cpp:382] conv5_3/sep -> conv5_3/sep
I0630 16:50:47.378229 28406 net.cpp:124] Setting up conv5_3/sep
I0630 16:50:47.378252 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.378262 28406 net.cpp:139] Memory required for data: 832832256
I0630 16:50:47.378280 28406 layer_factory.hpp:77] Creating layer conv5_3/sep/bn
I0630 16:50:47.378294 28406 net.cpp:86] Creating Layer conv5_3/sep/bn
I0630 16:50:47.378301 28406 net.cpp:408] conv5_3/sep/bn <- conv5_3/sep
I0630 16:50:47.378312 28406 net.cpp:369] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0630 16:50:47.378509 28406 net.cpp:124] Setting up conv5_3/sep/bn
I0630 16:50:47.378520 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.378528 28406 net.cpp:139] Memory required for data: 837550848
I0630 16:50:47.378543 28406 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0630 16:50:47.378553 28406 net.cpp:86] Creating Layer conv5_3/sep/scale
I0630 16:50:47.378561 28406 net.cpp:408] conv5_3/sep/scale <- conv5_3/sep
I0630 16:50:47.378572 28406 net.cpp:369] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0630 16:50:47.378619 28406 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0630 16:50:47.378742 28406 net.cpp:124] Setting up conv5_3/sep/scale
I0630 16:50:47.378752 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.378760 28406 net.cpp:139] Memory required for data: 842269440
I0630 16:50:47.378772 28406 layer_factory.hpp:77] Creating layer relu5_3/sep
I0630 16:50:47.378787 28406 net.cpp:86] Creating Layer relu5_3/sep
I0630 16:50:47.378793 28406 net.cpp:408] relu5_3/sep <- conv5_3/sep
I0630 16:50:47.378801 28406 net.cpp:369] relu5_3/sep -> conv5_3/sep (in-place)
I0630 16:50:47.379289 28406 net.cpp:124] Setting up relu5_3/sep
I0630 16:50:47.379300 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.379308 28406 net.cpp:139] Memory required for data: 846988032
I0630 16:50:47.379317 28406 layer_factory.hpp:77] Creating layer conv5_4/dw
I0630 16:50:47.379333 28406 net.cpp:86] Creating Layer conv5_4/dw
I0630 16:50:47.379340 28406 net.cpp:408] conv5_4/dw <- conv5_3/sep
I0630 16:50:47.379354 28406 net.cpp:382] conv5_4/dw -> conv5_4/dw
I0630 16:50:47.379600 28406 net.cpp:124] Setting up conv5_4/dw
I0630 16:50:47.379609 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.379617 28406 net.cpp:139] Memory required for data: 851706624
I0630 16:50:47.379629 28406 layer_factory.hpp:77] Creating layer conv5_4/dw/bn
I0630 16:50:47.379642 28406 net.cpp:86] Creating Layer conv5_4/dw/bn
I0630 16:50:47.379649 28406 net.cpp:408] conv5_4/dw/bn <- conv5_4/dw
I0630 16:50:47.379659 28406 net.cpp:369] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0630 16:50:47.379846 28406 net.cpp:124] Setting up conv5_4/dw/bn
I0630 16:50:47.379856 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.379864 28406 net.cpp:139] Memory required for data: 856425216
I0630 16:50:47.379878 28406 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0630 16:50:47.379890 28406 net.cpp:86] Creating Layer conv5_4/dw/scale
I0630 16:50:47.379899 28406 net.cpp:408] conv5_4/dw/scale <- conv5_4/dw
I0630 16:50:47.379907 28406 net.cpp:369] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0630 16:50:47.379952 28406 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0630 16:50:47.380074 28406 net.cpp:124] Setting up conv5_4/dw/scale
I0630 16:50:47.380085 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.380092 28406 net.cpp:139] Memory required for data: 861143808
I0630 16:50:47.380105 28406 layer_factory.hpp:77] Creating layer relu5_4/dw
I0630 16:50:47.380115 28406 net.cpp:86] Creating Layer relu5_4/dw
I0630 16:50:47.380122 28406 net.cpp:408] relu5_4/dw <- conv5_4/dw
I0630 16:50:47.380132 28406 net.cpp:369] relu5_4/dw -> conv5_4/dw (in-place)
I0630 16:50:47.381054 28406 net.cpp:124] Setting up relu5_4/dw
I0630 16:50:47.381072 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.381088 28406 net.cpp:139] Memory required for data: 865862400
I0630 16:50:47.381095 28406 layer_factory.hpp:77] Creating layer conv5_4/sep
I0630 16:50:47.381129 28406 net.cpp:86] Creating Layer conv5_4/sep
I0630 16:50:47.381137 28406 net.cpp:408] conv5_4/sep <- conv5_4/dw
I0630 16:50:47.381157 28406 net.cpp:382] conv5_4/sep -> conv5_4/sep
I0630 16:50:47.387627 28406 net.cpp:124] Setting up conv5_4/sep
I0630 16:50:47.387655 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.387660 28406 net.cpp:139] Memory required for data: 870580992
I0630 16:50:47.387670 28406 layer_factory.hpp:77] Creating layer conv5_4/sep/bn
I0630 16:50:47.387688 28406 net.cpp:86] Creating Layer conv5_4/sep/bn
I0630 16:50:47.387696 28406 net.cpp:408] conv5_4/sep/bn <- conv5_4/sep
I0630 16:50:47.387706 28406 net.cpp:369] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0630 16:50:47.387924 28406 net.cpp:124] Setting up conv5_4/sep/bn
I0630 16:50:47.387933 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.387938 28406 net.cpp:139] Memory required for data: 875299584
I0630 16:50:47.387954 28406 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0630 16:50:47.387964 28406 net.cpp:86] Creating Layer conv5_4/sep/scale
I0630 16:50:47.387969 28406 net.cpp:408] conv5_4/sep/scale <- conv5_4/sep
I0630 16:50:47.387974 28406 net.cpp:369] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0630 16:50:47.388032 28406 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0630 16:50:47.388180 28406 net.cpp:124] Setting up conv5_4/sep/scale
I0630 16:50:47.388188 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.388192 28406 net.cpp:139] Memory required for data: 880018176
I0630 16:50:47.388206 28406 layer_factory.hpp:77] Creating layer relu5_4/sep
I0630 16:50:47.388214 28406 net.cpp:86] Creating Layer relu5_4/sep
I0630 16:50:47.388218 28406 net.cpp:408] relu5_4/sep <- conv5_4/sep
I0630 16:50:47.388226 28406 net.cpp:369] relu5_4/sep -> conv5_4/sep (in-place)
I0630 16:50:47.388727 28406 net.cpp:124] Setting up relu5_4/sep
I0630 16:50:47.388738 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.388742 28406 net.cpp:139] Memory required for data: 884736768
I0630 16:50:47.388754 28406 layer_factory.hpp:77] Creating layer conv5_5/dw
I0630 16:50:47.388765 28406 net.cpp:86] Creating Layer conv5_5/dw
I0630 16:50:47.388770 28406 net.cpp:408] conv5_5/dw <- conv5_4/sep
I0630 16:50:47.388777 28406 net.cpp:382] conv5_5/dw -> conv5_5/dw
I0630 16:50:47.389042 28406 net.cpp:124] Setting up conv5_5/dw
I0630 16:50:47.389051 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.389055 28406 net.cpp:139] Memory required for data: 889455360
I0630 16:50:47.389070 28406 layer_factory.hpp:77] Creating layer conv5_5/dw/bn
I0630 16:50:47.389078 28406 net.cpp:86] Creating Layer conv5_5/dw/bn
I0630 16:50:47.389082 28406 net.cpp:408] conv5_5/dw/bn <- conv5_5/dw
I0630 16:50:47.389088 28406 net.cpp:369] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0630 16:50:47.389340 28406 net.cpp:124] Setting up conv5_5/dw/bn
I0630 16:50:47.389350 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.389355 28406 net.cpp:139] Memory required for data: 894173952
I0630 16:50:47.389379 28406 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0630 16:50:47.389394 28406 net.cpp:86] Creating Layer conv5_5/dw/scale
I0630 16:50:47.389400 28406 net.cpp:408] conv5_5/dw/scale <- conv5_5/dw
I0630 16:50:47.389405 28406 net.cpp:369] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0630 16:50:47.389451 28406 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0630 16:50:47.389566 28406 net.cpp:124] Setting up conv5_5/dw/scale
I0630 16:50:47.389578 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.389583 28406 net.cpp:139] Memory required for data: 898892544
I0630 16:50:47.389590 28406 layer_factory.hpp:77] Creating layer relu5_5/dw
I0630 16:50:47.389596 28406 net.cpp:86] Creating Layer relu5_5/dw
I0630 16:50:47.389601 28406 net.cpp:408] relu5_5/dw <- conv5_5/dw
I0630 16:50:47.389606 28406 net.cpp:369] relu5_5/dw -> conv5_5/dw (in-place)
I0630 16:50:47.390453 28406 net.cpp:124] Setting up relu5_5/dw
I0630 16:50:47.390465 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.390470 28406 net.cpp:139] Memory required for data: 903611136
I0630 16:50:47.390475 28406 layer_factory.hpp:77] Creating layer conv5_5/sep
I0630 16:50:47.390501 28406 net.cpp:86] Creating Layer conv5_5/sep
I0630 16:50:47.390507 28406 net.cpp:408] conv5_5/sep <- conv5_5/dw
I0630 16:50:47.390516 28406 net.cpp:382] conv5_5/sep -> conv5_5/sep
I0630 16:50:47.395313 28406 net.cpp:124] Setting up conv5_5/sep
I0630 16:50:47.395326 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.395331 28406 net.cpp:139] Memory required for data: 908329728
I0630 16:50:47.395345 28406 layer_factory.hpp:77] Creating layer conv5_5/sep/bn
I0630 16:50:47.395352 28406 net.cpp:86] Creating Layer conv5_5/sep/bn
I0630 16:50:47.395356 28406 net.cpp:408] conv5_5/sep/bn <- conv5_5/sep
I0630 16:50:47.395372 28406 net.cpp:369] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0630 16:50:47.395594 28406 net.cpp:124] Setting up conv5_5/sep/bn
I0630 16:50:47.395612 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.395617 28406 net.cpp:139] Memory required for data: 913048320
I0630 16:50:47.395624 28406 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0630 16:50:47.395632 28406 net.cpp:86] Creating Layer conv5_5/sep/scale
I0630 16:50:47.395635 28406 net.cpp:408] conv5_5/sep/scale <- conv5_5/sep
I0630 16:50:47.395651 28406 net.cpp:369] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0630 16:50:47.395706 28406 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0630 16:50:47.395874 28406 net.cpp:124] Setting up conv5_5/sep/scale
I0630 16:50:47.395884 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.395887 28406 net.cpp:139] Memory required for data: 917766912
I0630 16:50:47.395902 28406 layer_factory.hpp:77] Creating layer relu5_5/sep
I0630 16:50:47.395917 28406 net.cpp:86] Creating Layer relu5_5/sep
I0630 16:50:47.395922 28406 net.cpp:408] relu5_5/sep <- conv5_5/sep
I0630 16:50:47.395927 28406 net.cpp:369] relu5_5/sep -> conv5_5/sep (in-place)
I0630 16:50:47.397059 28406 net.cpp:124] Setting up relu5_5/sep
I0630 16:50:47.397079 28406 net.cpp:131] Top shape: 64 512 6 6 (1179648)
I0630 16:50:47.397084 28406 net.cpp:139] Memory required for data: 922485504
I0630 16:50:47.397089 28406 layer_factory.hpp:77] Creating layer pool6
I0630 16:50:47.397096 28406 net.cpp:86] Creating Layer pool6
I0630 16:50:47.397100 28406 net.cpp:408] pool6 <- conv5_5/sep
I0630 16:50:47.397115 28406 net.cpp:382] pool6 -> pool6
I0630 16:50:47.397712 28406 net.cpp:124] Setting up pool6
I0630 16:50:47.397727 28406 net.cpp:131] Top shape: 64 512 1 1 (32768)
I0630 16:50:47.397732 28406 net.cpp:139] Memory required for data: 922616576
I0630 16:50:47.397735 28406 layer_factory.hpp:77] Creating layer fc7-mouth
I0630 16:50:47.397745 28406 net.cpp:86] Creating Layer fc7-mouth
I0630 16:50:47.397752 28406 net.cpp:408] fc7-mouth <- pool6
I0630 16:50:47.397758 28406 net.cpp:382] fc7-mouth -> fc7-mouth
I0630 16:50:47.400168 28406 net.cpp:124] Setting up fc7-mouth
I0630 16:50:47.400182 28406 net.cpp:131] Top shape: 64 4 1 1 (256)
I0630 16:50:47.400187 28406 net.cpp:139] Memory required for data: 922617600
I0630 16:50:47.400194 28406 layer_factory.hpp:77] Creating layer fc7-mouth_fc7-mouth_0_split
I0630 16:50:47.400203 28406 net.cpp:86] Creating Layer fc7-mouth_fc7-mouth_0_split
I0630 16:50:47.400209 28406 net.cpp:408] fc7-mouth_fc7-mouth_0_split <- fc7-mouth
I0630 16:50:47.400218 28406 net.cpp:382] fc7-mouth_fc7-mouth_0_split -> fc7-mouth_fc7-mouth_0_split_0
I0630 16:50:47.400225 28406 net.cpp:382] fc7-mouth_fc7-mouth_0_split -> fc7-mouth_fc7-mouth_0_split_1
I0630 16:50:47.400267 28406 net.cpp:124] Setting up fc7-mouth_fc7-mouth_0_split
I0630 16:50:47.400279 28406 net.cpp:131] Top shape: 64 4 1 1 (256)
I0630 16:50:47.400285 28406 net.cpp:131] Top shape: 64 4 1 1 (256)
I0630 16:50:47.400287 28406 net.cpp:139] Memory required for data: 922619648
I0630 16:50:47.400292 28406 layer_factory.hpp:77] Creating layer loss
I0630 16:50:47.400298 28406 net.cpp:86] Creating Layer loss
I0630 16:50:47.400303 28406 net.cpp:408] loss <- fc7-mouth_fc7-mouth_0_split_0
I0630 16:50:47.400308 28406 net.cpp:408] loss <- clc-label_data_1_split_0
I0630 16:50:47.400315 28406 net.cpp:382] loss -> loss
I0630 16:50:47.400337 28406 layer_factory.hpp:77] Creating layer loss
I0630 16:50:47.401275 28406 net.cpp:124] Setting up loss
I0630 16:50:47.401295 28406 net.cpp:131] Top shape: (1)
I0630 16:50:47.401300 28406 net.cpp:134]     with loss weight 1
I0630 16:50:47.401316 28406 net.cpp:139] Memory required for data: 922619652
I0630 16:50:47.401320 28406 layer_factory.hpp:77] Creating layer acc
I0630 16:50:47.401338 28406 net.cpp:86] Creating Layer acc
I0630 16:50:47.401346 28406 net.cpp:408] acc <- fc7-mouth_fc7-mouth_0_split_1
I0630 16:50:47.401352 28406 net.cpp:408] acc <- clc-label_data_1_split_1
I0630 16:50:47.401368 28406 net.cpp:382] acc -> acc
I0630 16:50:47.401384 28406 net.cpp:124] Setting up acc
I0630 16:50:47.401401 28406 net.cpp:131] Top shape: (1)
I0630 16:50:47.401405 28406 net.cpp:139] Memory required for data: 922619656
I0630 16:50:47.401409 28406 net.cpp:202] acc does not need backward computation.
I0630 16:50:47.401417 28406 net.cpp:200] loss needs backward computation.
I0630 16:50:47.401422 28406 net.cpp:200] fc7-mouth_fc7-mouth_0_split needs backward computation.
I0630 16:50:47.401427 28406 net.cpp:200] fc7-mouth needs backward computation.
I0630 16:50:47.401430 28406 net.cpp:200] pool6 needs backward computation.
I0630 16:50:47.401434 28406 net.cpp:200] relu5_5/sep needs backward computation.
I0630 16:50:47.401446 28406 net.cpp:200] conv5_5/sep/scale needs backward computation.
I0630 16:50:47.401459 28406 net.cpp:200] conv5_5/sep/bn needs backward computation.
I0630 16:50:47.401463 28406 net.cpp:200] conv5_5/sep needs backward computation.
I0630 16:50:47.401468 28406 net.cpp:200] relu5_5/dw needs backward computation.
I0630 16:50:47.401479 28406 net.cpp:200] conv5_5/dw/scale needs backward computation.
I0630 16:50:47.401484 28406 net.cpp:200] conv5_5/dw/bn needs backward computation.
I0630 16:50:47.401489 28406 net.cpp:200] conv5_5/dw needs backward computation.
I0630 16:50:47.401492 28406 net.cpp:200] relu5_4/sep needs backward computation.
I0630 16:50:47.401496 28406 net.cpp:200] conv5_4/sep/scale needs backward computation.
I0630 16:50:47.401500 28406 net.cpp:200] conv5_4/sep/bn needs backward computation.
I0630 16:50:47.401504 28406 net.cpp:200] conv5_4/sep needs backward computation.
I0630 16:50:47.401510 28406 net.cpp:200] relu5_4/dw needs backward computation.
I0630 16:50:47.401513 28406 net.cpp:200] conv5_4/dw/scale needs backward computation.
I0630 16:50:47.401517 28406 net.cpp:200] conv5_4/dw/bn needs backward computation.
I0630 16:50:47.401521 28406 net.cpp:200] conv5_4/dw needs backward computation.
I0630 16:50:47.401526 28406 net.cpp:200] relu5_3/sep needs backward computation.
I0630 16:50:47.401530 28406 net.cpp:200] conv5_3/sep/scale needs backward computation.
I0630 16:50:47.401535 28406 net.cpp:200] conv5_3/sep/bn needs backward computation.
I0630 16:50:47.401538 28406 net.cpp:200] conv5_3/sep needs backward computation.
I0630 16:50:47.401542 28406 net.cpp:200] relu5_3/dw needs backward computation.
I0630 16:50:47.401546 28406 net.cpp:200] conv5_3/dw/scale needs backward computation.
I0630 16:50:47.401551 28406 net.cpp:200] conv5_3/dw/bn needs backward computation.
I0630 16:50:47.401554 28406 net.cpp:200] conv5_3/dw needs backward computation.
I0630 16:50:47.401559 28406 net.cpp:200] relu5_2/sep needs backward computation.
I0630 16:50:47.401563 28406 net.cpp:200] conv5_2/sep/scale needs backward computation.
I0630 16:50:47.401567 28406 net.cpp:200] conv5_2/sep/bn needs backward computation.
I0630 16:50:47.401571 28406 net.cpp:200] conv5_2/sep needs backward computation.
I0630 16:50:47.401576 28406 net.cpp:200] relu5_2/dw needs backward computation.
I0630 16:50:47.401579 28406 net.cpp:200] conv5_2/dw/scale needs backward computation.
I0630 16:50:47.401583 28406 net.cpp:200] conv5_2/dw/bn needs backward computation.
I0630 16:50:47.401587 28406 net.cpp:200] conv5_2/dw needs backward computation.
I0630 16:50:47.401592 28406 net.cpp:200] relu5_1/sep needs backward computation.
I0630 16:50:47.401595 28406 net.cpp:200] conv5_1/sep/scale needs backward computation.
I0630 16:50:47.401612 28406 net.cpp:200] conv5_1/sep/bn needs backward computation.
I0630 16:50:47.401618 28406 net.cpp:200] conv5_1/sep needs backward computation.
I0630 16:50:47.401623 28406 net.cpp:200] relu5_1/dw needs backward computation.
I0630 16:50:47.401626 28406 net.cpp:200] conv5_1/dw/scale needs backward computation.
I0630 16:50:47.401630 28406 net.cpp:200] conv5_1/dw/bn needs backward computation.
I0630 16:50:47.401634 28406 net.cpp:200] conv5_1/dw needs backward computation.
I0630 16:50:47.401638 28406 net.cpp:200] relu4_2/sep needs backward computation.
I0630 16:50:47.401643 28406 net.cpp:200] conv4_2/sep/scale needs backward computation.
I0630 16:50:47.401648 28406 net.cpp:200] conv4_2/sep/bn needs backward computation.
I0630 16:50:47.401650 28406 net.cpp:200] conv4_2/sep needs backward computation.
I0630 16:50:47.401655 28406 net.cpp:200] relu4_2/dw needs backward computation.
I0630 16:50:47.401659 28406 net.cpp:200] conv4_2/dw/scale needs backward computation.
I0630 16:50:47.401664 28406 net.cpp:200] conv4_2/dw/bn needs backward computation.
I0630 16:50:47.401667 28406 net.cpp:200] conv4_2/dw needs backward computation.
I0630 16:50:47.401671 28406 net.cpp:200] relu4_1/sep needs backward computation.
I0630 16:50:47.401676 28406 net.cpp:200] conv4_1/sep/scale needs backward computation.
I0630 16:50:47.401680 28406 net.cpp:200] conv4_1/sep/bn needs backward computation.
I0630 16:50:47.401684 28406 net.cpp:200] conv4_1/sep needs backward computation.
I0630 16:50:47.401688 28406 net.cpp:200] relu4_1/dw needs backward computation.
I0630 16:50:47.401692 28406 net.cpp:200] conv4_1/dw/scale needs backward computation.
I0630 16:50:47.401696 28406 net.cpp:200] conv4_1/dw/bn needs backward computation.
I0630 16:50:47.401700 28406 net.cpp:200] conv4_1/dw needs backward computation.
I0630 16:50:47.401705 28406 net.cpp:200] relu3_2/sep needs backward computation.
I0630 16:50:47.401708 28406 net.cpp:200] conv3_2/sep/scale needs backward computation.
I0630 16:50:47.401712 28406 net.cpp:200] conv3_2/sep/bn needs backward computation.
I0630 16:50:47.401716 28406 net.cpp:200] conv3_2/sep needs backward computation.
I0630 16:50:47.401721 28406 net.cpp:200] relu3_2/dw needs backward computation.
I0630 16:50:47.401726 28406 net.cpp:200] conv3_2/dw/scale needs backward computation.
I0630 16:50:47.401729 28406 net.cpp:200] conv3_2/dw/bn needs backward computation.
I0630 16:50:47.401733 28406 net.cpp:200] conv3_2/dw needs backward computation.
I0630 16:50:47.401737 28406 net.cpp:200] relu3_1/sep needs backward computation.
I0630 16:50:47.401742 28406 net.cpp:200] conv3_1/sep/scale needs backward computation.
I0630 16:50:47.401746 28406 net.cpp:200] conv3_1/sep/bn needs backward computation.
I0630 16:50:47.401751 28406 net.cpp:200] conv3_1/sep needs backward computation.
I0630 16:50:47.401754 28406 net.cpp:200] relu3_1/dw needs backward computation.
I0630 16:50:47.401758 28406 net.cpp:200] conv3_1/dw/scale needs backward computation.
I0630 16:50:47.401762 28406 net.cpp:200] conv3_1/dw/bn needs backward computation.
I0630 16:50:47.401767 28406 net.cpp:200] conv3_1/dw needs backward computation.
I0630 16:50:47.401772 28406 net.cpp:200] relu2_2/sep needs backward computation.
I0630 16:50:47.401775 28406 net.cpp:200] conv2_2/sep/scale needs backward computation.
I0630 16:50:47.401779 28406 net.cpp:200] conv2_2/sep/bn needs backward computation.
I0630 16:50:47.401783 28406 net.cpp:200] conv2_2/sep needs backward computation.
I0630 16:50:47.401787 28406 net.cpp:200] relu2_2/dw needs backward computation.
I0630 16:50:47.401791 28406 net.cpp:200] conv2_2/dw/scale needs backward computation.
I0630 16:50:47.401796 28406 net.cpp:200] conv2_2/dw/bn needs backward computation.
I0630 16:50:47.401800 28406 net.cpp:200] conv2_2/dw needs backward computation.
I0630 16:50:47.401804 28406 net.cpp:200] relu2_1/sep needs backward computation.
I0630 16:50:47.401808 28406 net.cpp:200] conv2_1/sep/scale needs backward computation.
I0630 16:50:47.401813 28406 net.cpp:200] conv2_1/sep/bn needs backward computation.
I0630 16:50:47.401816 28406 net.cpp:200] conv2_1/sep needs backward computation.
I0630 16:50:47.401827 28406 net.cpp:200] relu2_1/dw needs backward computation.
I0630 16:50:47.401832 28406 net.cpp:200] conv2_1/dw/scale needs backward computation.
I0630 16:50:47.401836 28406 net.cpp:200] conv2_1/dw/bn needs backward computation.
I0630 16:50:47.401840 28406 net.cpp:200] conv2_1/dw needs backward computation.
I0630 16:50:47.401845 28406 net.cpp:200] relu1 needs backward computation.
I0630 16:50:47.401851 28406 net.cpp:200] conv1/scale needs backward computation.
I0630 16:50:47.401859 28406 net.cpp:200] conv1/bn needs backward computation.
I0630 16:50:47.401863 28406 net.cpp:200] conv1 needs backward computation.
I0630 16:50:47.401868 28406 net.cpp:202] clc-label_data_1_split does not need backward computation.
I0630 16:50:47.401873 28406 net.cpp:202] data does not need backward computation.
I0630 16:50:47.401876 28406 net.cpp:244] This network produces output acc
I0630 16:50:47.401881 28406 net.cpp:244] This network produces output loss
I0630 16:50:47.401933 28406 net.cpp:257] Network initialization done.
I0630 16:50:47.402117 28406 solver.cpp:72] Finetuning from ./mobilenet.caffemodel
I0630 16:50:47.477147 28406 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./mobilenet.caffemodel
I0630 16:50:47.477207 28406 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0630 16:50:47.477219 28406 net.cpp:746] Ignoring source layer label_data_1_split
I0630 16:50:47.478621 28406 net.cpp:746] Ignoring source layer conv5_6/dw
I0630 16:50:47.478654 28406 net.cpp:746] Ignoring source layer conv5_6/dw/bn
I0630 16:50:47.478658 28406 net.cpp:746] Ignoring source layer conv5_6/dw/scale
I0630 16:50:47.478670 28406 net.cpp:746] Ignoring source layer relu5_6/dw
I0630 16:50:47.478674 28406 net.cpp:746] Ignoring source layer conv5_6/sep
I0630 16:50:47.478677 28406 net.cpp:746] Ignoring source layer conv5_6/sep/bn
I0630 16:50:47.478682 28406 net.cpp:746] Ignoring source layer conv5_6/sep/scale
I0630 16:50:47.478685 28406 net.cpp:746] Ignoring source layer relu5_6/sep
I0630 16:50:47.478688 28406 net.cpp:746] Ignoring source layer conv6/dw
I0630 16:50:47.478693 28406 net.cpp:746] Ignoring source layer conv6/dw/bn
I0630 16:50:47.478696 28406 net.cpp:746] Ignoring source layer conv6/dw/scale
I0630 16:50:47.478699 28406 net.cpp:746] Ignoring source layer relu6/dw
I0630 16:50:47.478703 28406 net.cpp:746] Ignoring source layer conv6/sep
I0630 16:50:47.478706 28406 net.cpp:746] Ignoring source layer conv6/sep/bn
I0630 16:50:47.478718 28406 net.cpp:746] Ignoring source layer conv6/sep/scale
I0630 16:50:47.478721 28406 net.cpp:746] Ignoring source layer relu6/sep
I0630 16:50:47.478725 28406 net.cpp:746] Ignoring source layer fc7
I0630 16:50:47.478729 28406 net.cpp:746] Ignoring source layer fc7_fc7_0_split
I0630 16:50:47.478734 28406 net.cpp:746] Ignoring source layer top1/acc
I0630 16:50:47.478736 28406 net.cpp:746] Ignoring source layer top5/acc
I0630 16:50:47.479540 28406 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: mobilenet_train.prototxt
I0630 16:50:47.479552 28406 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0630 16:50:47.479565 28406 solver.cpp:190] Creating test net (#0) specified by net file: mobilenet_train.prototxt
I0630 16:50:47.479655 28406 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0630 16:50:47.479697 28406 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer acc
I0630 16:50:47.480265 28406 net.cpp:53] Initializing net from parameters: 
name: "mouth"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "clc-label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 96
    mean_value: 104.008
    mean_value: 116.669
    mean_value: 122.675
    min_side_min: 96
    min_side_max: 128
  }
  image_data_param {
    source: "all_shuffle_val.txt"
    batch_size: 16
    shuffle: false
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "Convolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "Convolution"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "Convolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "Convolution"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "Convolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "Convolution"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "Convolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "Convolution"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "Convolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "Convolution"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "Convolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "Convolution"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "Convolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "Convolution"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "Convolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "Convolution"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "Convolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "Convolution"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "Convolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "Convolution"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "Convolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 1e-05
  }
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv5_5/sep"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc7-mouth"
  type: "Convolution"
  bottom: "pool6"
  top: "fc7-mouth"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc7-mouth"
  bottom: "clc-label"
  top: "loss"
}
layer {
  name: "acc"
  type: "Accuracy"
  bottom: "fc7-mouth"
  bottom: "clc-label"
  top: "acc"
  include {
    phase: TRAIN
  }
  include {
    phase: TEST
  }
}
I0630 16:50:47.480522 28406 layer_factory.hpp:77] Creating layer data
I0630 16:50:47.480540 28406 net.cpp:86] Creating Layer data
I0630 16:50:47.480546 28406 net.cpp:382] data -> data
I0630 16:50:47.480557 28406 net.cpp:382] data -> clc-label
I0630 16:50:47.480567 28406 image_data_layer.cpp:38] Opening file all_shuffle_val.txt
I0630 16:50:47.481207 28406 image_data_layer.cpp:63] A total of 1510 images.
I0630 16:50:47.481621 28406 image_data_layer.cpp:90] output data size: 16,3,96,96
I0630 16:50:47.488240 28406 net.cpp:124] Setting up data
I0630 16:50:47.488270 28406 net.cpp:131] Top shape: 16 3 96 96 (442368)
I0630 16:50:47.488276 28406 net.cpp:131] Top shape: 16 (16)
I0630 16:50:47.488281 28406 net.cpp:139] Memory required for data: 1769536
I0630 16:50:47.488291 28406 layer_factory.hpp:77] Creating layer clc-label_data_1_split
I0630 16:50:47.488307 28406 net.cpp:86] Creating Layer clc-label_data_1_split
I0630 16:50:47.488314 28406 net.cpp:408] clc-label_data_1_split <- clc-label
I0630 16:50:47.488329 28406 net.cpp:382] clc-label_data_1_split -> clc-label_data_1_split_0
I0630 16:50:47.488348 28406 net.cpp:382] clc-label_data_1_split -> clc-label_data_1_split_1
I0630 16:50:47.488441 28406 net.cpp:124] Setting up clc-label_data_1_split
I0630 16:50:47.488451 28406 net.cpp:131] Top shape: 16 (16)
I0630 16:50:47.488456 28406 net.cpp:131] Top shape: 16 (16)
I0630 16:50:47.488461 28406 net.cpp:139] Memory required for data: 1769664
I0630 16:50:47.488468 28406 layer_factory.hpp:77] Creating layer conv1
I0630 16:50:47.488487 28406 net.cpp:86] Creating Layer conv1
I0630 16:50:47.488495 28406 net.cpp:408] conv1 <- data
I0630 16:50:47.488504 28406 net.cpp:382] conv1 -> conv1
I0630 16:50:47.491333 28406 net.cpp:124] Setting up conv1
I0630 16:50:47.491359 28406 net.cpp:131] Top shape: 16 32 48 48 (1179648)
I0630 16:50:47.491367 28406 net.cpp:139] Memory required for data: 6488256
I0630 16:50:47.491384 28406 layer_factory.hpp:77] Creating layer conv1/bn
I0630 16:50:47.491405 28406 net.cpp:86] Creating Layer conv1/bn
I0630 16:50:47.491415 28406 net.cpp:408] conv1/bn <- conv1
I0630 16:50:47.491430 28406 net.cpp:369] conv1/bn -> conv1 (in-place)
I0630 16:50:47.491698 28406 net.cpp:124] Setting up conv1/bn
I0630 16:50:47.491710 28406 net.cpp:131] Top shape: 16 32 48 48 (1179648)
I0630 16:50:47.491715 28406 net.cpp:139] Memory required for data: 11206848
I0630 16:50:47.491727 28406 layer_factory.hpp:77] Creating layer conv1/scale
I0630 16:50:47.491740 28406 net.cpp:86] Creating Layer conv1/scale
I0630 16:50:47.491746 28406 net.cpp:408] conv1/scale <- conv1
I0630 16:50:47.491752 28406 net.cpp:369] conv1/scale -> conv1 (in-place)
I0630 16:50:47.491801 28406 layer_factory.hpp:77] Creating layer conv1/scale
I0630 16:50:47.491919 28406 net.cpp:124] Setting up conv1/scale
I0630 16:50:47.491930 28406 net.cpp:131] Top shape: 16 32 48 48 (1179648)
I0630 16:50:47.491935 28406 net.cpp:139] Memory required for data: 15925440
I0630 16:50:47.491943 28406 layer_factory.hpp:77] Creating layer relu1
I0630 16:50:47.491950 28406 net.cpp:86] Creating Layer relu1
I0630 16:50:47.491956 28406 net.cpp:408] relu1 <- conv1
I0630 16:50:47.491962 28406 net.cpp:369] relu1 -> conv1 (in-place)
I0630 16:50:47.492431 28406 net.cpp:124] Setting up relu1
I0630 16:50:47.492444 28406 net.cpp:131] Top shape: 16 32 48 48 (1179648)
I0630 16:50:47.492449 28406 net.cpp:139] Memory required for data: 20644032
I0630 16:50:47.492452 28406 layer_factory.hpp:77] Creating layer conv2_1/dw
I0630 16:50:47.492462 28406 net.cpp:86] Creating Layer conv2_1/dw
I0630 16:50:47.492467 28406 net.cpp:408] conv2_1/dw <- conv1
I0630 16:50:47.492475 28406 net.cpp:382] conv2_1/dw -> conv2_1/dw
I0630 16:50:47.492681 28406 net.cpp:124] Setting up conv2_1/dw
I0630 16:50:47.492692 28406 net.cpp:131] Top shape: 16 32 48 48 (1179648)
I0630 16:50:47.492697 28406 net.cpp:139] Memory required for data: 25362624
I0630 16:50:47.492702 28406 layer_factory.hpp:77] Creating layer conv2_1/dw/bn
I0630 16:50:47.492709 28406 net.cpp:86] Creating Layer conv2_1/dw/bn
I0630 16:50:47.492713 28406 net.cpp:408] conv2_1/dw/bn <- conv2_1/dw
I0630 16:50:47.492719 28406 net.cpp:369] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0630 16:50:47.492933 28406 net.cpp:124] Setting up conv2_1/dw/bn
I0630 16:50:47.492944 28406 net.cpp:131] Top shape: 16 32 48 48 (1179648)
I0630 16:50:47.492949 28406 net.cpp:139] Memory required for data: 30081216
I0630 16:50:47.492959 28406 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0630 16:50:47.492969 28406 net.cpp:86] Creating Layer conv2_1/dw/scale
I0630 16:50:47.492987 28406 net.cpp:408] conv2_1/dw/scale <- conv2_1/dw
I0630 16:50:47.492995 28406 net.cpp:369] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0630 16:50:47.493038 28406 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0630 16:50:47.493152 28406 net.cpp:124] Setting up conv2_1/dw/scale
I0630 16:50:47.493161 28406 net.cpp:131] Top shape: 16 32 48 48 (1179648)
I0630 16:50:47.493166 28406 net.cpp:139] Memory required for data: 34799808
I0630 16:50:47.493173 28406 layer_factory.hpp:77] Creating layer relu2_1/dw
I0630 16:50:47.493180 28406 net.cpp:86] Creating Layer relu2_1/dw
I0630 16:50:47.493191 28406 net.cpp:408] relu2_1/dw <- conv2_1/dw
I0630 16:50:47.493197 28406 net.cpp:369] relu2_1/dw -> conv2_1/dw (in-place)
I0630 16:50:47.494079 28406 net.cpp:124] Setting up relu2_1/dw
I0630 16:50:47.494094 28406 net.cpp:131] Top shape: 16 32 48 48 (1179648)
I0630 16:50:47.494099 28406 net.cpp:139] Memory required for data: 39518400
I0630 16:50:47.494104 28406 layer_factory.hpp:77] Creating layer conv2_1/sep
I0630 16:50:47.494114 28406 net.cpp:86] Creating Layer conv2_1/sep
I0630 16:50:47.494119 28406 net.cpp:408] conv2_1/sep <- conv2_1/dw
I0630 16:50:47.494129 28406 net.cpp:382] conv2_1/sep -> conv2_1/sep
I0630 16:50:47.496112 28406 net.cpp:124] Setting up conv2_1/sep
I0630 16:50:47.496127 28406 net.cpp:131] Top shape: 16 64 48 48 (2359296)
I0630 16:50:47.496132 28406 net.cpp:139] Memory required for data: 48955584
I0630 16:50:47.496143 28406 layer_factory.hpp:77] Creating layer conv2_1/sep/bn
I0630 16:50:47.496157 28406 net.cpp:86] Creating Layer conv2_1/sep/bn
I0630 16:50:47.496165 28406 net.cpp:408] conv2_1/sep/bn <- conv2_1/sep
I0630 16:50:47.496174 28406 net.cpp:369] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0630 16:50:47.496399 28406 net.cpp:124] Setting up conv2_1/sep/bn
I0630 16:50:47.496409 28406 net.cpp:131] Top shape: 16 64 48 48 (2359296)
I0630 16:50:47.496414 28406 net.cpp:139] Memory required for data: 58392768
I0630 16:50:47.496428 28406 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0630 16:50:47.496439 28406 net.cpp:86] Creating Layer conv2_1/sep/scale
I0630 16:50:47.496448 28406 net.cpp:408] conv2_1/sep/scale <- conv2_1/sep
I0630 16:50:47.496457 28406 net.cpp:369] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0630 16:50:47.496510 28406 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0630 16:50:47.496628 28406 net.cpp:124] Setting up conv2_1/sep/scale
I0630 16:50:47.496637 28406 net.cpp:131] Top shape: 16 64 48 48 (2359296)
I0630 16:50:47.496641 28406 net.cpp:139] Memory required for data: 67829952
I0630 16:50:47.496657 28406 layer_factory.hpp:77] Creating layer relu2_1/sep
I0630 16:50:47.496666 28406 net.cpp:86] Creating Layer relu2_1/sep
I0630 16:50:47.496673 28406 net.cpp:408] relu2_1/sep <- conv2_1/sep
I0630 16:50:47.496682 28406 net.cpp:369] relu2_1/sep -> conv2_1/sep (in-place)
I0630 16:50:47.497129 28406 net.cpp:124] Setting up relu2_1/sep
I0630 16:50:47.497141 28406 net.cpp:131] Top shape: 16 64 48 48 (2359296)
I0630 16:50:47.497145 28406 net.cpp:139] Memory required for data: 77267136
I0630 16:50:47.497153 28406 layer_factory.hpp:77] Creating layer conv2_2/dw
I0630 16:50:47.497177 28406 net.cpp:86] Creating Layer conv2_2/dw
I0630 16:50:47.497193 28406 net.cpp:408] conv2_2/dw <- conv2_1/sep
I0630 16:50:47.497205 28406 net.cpp:382] conv2_2/dw -> conv2_2/dw
I0630 16:50:47.497442 28406 net.cpp:124] Setting up conv2_2/dw
I0630 16:50:47.497452 28406 net.cpp:131] Top shape: 16 64 24 24 (589824)
I0630 16:50:47.497457 28406 net.cpp:139] Memory required for data: 79626432
I0630 16:50:47.497472 28406 layer_factory.hpp:77] Creating layer conv2_2/dw/bn
I0630 16:50:47.497479 28406 net.cpp:86] Creating Layer conv2_2/dw/bn
I0630 16:50:47.497484 28406 net.cpp:408] conv2_2/dw/bn <- conv2_2/dw
I0630 16:50:47.497490 28406 net.cpp:369] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0630 16:50:47.497710 28406 net.cpp:124] Setting up conv2_2/dw/bn
I0630 16:50:47.497720 28406 net.cpp:131] Top shape: 16 64 24 24 (589824)
I0630 16:50:47.497725 28406 net.cpp:139] Memory required for data: 81985728
I0630 16:50:47.497754 28406 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0630 16:50:47.497766 28406 net.cpp:86] Creating Layer conv2_2/dw/scale
I0630 16:50:47.497771 28406 net.cpp:408] conv2_2/dw/scale <- conv2_2/dw
I0630 16:50:47.497778 28406 net.cpp:369] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0630 16:50:47.497820 28406 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0630 16:50:47.497938 28406 net.cpp:124] Setting up conv2_2/dw/scale
I0630 16:50:47.497947 28406 net.cpp:131] Top shape: 16 64 24 24 (589824)
I0630 16:50:47.497951 28406 net.cpp:139] Memory required for data: 84345024
I0630 16:50:47.497958 28406 layer_factory.hpp:77] Creating layer relu2_2/dw
I0630 16:50:47.497964 28406 net.cpp:86] Creating Layer relu2_2/dw
I0630 16:50:47.497968 28406 net.cpp:408] relu2_2/dw <- conv2_2/dw
I0630 16:50:47.497974 28406 net.cpp:369] relu2_2/dw -> conv2_2/dw (in-place)
I0630 16:50:47.498775 28406 net.cpp:124] Setting up relu2_2/dw
I0630 16:50:47.498787 28406 net.cpp:131] Top shape: 16 64 24 24 (589824)
I0630 16:50:47.498791 28406 net.cpp:139] Memory required for data: 86704320
I0630 16:50:47.498796 28406 layer_factory.hpp:77] Creating layer conv2_2/sep
I0630 16:50:47.498805 28406 net.cpp:86] Creating Layer conv2_2/sep
I0630 16:50:47.498811 28406 net.cpp:408] conv2_2/sep <- conv2_2/dw
I0630 16:50:47.498816 28406 net.cpp:382] conv2_2/sep -> conv2_2/sep
I0630 16:50:47.501116 28406 net.cpp:124] Setting up conv2_2/sep
I0630 16:50:47.501132 28406 net.cpp:131] Top shape: 16 128 24 24 (1179648)
I0630 16:50:47.501135 28406 net.cpp:139] Memory required for data: 91422912
I0630 16:50:47.501142 28406 layer_factory.hpp:77] Creating layer conv2_2/sep/bn
I0630 16:50:47.501149 28406 net.cpp:86] Creating Layer conv2_2/sep/bn
I0630 16:50:47.501154 28406 net.cpp:408] conv2_2/sep/bn <- conv2_2/sep
I0630 16:50:47.501168 28406 net.cpp:369] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0630 16:50:47.501400 28406 net.cpp:124] Setting up conv2_2/sep/bn
I0630 16:50:47.501411 28406 net.cpp:131] Top shape: 16 128 24 24 (1179648)
I0630 16:50:47.501415 28406 net.cpp:139] Memory required for data: 96141504
I0630 16:50:47.501425 28406 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0630 16:50:47.501432 28406 net.cpp:86] Creating Layer conv2_2/sep/scale
I0630 16:50:47.501436 28406 net.cpp:408] conv2_2/sep/scale <- conv2_2/sep
I0630 16:50:47.501442 28406 net.cpp:369] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0630 16:50:47.501484 28406 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0630 16:50:47.501597 28406 net.cpp:124] Setting up conv2_2/sep/scale
I0630 16:50:47.501606 28406 net.cpp:131] Top shape: 16 128 24 24 (1179648)
I0630 16:50:47.501610 28406 net.cpp:139] Memory required for data: 100860096
I0630 16:50:47.501617 28406 layer_factory.hpp:77] Creating layer relu2_2/sep
I0630 16:50:47.501623 28406 net.cpp:86] Creating Layer relu2_2/sep
I0630 16:50:47.501628 28406 net.cpp:408] relu2_2/sep <- conv2_2/sep
I0630 16:50:47.501633 28406 net.cpp:369] relu2_2/sep -> conv2_2/sep (in-place)
I0630 16:50:47.502446 28406 net.cpp:124] Setting up relu2_2/sep
I0630 16:50:47.502460 28406 net.cpp:131] Top shape: 16 128 24 24 (1179648)
I0630 16:50:47.502465 28406 net.cpp:139] Memory required for data: 105578688
I0630 16:50:47.502468 28406 layer_factory.hpp:77] Creating layer conv3_1/dw
I0630 16:50:47.502496 28406 net.cpp:86] Creating Layer conv3_1/dw
I0630 16:50:47.502504 28406 net.cpp:408] conv3_1/dw <- conv2_2/sep
I0630 16:50:47.502511 28406 net.cpp:382] conv3_1/dw -> conv3_1/dw
I0630 16:50:47.502713 28406 net.cpp:124] Setting up conv3_1/dw
I0630 16:50:47.502723 28406 net.cpp:131] Top shape: 16 128 24 24 (1179648)
I0630 16:50:47.502727 28406 net.cpp:139] Memory required for data: 110297280
I0630 16:50:47.502733 28406 layer_factory.hpp:77] Creating layer conv3_1/dw/bn
I0630 16:50:47.502740 28406 net.cpp:86] Creating Layer conv3_1/dw/bn
I0630 16:50:47.502744 28406 net.cpp:408] conv3_1/dw/bn <- conv3_1/dw
I0630 16:50:47.502750 28406 net.cpp:369] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0630 16:50:47.502933 28406 net.cpp:124] Setting up conv3_1/dw/bn
I0630 16:50:47.502954 28406 net.cpp:131] Top shape: 16 128 24 24 (1179648)
I0630 16:50:47.502957 28406 net.cpp:139] Memory required for data: 115015872
I0630 16:50:47.502969 28406 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0630 16:50:47.502979 28406 net.cpp:86] Creating Layer conv3_1/dw/scale
I0630 16:50:47.502982 28406 net.cpp:408] conv3_1/dw/scale <- conv3_1/dw
I0630 16:50:47.502988 28406 net.cpp:369] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0630 16:50:47.503032 28406 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0630 16:50:47.503170 28406 net.cpp:124] Setting up conv3_1/dw/scale
I0630 16:50:47.503180 28406 net.cpp:131] Top shape: 16 128 24 24 (1179648)
I0630 16:50:47.503185 28406 net.cpp:139] Memory required for data: 119734464
I0630 16:50:47.503191 28406 layer_factory.hpp:77] Creating layer relu3_1/dw
I0630 16:50:47.503197 28406 net.cpp:86] Creating Layer relu3_1/dw
I0630 16:50:47.503201 28406 net.cpp:408] relu3_1/dw <- conv3_1/dw
I0630 16:50:47.503207 28406 net.cpp:369] relu3_1/dw -> conv3_1/dw (in-place)
I0630 16:50:47.503624 28406 net.cpp:124] Setting up relu3_1/dw
I0630 16:50:47.503636 28406 net.cpp:131] Top shape: 16 128 24 24 (1179648)
I0630 16:50:47.503640 28406 net.cpp:139] Memory required for data: 124453056
I0630 16:50:47.503644 28406 layer_factory.hpp:77] Creating layer conv3_1/sep
I0630 16:50:47.503654 28406 net.cpp:86] Creating Layer conv3_1/sep
I0630 16:50:47.503657 28406 net.cpp:408] conv3_1/sep <- conv3_1/dw
I0630 16:50:47.503664 28406 net.cpp:382] conv3_1/sep -> conv3_1/sep
I0630 16:50:47.505965 28406 net.cpp:124] Setting up conv3_1/sep
I0630 16:50:47.505983 28406 net.cpp:131] Top shape: 16 128 24 24 (1179648)
I0630 16:50:47.505987 28406 net.cpp:139] Memory required for data: 129171648
I0630 16:50:47.506003 28406 layer_factory.hpp:77] Creating layer conv3_1/sep/bn
I0630 16:50:47.506014 28406 net.cpp:86] Creating Layer conv3_1/sep/bn
I0630 16:50:47.506021 28406 net.cpp:408] conv3_1/sep/bn <- conv3_1/sep
I0630 16:50:47.506045 28406 net.cpp:369] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0630 16:50:47.506289 28406 net.cpp:124] Setting up conv3_1/sep/bn
I0630 16:50:47.506300 28406 net.cpp:131] Top shape: 16 128 24 24 (1179648)
I0630 16:50:47.506304 28406 net.cpp:139] Memory required for data: 133890240
I0630 16:50:47.506321 28406 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0630 16:50:47.506340 28406 net.cpp:86] Creating Layer conv3_1/sep/scale
I0630 16:50:47.506355 28406 net.cpp:408] conv3_1/sep/scale <- conv3_1/sep
I0630 16:50:47.506368 28406 net.cpp:369] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0630 16:50:47.506431 28406 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0630 16:50:47.506557 28406 net.cpp:124] Setting up conv3_1/sep/scale
I0630 16:50:47.506567 28406 net.cpp:131] Top shape: 16 128 24 24 (1179648)
I0630 16:50:47.506572 28406 net.cpp:139] Memory required for data: 138608832
I0630 16:50:47.506578 28406 layer_factory.hpp:77] Creating layer relu3_1/sep
I0630 16:50:47.506585 28406 net.cpp:86] Creating Layer relu3_1/sep
I0630 16:50:47.506589 28406 net.cpp:408] relu3_1/sep <- conv3_1/sep
I0630 16:50:47.506595 28406 net.cpp:369] relu3_1/sep -> conv3_1/sep (in-place)
I0630 16:50:47.507463 28406 net.cpp:124] Setting up relu3_1/sep
I0630 16:50:47.507477 28406 net.cpp:131] Top shape: 16 128 24 24 (1179648)
I0630 16:50:47.507480 28406 net.cpp:139] Memory required for data: 143327424
I0630 16:50:47.507485 28406 layer_factory.hpp:77] Creating layer conv3_2/dw
I0630 16:50:47.507495 28406 net.cpp:86] Creating Layer conv3_2/dw
I0630 16:50:47.507500 28406 net.cpp:408] conv3_2/dw <- conv3_1/sep
I0630 16:50:47.507508 28406 net.cpp:382] conv3_2/dw -> conv3_2/dw
I0630 16:50:47.507731 28406 net.cpp:124] Setting up conv3_2/dw
I0630 16:50:47.507742 28406 net.cpp:131] Top shape: 16 128 12 12 (294912)
I0630 16:50:47.507746 28406 net.cpp:139] Memory required for data: 144507072
I0630 16:50:47.507752 28406 layer_factory.hpp:77] Creating layer conv3_2/dw/bn
I0630 16:50:47.507760 28406 net.cpp:86] Creating Layer conv3_2/dw/bn
I0630 16:50:47.507764 28406 net.cpp:408] conv3_2/dw/bn <- conv3_2/dw
I0630 16:50:47.507783 28406 net.cpp:369] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0630 16:50:47.507992 28406 net.cpp:124] Setting up conv3_2/dw/bn
I0630 16:50:47.508002 28406 net.cpp:131] Top shape: 16 128 12 12 (294912)
I0630 16:50:47.508006 28406 net.cpp:139] Memory required for data: 145686720
I0630 16:50:47.508015 28406 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0630 16:50:47.508028 28406 net.cpp:86] Creating Layer conv3_2/dw/scale
I0630 16:50:47.508033 28406 net.cpp:408] conv3_2/dw/scale <- conv3_2/dw
I0630 16:50:47.508039 28406 net.cpp:369] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0630 16:50:47.508081 28406 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0630 16:50:47.508193 28406 net.cpp:124] Setting up conv3_2/dw/scale
I0630 16:50:47.508203 28406 net.cpp:131] Top shape: 16 128 12 12 (294912)
I0630 16:50:47.508206 28406 net.cpp:139] Memory required for data: 146866368
I0630 16:50:47.508213 28406 layer_factory.hpp:77] Creating layer relu3_2/dw
I0630 16:50:47.508219 28406 net.cpp:86] Creating Layer relu3_2/dw
I0630 16:50:47.508224 28406 net.cpp:408] relu3_2/dw <- conv3_2/dw
I0630 16:50:47.508229 28406 net.cpp:369] relu3_2/dw -> conv3_2/dw (in-place)
I0630 16:50:47.508680 28406 net.cpp:124] Setting up relu3_2/dw
I0630 16:50:47.508692 28406 net.cpp:131] Top shape: 16 128 12 12 (294912)
I0630 16:50:47.508697 28406 net.cpp:139] Memory required for data: 148046016
I0630 16:50:47.508702 28406 layer_factory.hpp:77] Creating layer conv3_2/sep
I0630 16:50:47.508710 28406 net.cpp:86] Creating Layer conv3_2/sep
I0630 16:50:47.508714 28406 net.cpp:408] conv3_2/sep <- conv3_2/dw
I0630 16:50:47.508721 28406 net.cpp:382] conv3_2/sep -> conv3_2/sep
I0630 16:50:47.511458 28406 net.cpp:124] Setting up conv3_2/sep
I0630 16:50:47.511476 28406 net.cpp:131] Top shape: 16 256 12 12 (589824)
I0630 16:50:47.511482 28406 net.cpp:139] Memory required for data: 150405312
I0630 16:50:47.511488 28406 layer_factory.hpp:77] Creating layer conv3_2/sep/bn
I0630 16:50:47.511497 28406 net.cpp:86] Creating Layer conv3_2/sep/bn
I0630 16:50:47.511502 28406 net.cpp:408] conv3_2/sep/bn <- conv3_2/sep
I0630 16:50:47.511509 28406 net.cpp:369] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0630 16:50:47.511703 28406 net.cpp:124] Setting up conv3_2/sep/bn
I0630 16:50:47.511713 28406 net.cpp:131] Top shape: 16 256 12 12 (589824)
I0630 16:50:47.511718 28406 net.cpp:139] Memory required for data: 152764608
I0630 16:50:47.511726 28406 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0630 16:50:47.511734 28406 net.cpp:86] Creating Layer conv3_2/sep/scale
I0630 16:50:47.511740 28406 net.cpp:408] conv3_2/sep/scale <- conv3_2/sep
I0630 16:50:47.511746 28406 net.cpp:369] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0630 16:50:47.511790 28406 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0630 16:50:47.511904 28406 net.cpp:124] Setting up conv3_2/sep/scale
I0630 16:50:47.511921 28406 net.cpp:131] Top shape: 16 256 12 12 (589824)
I0630 16:50:47.511934 28406 net.cpp:139] Memory required for data: 155123904
I0630 16:50:47.511941 28406 layer_factory.hpp:77] Creating layer relu3_2/sep
I0630 16:50:47.511948 28406 net.cpp:86] Creating Layer relu3_2/sep
I0630 16:50:47.511953 28406 net.cpp:408] relu3_2/sep <- conv3_2/sep
I0630 16:50:47.511958 28406 net.cpp:369] relu3_2/sep -> conv3_2/sep (in-place)
I0630 16:50:47.512820 28406 net.cpp:124] Setting up relu3_2/sep
I0630 16:50:47.512832 28406 net.cpp:131] Top shape: 16 256 12 12 (589824)
I0630 16:50:47.512837 28406 net.cpp:139] Memory required for data: 157483200
I0630 16:50:47.512841 28406 layer_factory.hpp:77] Creating layer conv4_1/dw
I0630 16:50:47.512852 28406 net.cpp:86] Creating Layer conv4_1/dw
I0630 16:50:47.512857 28406 net.cpp:408] conv4_1/dw <- conv3_2/sep
I0630 16:50:47.512864 28406 net.cpp:382] conv4_1/dw -> conv4_1/dw
I0630 16:50:47.513094 28406 net.cpp:124] Setting up conv4_1/dw
I0630 16:50:47.513104 28406 net.cpp:131] Top shape: 16 256 12 12 (589824)
I0630 16:50:47.513109 28406 net.cpp:139] Memory required for data: 159842496
I0630 16:50:47.513115 28406 layer_factory.hpp:77] Creating layer conv4_1/dw/bn
I0630 16:50:47.513154 28406 net.cpp:86] Creating Layer conv4_1/dw/bn
I0630 16:50:47.513161 28406 net.cpp:408] conv4_1/dw/bn <- conv4_1/dw
I0630 16:50:47.513168 28406 net.cpp:369] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0630 16:50:47.513373 28406 net.cpp:124] Setting up conv4_1/dw/bn
I0630 16:50:47.513384 28406 net.cpp:131] Top shape: 16 256 12 12 (589824)
I0630 16:50:47.513389 28406 net.cpp:139] Memory required for data: 162201792
I0630 16:50:47.513397 28406 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0630 16:50:47.513406 28406 net.cpp:86] Creating Layer conv4_1/dw/scale
I0630 16:50:47.513411 28406 net.cpp:408] conv4_1/dw/scale <- conv4_1/dw
I0630 16:50:47.513417 28406 net.cpp:369] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0630 16:50:47.513458 28406 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0630 16:50:47.513571 28406 net.cpp:124] Setting up conv4_1/dw/scale
I0630 16:50:47.513579 28406 net.cpp:131] Top shape: 16 256 12 12 (589824)
I0630 16:50:47.513597 28406 net.cpp:139] Memory required for data: 164561088
I0630 16:50:47.513604 28406 layer_factory.hpp:77] Creating layer relu4_1/dw
I0630 16:50:47.513610 28406 net.cpp:86] Creating Layer relu4_1/dw
I0630 16:50:47.513614 28406 net.cpp:408] relu4_1/dw <- conv4_1/dw
I0630 16:50:47.513620 28406 net.cpp:369] relu4_1/dw -> conv4_1/dw (in-place)
I0630 16:50:47.514076 28406 net.cpp:124] Setting up relu4_1/dw
I0630 16:50:47.514088 28406 net.cpp:131] Top shape: 16 256 12 12 (589824)
I0630 16:50:47.514093 28406 net.cpp:139] Memory required for data: 166920384
I0630 16:50:47.514097 28406 layer_factory.hpp:77] Creating layer conv4_1/sep
I0630 16:50:47.514106 28406 net.cpp:86] Creating Layer conv4_1/sep
I0630 16:50:47.514111 28406 net.cpp:408] conv4_1/sep <- conv4_1/dw
I0630 16:50:47.514127 28406 net.cpp:382] conv4_1/sep -> conv4_1/sep
I0630 16:50:47.516799 28406 net.cpp:124] Setting up conv4_1/sep
I0630 16:50:47.516813 28406 net.cpp:131] Top shape: 16 256 12 12 (589824)
I0630 16:50:47.516819 28406 net.cpp:139] Memory required for data: 169279680
I0630 16:50:47.516825 28406 layer_factory.hpp:77] Creating layer conv4_1/sep/bn
I0630 16:50:47.516834 28406 net.cpp:86] Creating Layer conv4_1/sep/bn
I0630 16:50:47.516839 28406 net.cpp:408] conv4_1/sep/bn <- conv4_1/sep
I0630 16:50:47.516845 28406 net.cpp:369] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0630 16:50:47.517061 28406 net.cpp:124] Setting up conv4_1/sep/bn
I0630 16:50:47.517071 28406 net.cpp:131] Top shape: 16 256 12 12 (589824)
I0630 16:50:47.517076 28406 net.cpp:139] Memory required for data: 171638976
I0630 16:50:47.517086 28406 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0630 16:50:47.517092 28406 net.cpp:86] Creating Layer conv4_1/sep/scale
I0630 16:50:47.517099 28406 net.cpp:408] conv4_1/sep/scale <- conv4_1/sep
I0630 16:50:47.517105 28406 net.cpp:369] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0630 16:50:47.517148 28406 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0630 16:50:47.517287 28406 net.cpp:124] Setting up conv4_1/sep/scale
I0630 16:50:47.517297 28406 net.cpp:131] Top shape: 16 256 12 12 (589824)
I0630 16:50:47.517302 28406 net.cpp:139] Memory required for data: 173998272
I0630 16:50:47.517315 28406 layer_factory.hpp:77] Creating layer relu4_1/sep
I0630 16:50:47.517323 28406 net.cpp:86] Creating Layer relu4_1/sep
I0630 16:50:47.517328 28406 net.cpp:408] relu4_1/sep <- conv4_1/sep
I0630 16:50:47.517333 28406 net.cpp:369] relu4_1/sep -> conv4_1/sep (in-place)
I0630 16:50:47.518132 28406 net.cpp:124] Setting up relu4_1/sep
I0630 16:50:47.518144 28406 net.cpp:131] Top shape: 16 256 12 12 (589824)
I0630 16:50:47.518149 28406 net.cpp:139] Memory required for data: 176357568
I0630 16:50:47.518153 28406 layer_factory.hpp:77] Creating layer conv4_2/dw
I0630 16:50:47.518163 28406 net.cpp:86] Creating Layer conv4_2/dw
I0630 16:50:47.518168 28406 net.cpp:408] conv4_2/dw <- conv4_1/sep
I0630 16:50:47.518174 28406 net.cpp:382] conv4_2/dw -> conv4_2/dw
I0630 16:50:47.518394 28406 net.cpp:124] Setting up conv4_2/dw
I0630 16:50:47.518415 28406 net.cpp:131] Top shape: 16 256 6 6 (147456)
I0630 16:50:47.518420 28406 net.cpp:139] Memory required for data: 176947392
I0630 16:50:47.518426 28406 layer_factory.hpp:77] Creating layer conv4_2/dw/bn
I0630 16:50:47.518434 28406 net.cpp:86] Creating Layer conv4_2/dw/bn
I0630 16:50:47.518438 28406 net.cpp:408] conv4_2/dw/bn <- conv4_2/dw
I0630 16:50:47.518445 28406 net.cpp:369] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0630 16:50:47.518636 28406 net.cpp:124] Setting up conv4_2/dw/bn
I0630 16:50:47.518646 28406 net.cpp:131] Top shape: 16 256 6 6 (147456)
I0630 16:50:47.518649 28406 net.cpp:139] Memory required for data: 177537216
I0630 16:50:47.518658 28406 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0630 16:50:47.518666 28406 net.cpp:86] Creating Layer conv4_2/dw/scale
I0630 16:50:47.518689 28406 net.cpp:408] conv4_2/dw/scale <- conv4_2/dw
I0630 16:50:47.518698 28406 net.cpp:369] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0630 16:50:47.518741 28406 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0630 16:50:47.518851 28406 net.cpp:124] Setting up conv4_2/dw/scale
I0630 16:50:47.518860 28406 net.cpp:131] Top shape: 16 256 6 6 (147456)
I0630 16:50:47.518864 28406 net.cpp:139] Memory required for data: 178127040
I0630 16:50:47.518872 28406 layer_factory.hpp:77] Creating layer relu4_2/dw
I0630 16:50:47.518877 28406 net.cpp:86] Creating Layer relu4_2/dw
I0630 16:50:47.518882 28406 net.cpp:408] relu4_2/dw <- conv4_2/dw
I0630 16:50:47.518887 28406 net.cpp:369] relu4_2/dw -> conv4_2/dw (in-place)
I0630 16:50:47.519363 28406 net.cpp:124] Setting up relu4_2/dw
I0630 16:50:47.519374 28406 net.cpp:131] Top shape: 16 256 6 6 (147456)
I0630 16:50:47.519379 28406 net.cpp:139] Memory required for data: 178716864
I0630 16:50:47.519383 28406 layer_factory.hpp:77] Creating layer conv4_2/sep
I0630 16:50:47.519393 28406 net.cpp:86] Creating Layer conv4_2/sep
I0630 16:50:47.519398 28406 net.cpp:408] conv4_2/sep <- conv4_2/dw
I0630 16:50:47.519407 28406 net.cpp:382] conv4_2/sep -> conv4_2/sep
I0630 16:50:47.523133 28406 net.cpp:124] Setting up conv4_2/sep
I0630 16:50:47.523149 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.523154 28406 net.cpp:139] Memory required for data: 179896512
I0630 16:50:47.523160 28406 layer_factory.hpp:77] Creating layer conv4_2/sep/bn
I0630 16:50:47.523176 28406 net.cpp:86] Creating Layer conv4_2/sep/bn
I0630 16:50:47.523182 28406 net.cpp:408] conv4_2/sep/bn <- conv4_2/sep
I0630 16:50:47.523190 28406 net.cpp:369] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0630 16:50:47.523427 28406 net.cpp:124] Setting up conv4_2/sep/bn
I0630 16:50:47.523437 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.523442 28406 net.cpp:139] Memory required for data: 181076160
I0630 16:50:47.523452 28406 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0630 16:50:47.523458 28406 net.cpp:86] Creating Layer conv4_2/sep/scale
I0630 16:50:47.523468 28406 net.cpp:408] conv4_2/sep/scale <- conv4_2/sep
I0630 16:50:47.523474 28406 net.cpp:369] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0630 16:50:47.523515 28406 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0630 16:50:47.523633 28406 net.cpp:124] Setting up conv4_2/sep/scale
I0630 16:50:47.523643 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.523648 28406 net.cpp:139] Memory required for data: 182255808
I0630 16:50:47.523653 28406 layer_factory.hpp:77] Creating layer relu4_2/sep
I0630 16:50:47.523660 28406 net.cpp:86] Creating Layer relu4_2/sep
I0630 16:50:47.523664 28406 net.cpp:408] relu4_2/sep <- conv4_2/sep
I0630 16:50:47.523670 28406 net.cpp:369] relu4_2/sep -> conv4_2/sep (in-place)
I0630 16:50:47.524113 28406 net.cpp:124] Setting up relu4_2/sep
I0630 16:50:47.524125 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.524129 28406 net.cpp:139] Memory required for data: 183435456
I0630 16:50:47.524133 28406 layer_factory.hpp:77] Creating layer conv5_1/dw
I0630 16:50:47.524142 28406 net.cpp:86] Creating Layer conv5_1/dw
I0630 16:50:47.524147 28406 net.cpp:408] conv5_1/dw <- conv4_2/sep
I0630 16:50:47.524168 28406 net.cpp:382] conv5_1/dw -> conv5_1/dw
I0630 16:50:47.524416 28406 net.cpp:124] Setting up conv5_1/dw
I0630 16:50:47.524427 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.524431 28406 net.cpp:139] Memory required for data: 184615104
I0630 16:50:47.524436 28406 layer_factory.hpp:77] Creating layer conv5_1/dw/bn
I0630 16:50:47.524446 28406 net.cpp:86] Creating Layer conv5_1/dw/bn
I0630 16:50:47.524451 28406 net.cpp:408] conv5_1/dw/bn <- conv5_1/dw
I0630 16:50:47.524456 28406 net.cpp:369] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0630 16:50:47.524668 28406 net.cpp:124] Setting up conv5_1/dw/bn
I0630 16:50:47.524678 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.524682 28406 net.cpp:139] Memory required for data: 185794752
I0630 16:50:47.524691 28406 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0630 16:50:47.524698 28406 net.cpp:86] Creating Layer conv5_1/dw/scale
I0630 16:50:47.524703 28406 net.cpp:408] conv5_1/dw/scale <- conv5_1/dw
I0630 16:50:47.524708 28406 net.cpp:369] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0630 16:50:47.524749 28406 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0630 16:50:47.524864 28406 net.cpp:124] Setting up conv5_1/dw/scale
I0630 16:50:47.524873 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.524878 28406 net.cpp:139] Memory required for data: 186974400
I0630 16:50:47.524884 28406 layer_factory.hpp:77] Creating layer relu5_1/dw
I0630 16:50:47.524890 28406 net.cpp:86] Creating Layer relu5_1/dw
I0630 16:50:47.524894 28406 net.cpp:408] relu5_1/dw <- conv5_1/dw
I0630 16:50:47.524900 28406 net.cpp:369] relu5_1/dw -> conv5_1/dw (in-place)
I0630 16:50:47.525514 28406 net.cpp:124] Setting up relu5_1/dw
I0630 16:50:47.525527 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.525530 28406 net.cpp:139] Memory required for data: 188154048
I0630 16:50:47.525534 28406 layer_factory.hpp:77] Creating layer conv5_1/sep
I0630 16:50:47.525543 28406 net.cpp:86] Creating Layer conv5_1/sep
I0630 16:50:47.525548 28406 net.cpp:408] conv5_1/sep <- conv5_1/dw
I0630 16:50:47.525554 28406 net.cpp:382] conv5_1/sep -> conv5_1/sep
I0630 16:50:47.531491 28406 net.cpp:124] Setting up conv5_1/sep
I0630 16:50:47.531510 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.531515 28406 net.cpp:139] Memory required for data: 189333696
I0630 16:50:47.531522 28406 layer_factory.hpp:77] Creating layer conv5_1/sep/bn
I0630 16:50:47.531533 28406 net.cpp:86] Creating Layer conv5_1/sep/bn
I0630 16:50:47.531539 28406 net.cpp:408] conv5_1/sep/bn <- conv5_1/sep
I0630 16:50:47.531548 28406 net.cpp:369] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0630 16:50:47.531749 28406 net.cpp:124] Setting up conv5_1/sep/bn
I0630 16:50:47.531759 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.531764 28406 net.cpp:139] Memory required for data: 190513344
I0630 16:50:47.531771 28406 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0630 16:50:47.531780 28406 net.cpp:86] Creating Layer conv5_1/sep/scale
I0630 16:50:47.531785 28406 net.cpp:408] conv5_1/sep/scale <- conv5_1/sep
I0630 16:50:47.531791 28406 net.cpp:369] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0630 16:50:47.531836 28406 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0630 16:50:47.531955 28406 net.cpp:124] Setting up conv5_1/sep/scale
I0630 16:50:47.531963 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.531967 28406 net.cpp:139] Memory required for data: 191692992
I0630 16:50:47.531975 28406 layer_factory.hpp:77] Creating layer relu5_1/sep
I0630 16:50:47.531981 28406 net.cpp:86] Creating Layer relu5_1/sep
I0630 16:50:47.531987 28406 net.cpp:408] relu5_1/sep <- conv5_1/sep
I0630 16:50:47.531993 28406 net.cpp:369] relu5_1/sep -> conv5_1/sep (in-place)
I0630 16:50:47.532416 28406 net.cpp:124] Setting up relu5_1/sep
I0630 16:50:47.532428 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.532431 28406 net.cpp:139] Memory required for data: 192872640
I0630 16:50:47.532435 28406 layer_factory.hpp:77] Creating layer conv5_2/dw
I0630 16:50:47.532459 28406 net.cpp:86] Creating Layer conv5_2/dw
I0630 16:50:47.532464 28406 net.cpp:408] conv5_2/dw <- conv5_1/sep
I0630 16:50:47.532471 28406 net.cpp:382] conv5_2/dw -> conv5_2/dw
I0630 16:50:47.532721 28406 net.cpp:124] Setting up conv5_2/dw
I0630 16:50:47.532732 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.532735 28406 net.cpp:139] Memory required for data: 194052288
I0630 16:50:47.532742 28406 layer_factory.hpp:77] Creating layer conv5_2/dw/bn
I0630 16:50:47.532749 28406 net.cpp:86] Creating Layer conv5_2/dw/bn
I0630 16:50:47.532754 28406 net.cpp:408] conv5_2/dw/bn <- conv5_2/dw
I0630 16:50:47.532760 28406 net.cpp:369] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0630 16:50:47.532953 28406 net.cpp:124] Setting up conv5_2/dw/bn
I0630 16:50:47.532963 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.532968 28406 net.cpp:139] Memory required for data: 195231936
I0630 16:50:47.532975 28406 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0630 16:50:47.532989 28406 net.cpp:86] Creating Layer conv5_2/dw/scale
I0630 16:50:47.532995 28406 net.cpp:408] conv5_2/dw/scale <- conv5_2/dw
I0630 16:50:47.533001 28406 net.cpp:369] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0630 16:50:47.533041 28406 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0630 16:50:47.533166 28406 net.cpp:124] Setting up conv5_2/dw/scale
I0630 16:50:47.533176 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.533180 28406 net.cpp:139] Memory required for data: 196411584
I0630 16:50:47.533196 28406 layer_factory.hpp:77] Creating layer relu5_2/dw
I0630 16:50:47.533205 28406 net.cpp:86] Creating Layer relu5_2/dw
I0630 16:50:47.533210 28406 net.cpp:408] relu5_2/dw <- conv5_2/dw
I0630 16:50:47.533215 28406 net.cpp:369] relu5_2/dw -> conv5_2/dw (in-place)
I0630 16:50:47.533648 28406 net.cpp:124] Setting up relu5_2/dw
I0630 16:50:47.533659 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.533663 28406 net.cpp:139] Memory required for data: 197591232
I0630 16:50:47.533676 28406 layer_factory.hpp:77] Creating layer conv5_2/sep
I0630 16:50:47.533684 28406 net.cpp:86] Creating Layer conv5_2/sep
I0630 16:50:47.533689 28406 net.cpp:408] conv5_2/sep <- conv5_2/dw
I0630 16:50:47.533704 28406 net.cpp:382] conv5_2/sep -> conv5_2/sep
I0630 16:50:47.538520 28406 net.cpp:124] Setting up conv5_2/sep
I0630 16:50:47.538535 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.538540 28406 net.cpp:139] Memory required for data: 198770880
I0630 16:50:47.538555 28406 layer_factory.hpp:77] Creating layer conv5_2/sep/bn
I0630 16:50:47.538563 28406 net.cpp:86] Creating Layer conv5_2/sep/bn
I0630 16:50:47.538568 28406 net.cpp:408] conv5_2/sep/bn <- conv5_2/sep
I0630 16:50:47.538581 28406 net.cpp:369] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0630 16:50:47.538794 28406 net.cpp:124] Setting up conv5_2/sep/bn
I0630 16:50:47.538803 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.538807 28406 net.cpp:139] Memory required for data: 199950528
I0630 16:50:47.538825 28406 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0630 16:50:47.538832 28406 net.cpp:86] Creating Layer conv5_2/sep/scale
I0630 16:50:47.538836 28406 net.cpp:408] conv5_2/sep/scale <- conv5_2/sep
I0630 16:50:47.538851 28406 net.cpp:369] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0630 16:50:47.538909 28406 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0630 16:50:47.539062 28406 net.cpp:124] Setting up conv5_2/sep/scale
I0630 16:50:47.539072 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.539075 28406 net.cpp:139] Memory required for data: 201130176
I0630 16:50:47.539090 28406 layer_factory.hpp:77] Creating layer relu5_2/sep
I0630 16:50:47.539096 28406 net.cpp:86] Creating Layer relu5_2/sep
I0630 16:50:47.539101 28406 net.cpp:408] relu5_2/sep <- conv5_2/sep
I0630 16:50:47.539106 28406 net.cpp:369] relu5_2/sep -> conv5_2/sep (in-place)
I0630 16:50:47.539598 28406 net.cpp:124] Setting up relu5_2/sep
I0630 16:50:47.539618 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.539635 28406 net.cpp:139] Memory required for data: 202309824
I0630 16:50:47.539641 28406 layer_factory.hpp:77] Creating layer conv5_3/dw
I0630 16:50:47.539655 28406 net.cpp:86] Creating Layer conv5_3/dw
I0630 16:50:47.539669 28406 net.cpp:408] conv5_3/dw <- conv5_2/sep
I0630 16:50:47.539682 28406 net.cpp:382] conv5_3/dw -> conv5_3/dw
I0630 16:50:47.540050 28406 net.cpp:124] Setting up conv5_3/dw
I0630 16:50:47.540061 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.540066 28406 net.cpp:139] Memory required for data: 203489472
I0630 16:50:47.540071 28406 layer_factory.hpp:77] Creating layer conv5_3/dw/bn
I0630 16:50:47.540079 28406 net.cpp:86] Creating Layer conv5_3/dw/bn
I0630 16:50:47.540083 28406 net.cpp:408] conv5_3/dw/bn <- conv5_3/dw
I0630 16:50:47.540089 28406 net.cpp:369] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0630 16:50:47.540290 28406 net.cpp:124] Setting up conv5_3/dw/bn
I0630 16:50:47.540300 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.540304 28406 net.cpp:139] Memory required for data: 204669120
I0630 16:50:47.540313 28406 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0630 16:50:47.540320 28406 net.cpp:86] Creating Layer conv5_3/dw/scale
I0630 16:50:47.540324 28406 net.cpp:408] conv5_3/dw/scale <- conv5_3/dw
I0630 16:50:47.540330 28406 net.cpp:369] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0630 16:50:47.540379 28406 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0630 16:50:47.540503 28406 net.cpp:124] Setting up conv5_3/dw/scale
I0630 16:50:47.540513 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.540518 28406 net.cpp:139] Memory required for data: 205848768
I0630 16:50:47.540524 28406 layer_factory.hpp:77] Creating layer relu5_3/dw
I0630 16:50:47.540530 28406 net.cpp:86] Creating Layer relu5_3/dw
I0630 16:50:47.540534 28406 net.cpp:408] relu5_3/dw <- conv5_3/dw
I0630 16:50:47.540539 28406 net.cpp:369] relu5_3/dw -> conv5_3/dw (in-place)
I0630 16:50:47.541399 28406 net.cpp:124] Setting up relu5_3/dw
I0630 16:50:47.541412 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.541417 28406 net.cpp:139] Memory required for data: 207028416
I0630 16:50:47.541421 28406 layer_factory.hpp:77] Creating layer conv5_3/sep
I0630 16:50:47.541430 28406 net.cpp:86] Creating Layer conv5_3/sep
I0630 16:50:47.541437 28406 net.cpp:408] conv5_3/sep <- conv5_3/dw
I0630 16:50:47.541450 28406 net.cpp:382] conv5_3/sep -> conv5_3/sep
I0630 16:50:47.546942 28406 net.cpp:124] Setting up conv5_3/sep
I0630 16:50:47.546972 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.546977 28406 net.cpp:139] Memory required for data: 208208064
I0630 16:50:47.546989 28406 layer_factory.hpp:77] Creating layer conv5_3/sep/bn
I0630 16:50:47.547013 28406 net.cpp:86] Creating Layer conv5_3/sep/bn
I0630 16:50:47.547020 28406 net.cpp:408] conv5_3/sep/bn <- conv5_3/sep
I0630 16:50:47.547045 28406 net.cpp:369] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0630 16:50:47.547271 28406 net.cpp:124] Setting up conv5_3/sep/bn
I0630 16:50:47.547288 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.547293 28406 net.cpp:139] Memory required for data: 209387712
I0630 16:50:47.547302 28406 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0630 16:50:47.547312 28406 net.cpp:86] Creating Layer conv5_3/sep/scale
I0630 16:50:47.547320 28406 net.cpp:408] conv5_3/sep/scale <- conv5_3/sep
I0630 16:50:47.547338 28406 net.cpp:369] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0630 16:50:47.547400 28406 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0630 16:50:47.547564 28406 net.cpp:124] Setting up conv5_3/sep/scale
I0630 16:50:47.547580 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.547592 28406 net.cpp:139] Memory required for data: 210567360
I0630 16:50:47.547600 28406 layer_factory.hpp:77] Creating layer relu5_3/sep
I0630 16:50:47.547606 28406 net.cpp:86] Creating Layer relu5_3/sep
I0630 16:50:47.547612 28406 net.cpp:408] relu5_3/sep <- conv5_3/sep
I0630 16:50:47.547631 28406 net.cpp:369] relu5_3/sep -> conv5_3/sep (in-place)
I0630 16:50:47.548122 28406 net.cpp:124] Setting up relu5_3/sep
I0630 16:50:47.548133 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.548138 28406 net.cpp:139] Memory required for data: 211747008
I0630 16:50:47.548142 28406 layer_factory.hpp:77] Creating layer conv5_4/dw
I0630 16:50:47.548152 28406 net.cpp:86] Creating Layer conv5_4/dw
I0630 16:50:47.548156 28406 net.cpp:408] conv5_4/dw <- conv5_3/sep
I0630 16:50:47.548164 28406 net.cpp:382] conv5_4/dw -> conv5_4/dw
I0630 16:50:47.548424 28406 net.cpp:124] Setting up conv5_4/dw
I0630 16:50:47.548434 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.548439 28406 net.cpp:139] Memory required for data: 212926656
I0630 16:50:47.548444 28406 layer_factory.hpp:77] Creating layer conv5_4/dw/bn
I0630 16:50:47.548451 28406 net.cpp:86] Creating Layer conv5_4/dw/bn
I0630 16:50:47.548455 28406 net.cpp:408] conv5_4/dw/bn <- conv5_4/dw
I0630 16:50:47.548461 28406 net.cpp:369] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0630 16:50:47.548661 28406 net.cpp:124] Setting up conv5_4/dw/bn
I0630 16:50:47.548672 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.548676 28406 net.cpp:139] Memory required for data: 214106304
I0630 16:50:47.548684 28406 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0630 16:50:47.548691 28406 net.cpp:86] Creating Layer conv5_4/dw/scale
I0630 16:50:47.548696 28406 net.cpp:408] conv5_4/dw/scale <- conv5_4/dw
I0630 16:50:47.548702 28406 net.cpp:369] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0630 16:50:47.548749 28406 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0630 16:50:47.548877 28406 net.cpp:124] Setting up conv5_4/dw/scale
I0630 16:50:47.548887 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.548892 28406 net.cpp:139] Memory required for data: 215285952
I0630 16:50:47.548897 28406 layer_factory.hpp:77] Creating layer relu5_4/dw
I0630 16:50:47.548903 28406 net.cpp:86] Creating Layer relu5_4/dw
I0630 16:50:47.548909 28406 net.cpp:408] relu5_4/dw <- conv5_4/dw
I0630 16:50:47.548919 28406 net.cpp:369] relu5_4/dw -> conv5_4/dw (in-place)
I0630 16:50:47.549696 28406 net.cpp:124] Setting up relu5_4/dw
I0630 16:50:47.549710 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.549713 28406 net.cpp:139] Memory required for data: 216465600
I0630 16:50:47.549718 28406 layer_factory.hpp:77] Creating layer conv5_4/sep
I0630 16:50:47.549726 28406 net.cpp:86] Creating Layer conv5_4/sep
I0630 16:50:47.549732 28406 net.cpp:408] conv5_4/sep <- conv5_4/dw
I0630 16:50:47.549744 28406 net.cpp:382] conv5_4/sep -> conv5_4/sep
I0630 16:50:47.554301 28406 net.cpp:124] Setting up conv5_4/sep
I0630 16:50:47.554323 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.554328 28406 net.cpp:139] Memory required for data: 217645248
I0630 16:50:47.554338 28406 layer_factory.hpp:77] Creating layer conv5_4/sep/bn
I0630 16:50:47.554358 28406 net.cpp:86] Creating Layer conv5_4/sep/bn
I0630 16:50:47.554365 28406 net.cpp:408] conv5_4/sep/bn <- conv5_4/sep
I0630 16:50:47.554378 28406 net.cpp:369] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0630 16:50:47.554594 28406 net.cpp:124] Setting up conv5_4/sep/bn
I0630 16:50:47.554611 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.554616 28406 net.cpp:139] Memory required for data: 218824896
I0630 16:50:47.554628 28406 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0630 16:50:47.554647 28406 net.cpp:86] Creating Layer conv5_4/sep/scale
I0630 16:50:47.554669 28406 net.cpp:408] conv5_4/sep/scale <- conv5_4/sep
I0630 16:50:47.554677 28406 net.cpp:369] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0630 16:50:47.554734 28406 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0630 16:50:47.554901 28406 net.cpp:124] Setting up conv5_4/sep/scale
I0630 16:50:47.554919 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.554924 28406 net.cpp:139] Memory required for data: 220004544
I0630 16:50:47.554934 28406 layer_factory.hpp:77] Creating layer relu5_4/sep
I0630 16:50:47.554951 28406 net.cpp:86] Creating Layer relu5_4/sep
I0630 16:50:47.554970 28406 net.cpp:408] relu5_4/sep <- conv5_4/sep
I0630 16:50:47.554980 28406 net.cpp:369] relu5_4/sep -> conv5_4/sep (in-place)
I0630 16:50:47.555737 28406 net.cpp:124] Setting up relu5_4/sep
I0630 16:50:47.555749 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.555753 28406 net.cpp:139] Memory required for data: 221184192
I0630 16:50:47.555758 28406 layer_factory.hpp:77] Creating layer conv5_5/dw
I0630 16:50:47.555766 28406 net.cpp:86] Creating Layer conv5_5/dw
I0630 16:50:47.555773 28406 net.cpp:408] conv5_5/dw <- conv5_4/sep
I0630 16:50:47.555784 28406 net.cpp:382] conv5_5/dw -> conv5_5/dw
I0630 16:50:47.556044 28406 net.cpp:124] Setting up conv5_5/dw
I0630 16:50:47.556054 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.556059 28406 net.cpp:139] Memory required for data: 222363840
I0630 16:50:47.556064 28406 layer_factory.hpp:77] Creating layer conv5_5/dw/bn
I0630 16:50:47.556071 28406 net.cpp:86] Creating Layer conv5_5/dw/bn
I0630 16:50:47.556077 28406 net.cpp:408] conv5_5/dw/bn <- conv5_5/dw
I0630 16:50:47.556085 28406 net.cpp:369] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0630 16:50:47.556290 28406 net.cpp:124] Setting up conv5_5/dw/bn
I0630 16:50:47.556300 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.556304 28406 net.cpp:139] Memory required for data: 223543488
I0630 16:50:47.556324 28406 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0630 16:50:47.556335 28406 net.cpp:86] Creating Layer conv5_5/dw/scale
I0630 16:50:47.556345 28406 net.cpp:408] conv5_5/dw/scale <- conv5_5/dw
I0630 16:50:47.556354 28406 net.cpp:369] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0630 16:50:47.556406 28406 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0630 16:50:47.556535 28406 net.cpp:124] Setting up conv5_5/dw/scale
I0630 16:50:47.556545 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.556548 28406 net.cpp:139] Memory required for data: 224723136
I0630 16:50:47.556555 28406 layer_factory.hpp:77] Creating layer relu5_5/dw
I0630 16:50:47.556565 28406 net.cpp:86] Creating Layer relu5_5/dw
I0630 16:50:47.556572 28406 net.cpp:408] relu5_5/dw <- conv5_5/dw
I0630 16:50:47.556581 28406 net.cpp:369] relu5_5/dw -> conv5_5/dw (in-place)
I0630 16:50:47.557365 28406 net.cpp:124] Setting up relu5_5/dw
I0630 16:50:47.557379 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.557387 28406 net.cpp:139] Memory required for data: 225902784
I0630 16:50:47.557395 28406 layer_factory.hpp:77] Creating layer conv5_5/sep
I0630 16:50:47.557410 28406 net.cpp:86] Creating Layer conv5_5/sep
I0630 16:50:47.557415 28406 net.cpp:408] conv5_5/sep <- conv5_5/dw
I0630 16:50:47.557423 28406 net.cpp:382] conv5_5/sep -> conv5_5/sep
I0630 16:50:47.562845 28406 net.cpp:124] Setting up conv5_5/sep
I0630 16:50:47.562862 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.562868 28406 net.cpp:139] Memory required for data: 227082432
I0630 16:50:47.562880 28406 layer_factory.hpp:77] Creating layer conv5_5/sep/bn
I0630 16:50:47.562901 28406 net.cpp:86] Creating Layer conv5_5/sep/bn
I0630 16:50:47.562909 28406 net.cpp:408] conv5_5/sep/bn <- conv5_5/sep
I0630 16:50:47.562922 28406 net.cpp:369] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0630 16:50:47.563139 28406 net.cpp:124] Setting up conv5_5/sep/bn
I0630 16:50:47.563149 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.563158 28406 net.cpp:139] Memory required for data: 228262080
I0630 16:50:47.563177 28406 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0630 16:50:47.563189 28406 net.cpp:86] Creating Layer conv5_5/sep/scale
I0630 16:50:47.563197 28406 net.cpp:408] conv5_5/sep/scale <- conv5_5/sep
I0630 16:50:47.563206 28406 net.cpp:369] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0630 16:50:47.563257 28406 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0630 16:50:47.563411 28406 net.cpp:124] Setting up conv5_5/sep/scale
I0630 16:50:47.563421 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.563436 28406 net.cpp:139] Memory required for data: 229441728
I0630 16:50:47.563463 28406 layer_factory.hpp:77] Creating layer relu5_5/sep
I0630 16:50:47.563474 28406 net.cpp:86] Creating Layer relu5_5/sep
I0630 16:50:47.563482 28406 net.cpp:408] relu5_5/sep <- conv5_5/sep
I0630 16:50:47.563493 28406 net.cpp:369] relu5_5/sep -> conv5_5/sep (in-place)
I0630 16:50:47.563983 28406 net.cpp:124] Setting up relu5_5/sep
I0630 16:50:47.563995 28406 net.cpp:131] Top shape: 16 512 6 6 (294912)
I0630 16:50:47.564010 28406 net.cpp:139] Memory required for data: 230621376
I0630 16:50:47.564019 28406 layer_factory.hpp:77] Creating layer pool6
I0630 16:50:47.564031 28406 net.cpp:86] Creating Layer pool6
I0630 16:50:47.564038 28406 net.cpp:408] pool6 <- conv5_5/sep
I0630 16:50:47.564049 28406 net.cpp:382] pool6 -> pool6
I0630 16:50:47.564936 28406 net.cpp:124] Setting up pool6
I0630 16:50:47.564952 28406 net.cpp:131] Top shape: 16 512 1 1 (8192)
I0630 16:50:47.564961 28406 net.cpp:139] Memory required for data: 230654144
I0630 16:50:47.564970 28406 layer_factory.hpp:77] Creating layer fc7-mouth
I0630 16:50:47.564988 28406 net.cpp:86] Creating Layer fc7-mouth
I0630 16:50:47.564996 28406 net.cpp:408] fc7-mouth <- pool6
I0630 16:50:47.565007 28406 net.cpp:382] fc7-mouth -> fc7-mouth
I0630 16:50:47.567222 28406 net.cpp:124] Setting up fc7-mouth
I0630 16:50:47.567235 28406 net.cpp:131] Top shape: 16 4 1 1 (64)
I0630 16:50:47.567243 28406 net.cpp:139] Memory required for data: 230654400
I0630 16:50:47.567265 28406 layer_factory.hpp:77] Creating layer fc7-mouth_fc7-mouth_0_split
I0630 16:50:47.567277 28406 net.cpp:86] Creating Layer fc7-mouth_fc7-mouth_0_split
I0630 16:50:47.567284 28406 net.cpp:408] fc7-mouth_fc7-mouth_0_split <- fc7-mouth
I0630 16:50:47.567297 28406 net.cpp:382] fc7-mouth_fc7-mouth_0_split -> fc7-mouth_fc7-mouth_0_split_0
I0630 16:50:47.567309 28406 net.cpp:382] fc7-mouth_fc7-mouth_0_split -> fc7-mouth_fc7-mouth_0_split_1
I0630 16:50:47.567360 28406 net.cpp:124] Setting up fc7-mouth_fc7-mouth_0_split
I0630 16:50:47.567380 28406 net.cpp:131] Top shape: 16 4 1 1 (64)
I0630 16:50:47.567389 28406 net.cpp:131] Top shape: 16 4 1 1 (64)
I0630 16:50:47.567404 28406 net.cpp:139] Memory required for data: 230654912
I0630 16:50:47.567409 28406 layer_factory.hpp:77] Creating layer loss
I0630 16:50:47.567420 28406 net.cpp:86] Creating Layer loss
I0630 16:50:47.567427 28406 net.cpp:408] loss <- fc7-mouth_fc7-mouth_0_split_0
I0630 16:50:47.567436 28406 net.cpp:408] loss <- clc-label_data_1_split_0
I0630 16:50:47.567445 28406 net.cpp:382] loss -> loss
I0630 16:50:47.567457 28406 layer_factory.hpp:77] Creating layer loss
I0630 16:50:47.568413 28406 net.cpp:124] Setting up loss
I0630 16:50:47.568424 28406 net.cpp:131] Top shape: (1)
I0630 16:50:47.568433 28406 net.cpp:134]     with loss weight 1
I0630 16:50:47.568454 28406 net.cpp:139] Memory required for data: 230654916
I0630 16:50:47.568461 28406 layer_factory.hpp:77] Creating layer acc
I0630 16:50:47.568473 28406 net.cpp:86] Creating Layer acc
I0630 16:50:47.568480 28406 net.cpp:408] acc <- fc7-mouth_fc7-mouth_0_split_1
I0630 16:50:47.568490 28406 net.cpp:408] acc <- clc-label_data_1_split_1
I0630 16:50:47.568502 28406 net.cpp:382] acc -> acc
I0630 16:50:47.568531 28406 net.cpp:124] Setting up acc
I0630 16:50:47.568540 28406 net.cpp:131] Top shape: (1)
I0630 16:50:47.568544 28406 net.cpp:139] Memory required for data: 230654920
I0630 16:50:47.568549 28406 net.cpp:202] acc does not need backward computation.
I0630 16:50:47.568553 28406 net.cpp:200] loss needs backward computation.
I0630 16:50:47.568559 28406 net.cpp:200] fc7-mouth_fc7-mouth_0_split needs backward computation.
I0630 16:50:47.568564 28406 net.cpp:200] fc7-mouth needs backward computation.
I0630 16:50:47.568572 28406 net.cpp:200] pool6 needs backward computation.
I0630 16:50:47.568578 28406 net.cpp:200] relu5_5/sep needs backward computation.
I0630 16:50:47.568581 28406 net.cpp:200] conv5_5/sep/scale needs backward computation.
I0630 16:50:47.568585 28406 net.cpp:200] conv5_5/sep/bn needs backward computation.
I0630 16:50:47.568589 28406 net.cpp:200] conv5_5/sep needs backward computation.
I0630 16:50:47.568605 28406 net.cpp:200] relu5_5/dw needs backward computation.
I0630 16:50:47.568610 28406 net.cpp:200] conv5_5/dw/scale needs backward computation.
I0630 16:50:47.568614 28406 net.cpp:200] conv5_5/dw/bn needs backward computation.
I0630 16:50:47.568619 28406 net.cpp:200] conv5_5/dw needs backward computation.
I0630 16:50:47.568624 28406 net.cpp:200] relu5_4/sep needs backward computation.
I0630 16:50:47.568627 28406 net.cpp:200] conv5_4/sep/scale needs backward computation.
I0630 16:50:47.568632 28406 net.cpp:200] conv5_4/sep/bn needs backward computation.
I0630 16:50:47.568636 28406 net.cpp:200] conv5_4/sep needs backward computation.
I0630 16:50:47.568641 28406 net.cpp:200] relu5_4/dw needs backward computation.
I0630 16:50:47.568645 28406 net.cpp:200] conv5_4/dw/scale needs backward computation.
I0630 16:50:47.568651 28406 net.cpp:200] conv5_4/dw/bn needs backward computation.
I0630 16:50:47.568658 28406 net.cpp:200] conv5_4/dw needs backward computation.
I0630 16:50:47.568666 28406 net.cpp:200] relu5_3/sep needs backward computation.
I0630 16:50:47.568673 28406 net.cpp:200] conv5_3/sep/scale needs backward computation.
I0630 16:50:47.568681 28406 net.cpp:200] conv5_3/sep/bn needs backward computation.
I0630 16:50:47.568687 28406 net.cpp:200] conv5_3/sep needs backward computation.
I0630 16:50:47.568694 28406 net.cpp:200] relu5_3/dw needs backward computation.
I0630 16:50:47.568702 28406 net.cpp:200] conv5_3/dw/scale needs backward computation.
I0630 16:50:47.568711 28406 net.cpp:200] conv5_3/dw/bn needs backward computation.
I0630 16:50:47.568718 28406 net.cpp:200] conv5_3/dw needs backward computation.
I0630 16:50:47.568727 28406 net.cpp:200] relu5_2/sep needs backward computation.
I0630 16:50:47.568735 28406 net.cpp:200] conv5_2/sep/scale needs backward computation.
I0630 16:50:47.568742 28406 net.cpp:200] conv5_2/sep/bn needs backward computation.
I0630 16:50:47.568749 28406 net.cpp:200] conv5_2/sep needs backward computation.
I0630 16:50:47.568756 28406 net.cpp:200] relu5_2/dw needs backward computation.
I0630 16:50:47.568763 28406 net.cpp:200] conv5_2/dw/scale needs backward computation.
I0630 16:50:47.568771 28406 net.cpp:200] conv5_2/dw/bn needs backward computation.
I0630 16:50:47.568778 28406 net.cpp:200] conv5_2/dw needs backward computation.
I0630 16:50:47.568786 28406 net.cpp:200] relu5_1/sep needs backward computation.
I0630 16:50:47.568794 28406 net.cpp:200] conv5_1/sep/scale needs backward computation.
I0630 16:50:47.568800 28406 net.cpp:200] conv5_1/sep/bn needs backward computation.
I0630 16:50:47.568809 28406 net.cpp:200] conv5_1/sep needs backward computation.
I0630 16:50:47.568815 28406 net.cpp:200] relu5_1/dw needs backward computation.
I0630 16:50:47.568822 28406 net.cpp:200] conv5_1/dw/scale needs backward computation.
I0630 16:50:47.568830 28406 net.cpp:200] conv5_1/dw/bn needs backward computation.
I0630 16:50:47.568837 28406 net.cpp:200] conv5_1/dw needs backward computation.
I0630 16:50:47.568845 28406 net.cpp:200] relu4_2/sep needs backward computation.
I0630 16:50:47.568851 28406 net.cpp:200] conv4_2/sep/scale needs backward computation.
I0630 16:50:47.568858 28406 net.cpp:200] conv4_2/sep/bn needs backward computation.
I0630 16:50:47.568866 28406 net.cpp:200] conv4_2/sep needs backward computation.
I0630 16:50:47.568873 28406 net.cpp:200] relu4_2/dw needs backward computation.
I0630 16:50:47.568881 28406 net.cpp:200] conv4_2/dw/scale needs backward computation.
I0630 16:50:47.568887 28406 net.cpp:200] conv4_2/dw/bn needs backward computation.
I0630 16:50:47.568895 28406 net.cpp:200] conv4_2/dw needs backward computation.
I0630 16:50:47.568904 28406 net.cpp:200] relu4_1/sep needs backward computation.
I0630 16:50:47.568912 28406 net.cpp:200] conv4_1/sep/scale needs backward computation.
I0630 16:50:47.568919 28406 net.cpp:200] conv4_1/sep/bn needs backward computation.
I0630 16:50:47.568926 28406 net.cpp:200] conv4_1/sep needs backward computation.
I0630 16:50:47.568934 28406 net.cpp:200] relu4_1/dw needs backward computation.
I0630 16:50:47.568941 28406 net.cpp:200] conv4_1/dw/scale needs backward computation.
I0630 16:50:47.568956 28406 net.cpp:200] conv4_1/dw/bn needs backward computation.
I0630 16:50:47.568964 28406 net.cpp:200] conv4_1/dw needs backward computation.
I0630 16:50:47.568974 28406 net.cpp:200] relu3_2/sep needs backward computation.
I0630 16:50:47.568981 28406 net.cpp:200] conv3_2/sep/scale needs backward computation.
I0630 16:50:47.568989 28406 net.cpp:200] conv3_2/sep/bn needs backward computation.
I0630 16:50:47.568997 28406 net.cpp:200] conv3_2/sep needs backward computation.
I0630 16:50:47.569005 28406 net.cpp:200] relu3_2/dw needs backward computation.
I0630 16:50:47.569015 28406 net.cpp:200] conv3_2/dw/scale needs backward computation.
I0630 16:50:47.569021 28406 net.cpp:200] conv3_2/dw/bn needs backward computation.
I0630 16:50:47.569030 28406 net.cpp:200] conv3_2/dw needs backward computation.
I0630 16:50:47.569038 28406 net.cpp:200] relu3_1/sep needs backward computation.
I0630 16:50:47.569046 28406 net.cpp:200] conv3_1/sep/scale needs backward computation.
I0630 16:50:47.569053 28406 net.cpp:200] conv3_1/sep/bn needs backward computation.
I0630 16:50:47.569062 28406 net.cpp:200] conv3_1/sep needs backward computation.
I0630 16:50:47.569070 28406 net.cpp:200] relu3_1/dw needs backward computation.
I0630 16:50:47.569078 28406 net.cpp:200] conv3_1/dw/scale needs backward computation.
I0630 16:50:47.569087 28406 net.cpp:200] conv3_1/dw/bn needs backward computation.
I0630 16:50:47.569093 28406 net.cpp:200] conv3_1/dw needs backward computation.
I0630 16:50:47.569103 28406 net.cpp:200] relu2_2/sep needs backward computation.
I0630 16:50:47.569110 28406 net.cpp:200] conv2_2/sep/scale needs backward computation.
I0630 16:50:47.569118 28406 net.cpp:200] conv2_2/sep/bn needs backward computation.
I0630 16:50:47.569126 28406 net.cpp:200] conv2_2/sep needs backward computation.
I0630 16:50:47.569134 28406 net.cpp:200] relu2_2/dw needs backward computation.
I0630 16:50:47.569142 28406 net.cpp:200] conv2_2/dw/scale needs backward computation.
I0630 16:50:47.569150 28406 net.cpp:200] conv2_2/dw/bn needs backward computation.
I0630 16:50:47.569159 28406 net.cpp:200] conv2_2/dw needs backward computation.
I0630 16:50:47.569166 28406 net.cpp:200] relu2_1/sep needs backward computation.
I0630 16:50:47.569175 28406 net.cpp:200] conv2_1/sep/scale needs backward computation.
I0630 16:50:47.569190 28406 net.cpp:200] conv2_1/sep/bn needs backward computation.
I0630 16:50:47.569200 28406 net.cpp:200] conv2_1/sep needs backward computation.
I0630 16:50:47.569205 28406 net.cpp:200] relu2_1/dw needs backward computation.
I0630 16:50:47.569211 28406 net.cpp:200] conv2_1/dw/scale needs backward computation.
I0630 16:50:47.569214 28406 net.cpp:200] conv2_1/dw/bn needs backward computation.
I0630 16:50:47.569218 28406 net.cpp:200] conv2_1/dw needs backward computation.
I0630 16:50:47.569223 28406 net.cpp:200] relu1 needs backward computation.
I0630 16:50:47.569227 28406 net.cpp:200] conv1/scale needs backward computation.
I0630 16:50:47.569231 28406 net.cpp:200] conv1/bn needs backward computation.
I0630 16:50:47.569236 28406 net.cpp:200] conv1 needs backward computation.
I0630 16:50:47.569241 28406 net.cpp:202] clc-label_data_1_split does not need backward computation.
I0630 16:50:47.569245 28406 net.cpp:202] data does not need backward computation.
I0630 16:50:47.569248 28406 net.cpp:244] This network produces output acc
I0630 16:50:47.569253 28406 net.cpp:244] This network produces output loss
I0630 16:50:47.569298 28406 net.cpp:257] Network initialization done.
I0630 16:50:47.569483 28406 solver.cpp:72] Finetuning from ./mobilenet.caffemodel
I0630 16:50:47.580669 28406 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./mobilenet.caffemodel
I0630 16:50:47.580709 28406 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0630 16:50:47.580716 28406 net.cpp:746] Ignoring source layer label_data_1_split
I0630 16:50:47.582114 28406 net.cpp:746] Ignoring source layer conv5_6/dw
I0630 16:50:47.582147 28406 net.cpp:746] Ignoring source layer conv5_6/dw/bn
I0630 16:50:47.582180 28406 net.cpp:746] Ignoring source layer conv5_6/dw/scale
I0630 16:50:47.582185 28406 net.cpp:746] Ignoring source layer relu5_6/dw
I0630 16:50:47.582188 28406 net.cpp:746] Ignoring source layer conv5_6/sep
I0630 16:50:47.582192 28406 net.cpp:746] Ignoring source layer conv5_6/sep/bn
I0630 16:50:47.582196 28406 net.cpp:746] Ignoring source layer conv5_6/sep/scale
I0630 16:50:47.582199 28406 net.cpp:746] Ignoring source layer relu5_6/sep
I0630 16:50:47.582203 28406 net.cpp:746] Ignoring source layer conv6/dw
I0630 16:50:47.582207 28406 net.cpp:746] Ignoring source layer conv6/dw/bn
I0630 16:50:47.582219 28406 net.cpp:746] Ignoring source layer conv6/dw/scale
I0630 16:50:47.582223 28406 net.cpp:746] Ignoring source layer relu6/dw
I0630 16:50:47.582226 28406 net.cpp:746] Ignoring source layer conv6/sep
I0630 16:50:47.582231 28406 net.cpp:746] Ignoring source layer conv6/sep/bn
I0630 16:50:47.582233 28406 net.cpp:746] Ignoring source layer conv6/sep/scale
I0630 16:50:47.582245 28406 net.cpp:746] Ignoring source layer relu6/sep
I0630 16:50:47.582250 28406 net.cpp:746] Ignoring source layer fc7
I0630 16:50:47.582253 28406 net.cpp:746] Ignoring source layer fc7_fc7_0_split
I0630 16:50:47.582258 28406 net.cpp:746] Ignoring source layer top1/acc
I0630 16:50:47.582262 28406 net.cpp:746] Ignoring source layer top5/acc
I0630 16:50:47.582476 28406 solver.cpp:57] Solver scaffolding done.
I0630 16:50:47.589488 28406 caffe.cpp:239] Starting Optimization
I0630 16:50:47.589498 28406 solver.cpp:289] Solving mouth
I0630 16:50:47.589501 28406 solver.cpp:290] Learning Rate Policy: fixed
I0630 16:50:47.591964 28406 solver.cpp:347] Iteration 0, Testing net (#0)
I0630 16:51:06.305799 28406 solver.cpp:414]     Test net output #0: acc = 0.22375
I0630 16:51:06.305843 28406 solver.cpp:414]     Test net output #1: loss = 1.39214 (* 1 = 1.39214 loss)
I0630 16:51:08.667834 28406 solver.cpp:239] Iteration 0 (0 iter/s, 21.0786s/100 iters), loss = 1.39552
I0630 16:51:08.667866 28406 solver.cpp:258]     Train net output #0: acc = 0.1875
I0630 16:51:08.667878 28406 solver.cpp:258]     Train net output #1: loss = 1.39552 (* 1 = 1.39552 loss)
I0630 16:51:08.667896 28406 sgd_solver.cpp:112] Iteration 0, lr = 0.0001
I0630 16:54:53.201442 28406 solver.cpp:347] Iteration 100, Testing net (#0)
I0630 16:55:11.540827 28406 solver.cpp:414]     Test net output #0: acc = 0.891875
I0630 16:55:11.540853 28406 solver.cpp:414]     Test net output #1: loss = 0.582282 (* 1 = 0.582282 loss)
I0630 16:55:13.788172 28406 solver.cpp:239] Iteration 100 (0.407951 iter/s, 245.128s/100 iters), loss = 0.47711
I0630 16:55:13.788206 28406 solver.cpp:258]     Train net output #0: acc = 0.96875
I0630 16:55:13.788226 28406 solver.cpp:258]     Train net output #1: loss = 0.47711 (* 1 = 0.47711 loss)
I0630 16:55:13.788233 28406 sgd_solver.cpp:112] Iteration 100, lr = 0.0001
I0630 16:58:56.855338 28406 solver.cpp:347] Iteration 200, Testing net (#0)
I0630 16:59:15.174216 28406 solver.cpp:414]     Test net output #0: acc = 0.9075
I0630 16:59:15.174247 28406 solver.cpp:414]     Test net output #1: loss = 0.374556 (* 1 = 0.374556 loss)
I0630 16:59:17.426681 28406 solver.cpp:239] Iteration 200 (0.410433 iter/s, 243.645s/100 iters), loss = 0.428916
I0630 16:59:17.426723 28406 solver.cpp:258]     Train net output #0: acc = 0.90625
I0630 16:59:17.426750 28406 solver.cpp:258]     Train net output #1: loss = 0.428916 (* 1 = 0.428916 loss)
I0630 16:59:17.426762 28406 sgd_solver.cpp:112] Iteration 200, lr = 0.0001
I0630 17:03:00.349393 28406 solver.cpp:347] Iteration 300, Testing net (#0)
I0630 17:03:18.638150 28406 solver.cpp:414]     Test net output #0: acc = 0.92125
I0630 17:03:18.638181 28406 solver.cpp:414]     Test net output #1: loss = 0.274203 (* 1 = 0.274203 loss)
I0630 17:03:20.886557 28406 solver.cpp:239] Iteration 300 (0.410735 iter/s, 243.466s/100 iters), loss = 0.282
I0630 17:03:20.886598 28406 solver.cpp:258]     Train net output #0: acc = 0.921875
I0630 17:03:20.886624 28406 solver.cpp:258]     Train net output #1: loss = 0.282 (* 1 = 0.282 loss)
I0630 17:03:20.886636 28406 sgd_solver.cpp:112] Iteration 300, lr = 0.0001
I0630 17:07:03.830569 28406 solver.cpp:347] Iteration 400, Testing net (#0)
I0630 17:07:22.105440 28406 solver.cpp:414]     Test net output #0: acc = 0.93
I0630 17:07:22.105468 28406 solver.cpp:414]     Test net output #1: loss = 0.252187 (* 1 = 0.252187 loss)
I0630 17:07:24.354763 28406 solver.cpp:239] Iteration 400 (0.410722 iter/s, 243.474s/100 iters), loss = 0.194355
I0630 17:07:24.354799 28406 solver.cpp:258]     Train net output #0: acc = 0.9375
I0630 17:07:24.354820 28406 solver.cpp:258]     Train net output #1: loss = 0.194355 (* 1 = 0.194355 loss)
I0630 17:07:24.354825 28406 sgd_solver.cpp:112] Iteration 400, lr = 0.0001
I0630 17:11:07.025873 28406 solver.cpp:347] Iteration 500, Testing net (#0)
I0630 17:11:25.332988 28406 solver.cpp:414]     Test net output #0: acc = 0.92125
I0630 17:11:25.333014 28406 solver.cpp:414]     Test net output #1: loss = 0.247903 (* 1 = 0.247903 loss)
I0630 17:11:27.582487 28406 solver.cpp:239] Iteration 500 (0.411129 iter/s, 243.233s/100 iters), loss = 0.1342
I0630 17:11:27.582522 28406 solver.cpp:258]     Train net output #0: acc = 0.96875
I0630 17:11:27.582543 28406 solver.cpp:258]     Train net output #1: loss = 0.1342 (* 1 = 0.1342 loss)
I0630 17:11:27.582551 28406 sgd_solver.cpp:112] Iteration 500, lr = 0.0001
I0630 17:15:10.472189 28406 solver.cpp:347] Iteration 600, Testing net (#0)
I0630 17:15:28.724180 28406 solver.cpp:414]     Test net output #0: acc = 0.9275
I0630 17:15:28.724207 28406 solver.cpp:414]     Test net output #1: loss = 0.216897 (* 1 = 0.216897 loss)
I0630 17:15:30.986529 28406 solver.cpp:239] Iteration 600 (0.410831 iter/s, 243.409s/100 iters), loss = 0.0928469
I0630 17:15:30.986567 28406 solver.cpp:258]     Train net output #0: acc = 0.96875
I0630 17:15:30.986588 28406 solver.cpp:258]     Train net output #1: loss = 0.0928469 (* 1 = 0.0928469 loss)
I0630 17:15:30.986595 28406 sgd_solver.cpp:112] Iteration 600, lr = 0.0001
I0630 17:19:13.861981 28406 solver.cpp:347] Iteration 700, Testing net (#0)
I0630 17:19:32.162953 28406 solver.cpp:414]     Test net output #0: acc = 0.929375
I0630 17:19:32.162979 28406 solver.cpp:414]     Test net output #1: loss = 0.218887 (* 1 = 0.218887 loss)
I0630 17:19:34.413020 28406 solver.cpp:239] Iteration 700 (0.410794 iter/s, 243.431s/100 iters), loss = 0.0948103
I0630 17:19:34.413066 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 17:19:34.413080 28406 solver.cpp:258]     Train net output #1: loss = 0.0948104 (* 1 = 0.0948104 loss)
I0630 17:19:34.413087 28406 sgd_solver.cpp:112] Iteration 700, lr = 0.0001
I0630 17:23:17.312707 28406 solver.cpp:347] Iteration 800, Testing net (#0)
I0630 17:23:35.630990 28406 solver.cpp:414]     Test net output #0: acc = 0.934375
I0630 17:23:35.631017 28406 solver.cpp:414]     Test net output #1: loss = 0.211214 (* 1 = 0.211214 loss)
I0630 17:23:37.888094 28406 solver.cpp:239] Iteration 800 (0.410712 iter/s, 243.48s/100 iters), loss = 0.0977424
I0630 17:23:37.888130 28406 solver.cpp:258]     Train net output #0: acc = 0.96875
I0630 17:23:37.888151 28406 solver.cpp:258]     Train net output #1: loss = 0.0977424 (* 1 = 0.0977424 loss)
I0630 17:23:37.888159 28406 sgd_solver.cpp:112] Iteration 800, lr = 0.0001
I0630 17:27:20.813271 28406 solver.cpp:347] Iteration 900, Testing net (#0)
I0630 17:27:39.066012 28406 solver.cpp:414]     Test net output #0: acc = 0.935625
I0630 17:27:39.066040 28406 solver.cpp:414]     Test net output #1: loss = 0.205747 (* 1 = 0.205747 loss)
I0630 17:27:41.311342 28406 solver.cpp:239] Iteration 900 (0.410805 iter/s, 243.425s/100 iters), loss = 0.197299
I0630 17:27:41.311377 28406 solver.cpp:258]     Train net output #0: acc = 0.921875
I0630 17:27:41.311398 28406 solver.cpp:258]     Train net output #1: loss = 0.197299 (* 1 = 0.197299 loss)
I0630 17:27:41.311404 28406 sgd_solver.cpp:112] Iteration 900, lr = 0.0001
I0630 17:31:24.179108 28406 solver.cpp:464] Snapshotting to binary proto file models/mobilenet_finetune_iter_1000.caffemodel
I0630 17:31:24.221578 28406 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/mobilenet_finetune_iter_1000.solverstate
I0630 17:31:24.245899 28406 solver.cpp:347] Iteration 1000, Testing net (#0)
I0630 17:31:42.546972 28406 solver.cpp:414]     Test net output #0: acc = 0.931875
I0630 17:31:42.547013 28406 solver.cpp:414]     Test net output #1: loss = 0.21854 (* 1 = 0.21854 loss)
I0630 17:31:44.800034 28406 solver.cpp:239] Iteration 1000 (0.410699 iter/s, 243.487s/100 iters), loss = 0.140883
I0630 17:31:44.800070 28406 solver.cpp:258]     Train net output #0: acc = 0.9375
I0630 17:31:44.800089 28406 solver.cpp:258]     Train net output #1: loss = 0.140883 (* 1 = 0.140883 loss)
I0630 17:31:44.800096 28406 sgd_solver.cpp:112] Iteration 1000, lr = 0.0001
I0630 17:35:27.786281 28406 solver.cpp:347] Iteration 1100, Testing net (#0)
I0630 17:35:46.140631 28406 solver.cpp:414]     Test net output #0: acc = 0.94625
I0630 17:35:46.140660 28406 solver.cpp:414]     Test net output #1: loss = 0.163975 (* 1 = 0.163975 loss)
I0630 17:35:48.380666 28406 solver.cpp:239] Iteration 1100 (0.410541 iter/s, 243.581s/100 iters), loss = 0.0853353
I0630 17:35:48.380704 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 17:35:48.380725 28406 solver.cpp:258]     Train net output #1: loss = 0.0853353 (* 1 = 0.0853353 loss)
I0630 17:35:48.380731 28406 sgd_solver.cpp:112] Iteration 1100, lr = 0.0001
I0630 17:39:31.198277 28406 solver.cpp:347] Iteration 1200, Testing net (#0)
I0630 17:39:49.519480 28406 solver.cpp:414]     Test net output #0: acc = 0.938125
I0630 17:39:49.519508 28406 solver.cpp:414]     Test net output #1: loss = 0.205954 (* 1 = 0.205954 loss)
I0630 17:39:51.764685 28406 solver.cpp:239] Iteration 1200 (0.41087 iter/s, 243.386s/100 iters), loss = 0.0897031
I0630 17:39:51.764721 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 17:39:51.764741 28406 solver.cpp:258]     Train net output #1: loss = 0.0897031 (* 1 = 0.0897031 loss)
I0630 17:39:51.764748 28406 sgd_solver.cpp:112] Iteration 1200, lr = 0.0001
I0630 17:43:34.697173 28406 solver.cpp:347] Iteration 1300, Testing net (#0)
I0630 17:43:52.987892 28406 solver.cpp:414]     Test net output #0: acc = 0.938125
I0630 17:43:52.987920 28406 solver.cpp:414]     Test net output #1: loss = 0.192128 (* 1 = 0.192128 loss)
I0630 17:43:55.251426 28406 solver.cpp:239] Iteration 1300 (0.410696 iter/s, 243.489s/100 iters), loss = 0.0236444
I0630 17:43:55.251466 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 17:43:55.251487 28406 solver.cpp:258]     Train net output #1: loss = 0.0236444 (* 1 = 0.0236444 loss)
I0630 17:43:55.251494 28406 sgd_solver.cpp:112] Iteration 1300, lr = 0.0001
I0630 17:47:38.062510 28406 solver.cpp:347] Iteration 1400, Testing net (#0)
I0630 17:47:56.406492 28406 solver.cpp:414]     Test net output #0: acc = 0.939375
I0630 17:47:56.406520 28406 solver.cpp:414]     Test net output #1: loss = 0.190846 (* 1 = 0.190846 loss)
I0630 17:47:58.653980 28406 solver.cpp:239] Iteration 1400 (0.410837 iter/s, 243.406s/100 iters), loss = 0.0671185
I0630 17:47:58.654018 28406 solver.cpp:258]     Train net output #0: acc = 0.96875
I0630 17:47:58.654039 28406 solver.cpp:258]     Train net output #1: loss = 0.0671185 (* 1 = 0.0671185 loss)
I0630 17:47:58.654047 28406 sgd_solver.cpp:112] Iteration 1400, lr = 0.0001
I0630 17:51:41.437002 28406 solver.cpp:347] Iteration 1500, Testing net (#0)
I0630 17:51:59.762769 28406 solver.cpp:414]     Test net output #0: acc = 0.93375
I0630 17:51:59.762797 28406 solver.cpp:414]     Test net output #1: loss = 0.207689 (* 1 = 0.207689 loss)
I0630 17:52:02.014714 28406 solver.cpp:239] Iteration 1500 (0.410907 iter/s, 243.364s/100 iters), loss = 0.031504
I0630 17:52:02.014748 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 17:52:02.014768 28406 solver.cpp:258]     Train net output #1: loss = 0.031504 (* 1 = 0.031504 loss)
I0630 17:52:02.014775 28406 sgd_solver.cpp:112] Iteration 1500, lr = 0.0001
I0630 17:55:44.792578 28406 solver.cpp:347] Iteration 1600, Testing net (#0)
I0630 17:56:03.084245 28406 solver.cpp:414]     Test net output #0: acc = 0.9425
I0630 17:56:03.084272 28406 solver.cpp:414]     Test net output #1: loss = 0.188099 (* 1 = 0.188099 loss)
I0630 17:56:05.334836 28406 solver.cpp:239] Iteration 1600 (0.410975 iter/s, 243.324s/100 iters), loss = 0.0212655
I0630 17:56:05.334872 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 17:56:05.334892 28406 solver.cpp:258]     Train net output #1: loss = 0.0212655 (* 1 = 0.0212655 loss)
I0630 17:56:05.334898 28406 sgd_solver.cpp:112] Iteration 1600, lr = 0.0001
I0630 17:59:48.249732 28406 solver.cpp:347] Iteration 1700, Testing net (#0)
I0630 18:00:06.551445 28406 solver.cpp:414]     Test net output #0: acc = 0.939375
I0630 18:00:06.551473 28406 solver.cpp:414]     Test net output #1: loss = 0.196061 (* 1 = 0.196061 loss)
I0630 18:00:08.814738 28406 solver.cpp:239] Iteration 1700 (0.410705 iter/s, 243.483s/100 iters), loss = 0.0384544
I0630 18:00:08.814776 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 18:00:08.814796 28406 solver.cpp:258]     Train net output #1: loss = 0.0384543 (* 1 = 0.0384543 loss)
I0630 18:00:08.814803 28406 sgd_solver.cpp:112] Iteration 1700, lr = 0.0001
I0630 18:03:52.045931 28406 solver.cpp:347] Iteration 1800, Testing net (#0)
I0630 18:04:10.320677 28406 solver.cpp:414]     Test net output #0: acc = 0.950625
I0630 18:04:10.320704 28406 solver.cpp:414]     Test net output #1: loss = 0.158983 (* 1 = 0.158983 loss)
I0630 18:04:12.572458 28406 solver.cpp:239] Iteration 1800 (0.41023 iter/s, 243.766s/100 iters), loss = 0.103709
I0630 18:04:12.572491 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 18:04:12.572511 28406 solver.cpp:258]     Train net output #1: loss = 0.103709 (* 1 = 0.103709 loss)
I0630 18:04:12.572517 28406 sgd_solver.cpp:112] Iteration 1800, lr = 0.0001
I0630 18:07:55.398838 28406 solver.cpp:347] Iteration 1900, Testing net (#0)
I0630 18:08:13.692932 28406 solver.cpp:414]     Test net output #0: acc = 0.943125
I0630 18:08:13.692960 28406 solver.cpp:414]     Test net output #1: loss = 0.193857 (* 1 = 0.193857 loss)
I0630 18:08:15.950279 28406 solver.cpp:239] Iteration 1900 (0.410873 iter/s, 243.384s/100 iters), loss = 0.0218847
I0630 18:08:15.950327 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 18:08:15.950340 28406 solver.cpp:258]     Train net output #1: loss = 0.0218847 (* 1 = 0.0218847 loss)
I0630 18:08:15.950347 28406 sgd_solver.cpp:112] Iteration 1900, lr = 0.0001
I0630 18:11:58.904772 28406 solver.cpp:464] Snapshotting to binary proto file models/mobilenet_finetune_iter_2000.caffemodel
I0630 18:11:58.931758 28406 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/mobilenet_finetune_iter_2000.solverstate
I0630 18:11:58.955008 28406 solver.cpp:347] Iteration 2000, Testing net (#0)
I0630 18:12:17.292918 28406 solver.cpp:414]     Test net output #0: acc = 0.9425
I0630 18:12:17.292946 28406 solver.cpp:414]     Test net output #1: loss = 0.172782 (* 1 = 0.172782 loss)
I0630 18:12:19.549919 28406 solver.cpp:239] Iteration 2000 (0.4105 iter/s, 243.605s/100 iters), loss = 0.122515
I0630 18:12:19.549958 28406 solver.cpp:258]     Train net output #0: acc = 0.96875
I0630 18:12:19.549978 28406 solver.cpp:258]     Train net output #1: loss = 0.122515 (* 1 = 0.122515 loss)
I0630 18:12:19.549985 28406 sgd_solver.cpp:112] Iteration 2000, lr = 0.0001
I0630 18:16:02.394882 28406 solver.cpp:347] Iteration 2100, Testing net (#0)
I0630 18:16:20.666115 28406 solver.cpp:414]     Test net output #0: acc = 0.94875
I0630 18:16:20.666144 28406 solver.cpp:414]     Test net output #1: loss = 0.164784 (* 1 = 0.164784 loss)
I0630 18:16:22.924758 28406 solver.cpp:239] Iteration 2100 (0.41088 iter/s, 243.38s/100 iters), loss = 0.0269038
I0630 18:16:22.924795 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 18:16:22.924816 28406 solver.cpp:258]     Train net output #1: loss = 0.0269038 (* 1 = 0.0269038 loss)
I0630 18:16:22.924823 28406 sgd_solver.cpp:112] Iteration 2100, lr = 0.0001
I0630 18:20:05.607694 28406 solver.cpp:347] Iteration 2200, Testing net (#0)
I0630 18:20:23.930222 28406 solver.cpp:414]     Test net output #0: acc = 0.940625
I0630 18:20:23.930248 28406 solver.cpp:414]     Test net output #1: loss = 0.170913 (* 1 = 0.170913 loss)
I0630 18:20:26.182811 28406 solver.cpp:239] Iteration 2200 (0.411078 iter/s, 243.263s/100 iters), loss = 0.0480421
I0630 18:20:26.182848 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 18:20:26.182869 28406 solver.cpp:258]     Train net output #1: loss = 0.0480421 (* 1 = 0.0480421 loss)
I0630 18:20:26.182876 28406 sgd_solver.cpp:112] Iteration 2200, lr = 0.0001
I0630 18:24:09.091588 28406 solver.cpp:347] Iteration 2300, Testing net (#0)
I0630 18:24:27.404907 28406 solver.cpp:414]     Test net output #0: acc = 0.944375
I0630 18:24:27.404934 28406 solver.cpp:414]     Test net output #1: loss = 0.180396 (* 1 = 0.180396 loss)
I0630 18:24:29.653359 28406 solver.cpp:239] Iteration 2300 (0.410719 iter/s, 243.475s/100 iters), loss = 0.0560436
I0630 18:24:29.653395 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 18:24:29.653416 28406 solver.cpp:258]     Train net output #1: loss = 0.0560436 (* 1 = 0.0560436 loss)
I0630 18:24:29.653424 28406 sgd_solver.cpp:112] Iteration 2300, lr = 0.0001
I0630 18:28:12.545480 28406 solver.cpp:347] Iteration 2400, Testing net (#0)
I0630 18:28:30.836778 28406 solver.cpp:414]     Test net output #0: acc = 0.9425
I0630 18:28:30.836805 28406 solver.cpp:414]     Test net output #1: loss = 0.183076 (* 1 = 0.183076 loss)
I0630 18:28:33.122673 28406 solver.cpp:239] Iteration 2400 (0.410721 iter/s, 243.474s/100 iters), loss = 0.0107639
I0630 18:28:33.122712 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 18:28:33.122738 28406 solver.cpp:258]     Train net output #1: loss = 0.0107639 (* 1 = 0.0107639 loss)
I0630 18:28:33.122750 28406 sgd_solver.cpp:112] Iteration 2400, lr = 0.0001
I0630 18:32:15.955842 28406 solver.cpp:347] Iteration 2500, Testing net (#0)
I0630 18:32:34.279664 28406 solver.cpp:414]     Test net output #0: acc = 0.944375
I0630 18:32:34.279692 28406 solver.cpp:414]     Test net output #1: loss = 0.189802 (* 1 = 0.189802 loss)
I0630 18:32:36.525557 28406 solver.cpp:239] Iteration 2500 (0.410834 iter/s, 243.407s/100 iters), loss = 0.108783
I0630 18:32:36.525591 28406 solver.cpp:258]     Train net output #0: acc = 0.96875
I0630 18:32:36.525611 28406 solver.cpp:258]     Train net output #1: loss = 0.108783 (* 1 = 0.108783 loss)
I0630 18:32:36.525619 28406 sgd_solver.cpp:112] Iteration 2500, lr = 0.0001
I0630 18:36:19.298991 28406 solver.cpp:347] Iteration 2600, Testing net (#0)
I0630 18:36:37.627274 28406 solver.cpp:414]     Test net output #0: acc = 0.946875
I0630 18:36:37.627300 28406 solver.cpp:414]     Test net output #1: loss = 0.166837 (* 1 = 0.166837 loss)
I0630 18:36:39.878901 28406 solver.cpp:239] Iteration 2600 (0.410924 iter/s, 243.354s/100 iters), loss = 0.0169825
I0630 18:36:39.878937 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 18:36:39.878957 28406 solver.cpp:258]     Train net output #1: loss = 0.0169825 (* 1 = 0.0169825 loss)
I0630 18:36:39.878964 28406 sgd_solver.cpp:112] Iteration 2600, lr = 0.0001
I0630 18:40:22.928876 28406 solver.cpp:347] Iteration 2700, Testing net (#0)
I0630 18:40:41.292187 28406 solver.cpp:414]     Test net output #0: acc = 0.943125
I0630 18:40:41.292215 28406 solver.cpp:414]     Test net output #1: loss = 0.212077 (* 1 = 0.212077 loss)
I0630 18:40:43.546903 28406 solver.cpp:239] Iteration 2700 (0.410394 iter/s, 243.668s/100 iters), loss = 0.0430393
I0630 18:40:43.546947 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 18:40:43.546960 28406 solver.cpp:258]     Train net output #1: loss = 0.0430393 (* 1 = 0.0430393 loss)
I0630 18:40:43.546967 28406 sgd_solver.cpp:112] Iteration 2700, lr = 0.0001
I0630 18:44:26.597666 28406 solver.cpp:347] Iteration 2800, Testing net (#0)
I0630 18:44:44.876313 28406 solver.cpp:414]     Test net output #0: acc = 0.950625
I0630 18:44:44.876341 28406 solver.cpp:414]     Test net output #1: loss = 0.159067 (* 1 = 0.159067 loss)
I0630 18:44:47.135771 28406 solver.cpp:239] Iteration 2800 (0.410525 iter/s, 243.59s/100 iters), loss = 0.0124607
I0630 18:44:47.135807 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 18:44:47.135828 28406 solver.cpp:258]     Train net output #1: loss = 0.0124607 (* 1 = 0.0124607 loss)
I0630 18:44:47.135834 28406 sgd_solver.cpp:112] Iteration 2800, lr = 0.0001
I0630 18:48:30.141292 28406 solver.cpp:347] Iteration 2900, Testing net (#0)
I0630 18:48:48.441397 28406 solver.cpp:414]     Test net output #0: acc = 0.946875
I0630 18:48:48.441426 28406 solver.cpp:414]     Test net output #1: loss = 0.166761 (* 1 = 0.166761 loss)
I0630 18:48:50.695737 28406 solver.cpp:239] Iteration 2900 (0.410573 iter/s, 243.562s/100 iters), loss = 0.0250049
I0630 18:48:50.695775 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 18:48:50.695786 28406 solver.cpp:258]     Train net output #1: loss = 0.0250049 (* 1 = 0.0250049 loss)
I0630 18:48:50.695793 28406 sgd_solver.cpp:112] Iteration 2900, lr = 0.0001
I0630 18:52:33.613484 28406 solver.cpp:464] Snapshotting to binary proto file models/mobilenet_finetune_iter_3000.caffemodel
I0630 18:52:33.640313 28406 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/mobilenet_finetune_iter_3000.solverstate
I0630 18:52:33.662976 28406 solver.cpp:347] Iteration 3000, Testing net (#0)
I0630 18:52:51.984899 28406 solver.cpp:414]     Test net output #0: acc = 0.93875
I0630 18:52:51.984925 28406 solver.cpp:414]     Test net output #1: loss = 0.205244 (* 1 = 0.205244 loss)
I0630 18:52:54.230798 28406 solver.cpp:239] Iteration 3000 (0.410614 iter/s, 243.538s/100 iters), loss = 0.0162518
I0630 18:52:54.230832 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 18:52:54.230854 28406 solver.cpp:258]     Train net output #1: loss = 0.0162517 (* 1 = 0.0162517 loss)
I0630 18:52:54.230860 28406 sgd_solver.cpp:112] Iteration 3000, lr = 0.0001
I0630 18:56:37.242388 28406 solver.cpp:347] Iteration 3100, Testing net (#0)
I0630 18:56:55.585155 28406 solver.cpp:414]     Test net output #0: acc = 0.95
I0630 18:56:55.585181 28406 solver.cpp:414]     Test net output #1: loss = 0.172254 (* 1 = 0.172254 loss)
I0630 18:56:57.848260 28406 solver.cpp:239] Iteration 3100 (0.410474 iter/s, 243.621s/100 iters), loss = 0.0422788
I0630 18:56:57.848299 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 18:56:57.848320 28406 solver.cpp:258]     Train net output #1: loss = 0.0422788 (* 1 = 0.0422788 loss)
I0630 18:56:57.848326 28406 sgd_solver.cpp:112] Iteration 3100, lr = 0.0001
I0630 19:00:41.835991 28406 solver.cpp:347] Iteration 3200, Testing net (#0)
I0630 19:01:00.304277 28406 solver.cpp:414]     Test net output #0: acc = 0.95
I0630 19:01:00.304308 28406 solver.cpp:414]     Test net output #1: loss = 0.190253 (* 1 = 0.190253 loss)
I0630 19:01:02.572777 28406 solver.cpp:239] Iteration 3200 (0.408617 iter/s, 244.728s/100 iters), loss = 0.0480784
I0630 19:01:02.572811 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 19:01:02.572831 28406 solver.cpp:258]     Train net output #1: loss = 0.0480784 (* 1 = 0.0480784 loss)
I0630 19:01:02.572839 28406 sgd_solver.cpp:112] Iteration 3200, lr = 0.0001
I0630 19:04:46.800197 28406 solver.cpp:347] Iteration 3300, Testing net (#0)
I0630 19:05:05.195662 28406 solver.cpp:414]     Test net output #0: acc = 0.951875
I0630 19:05:05.195690 28406 solver.cpp:414]     Test net output #1: loss = 0.143399 (* 1 = 0.143399 loss)
I0630 19:05:07.457130 28406 solver.cpp:239] Iteration 3300 (0.40835 iter/s, 244.888s/100 iters), loss = 0.0228054
I0630 19:05:07.457175 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 19:05:07.457192 28406 solver.cpp:258]     Train net output #1: loss = 0.0228054 (* 1 = 0.0228054 loss)
I0630 19:05:07.457207 28406 sgd_solver.cpp:112] Iteration 3300, lr = 0.0001
I0630 19:08:51.616564 28406 solver.cpp:347] Iteration 3400, Testing net (#0)
I0630 19:09:10.033332 28406 solver.cpp:414]     Test net output #0: acc = 0.95125
I0630 19:09:10.033366 28406 solver.cpp:414]     Test net output #1: loss = 0.161518 (* 1 = 0.161518 loss)
I0630 19:09:12.297650 28406 solver.cpp:239] Iteration 3400 (0.408418 iter/s, 244.847s/100 iters), loss = 0.0113401
I0630 19:09:12.297684 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 19:09:12.297705 28406 solver.cpp:258]     Train net output #1: loss = 0.01134 (* 1 = 0.01134 loss)
I0630 19:09:12.297713 28406 sgd_solver.cpp:112] Iteration 3400, lr = 0.0001
I0630 19:12:57.151538 28406 solver.cpp:347] Iteration 3500, Testing net (#0)
I0630 19:13:15.750365 28406 solver.cpp:414]     Test net output #0: acc = 0.93375
I0630 19:13:15.750391 28406 solver.cpp:414]     Test net output #1: loss = 0.23647 (* 1 = 0.23647 loss)
I0630 19:13:18.016414 28406 solver.cpp:239] Iteration 3500 (0.406944 iter/s, 245.734s/100 iters), loss = 0.0145548
I0630 19:13:18.016450 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 19:13:18.016463 28406 solver.cpp:258]     Train net output #1: loss = 0.0145548 (* 1 = 0.0145548 loss)
I0630 19:13:18.016469 28406 sgd_solver.cpp:112] Iteration 3500, lr = 0.0001
I0630 19:17:02.809331 28406 solver.cpp:347] Iteration 3600, Testing net (#0)
I0630 19:17:21.165450 28406 solver.cpp:414]     Test net output #0: acc = 0.946875
I0630 19:17:21.165480 28406 solver.cpp:414]     Test net output #1: loss = 0.165038 (* 1 = 0.165038 loss)
I0630 19:17:23.445242 28406 solver.cpp:239] Iteration 3600 (0.407431 iter/s, 245.441s/100 iters), loss = 0.0092886
I0630 19:17:23.445283 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 19:17:23.445295 28406 solver.cpp:258]     Train net output #1: loss = 0.00928856 (* 1 = 0.00928856 loss)
I0630 19:17:23.445302 28406 sgd_solver.cpp:112] Iteration 3600, lr = 0.0001
I0630 19:21:08.059634 28406 solver.cpp:347] Iteration 3700, Testing net (#0)
I0630 19:21:26.447369 28406 solver.cpp:414]     Test net output #0: acc = 0.951875
I0630 19:21:26.447408 28406 solver.cpp:414]     Test net output #1: loss = 0.167596 (* 1 = 0.167596 loss)
I0630 19:21:28.723493 28406 solver.cpp:239] Iteration 3700 (0.407685 iter/s, 245.288s/100 iters), loss = 0.0407776
I0630 19:21:28.723531 28406 solver.cpp:258]     Train net output #0: acc = 0.96875
I0630 19:21:28.723551 28406 solver.cpp:258]     Train net output #1: loss = 0.0407775 (* 1 = 0.0407775 loss)
I0630 19:21:28.723557 28406 sgd_solver.cpp:112] Iteration 3700, lr = 0.0001
I0630 19:25:13.013432 28406 solver.cpp:347] Iteration 3800, Testing net (#0)
I0630 19:25:31.399920 28406 solver.cpp:414]     Test net output #0: acc = 0.94875
I0630 19:25:31.399960 28406 solver.cpp:414]     Test net output #1: loss = 0.170551 (* 1 = 0.170551 loss)
I0630 19:25:33.676546 28406 solver.cpp:239] Iteration 3800 (0.408228 iter/s, 244.961s/100 iters), loss = 0.0364497
I0630 19:25:33.676584 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 19:25:33.676604 28406 solver.cpp:258]     Train net output #1: loss = 0.0364497 (* 1 = 0.0364497 loss)
I0630 19:25:33.676610 28406 sgd_solver.cpp:112] Iteration 3800, lr = 0.0001
I0630 19:29:17.858328 28406 solver.cpp:347] Iteration 3900, Testing net (#0)
I0630 19:29:36.257540 28406 solver.cpp:414]     Test net output #0: acc = 0.954375
I0630 19:29:36.257570 28406 solver.cpp:414]     Test net output #1: loss = 0.163455 (* 1 = 0.163455 loss)
I0630 19:29:38.507967 28406 solver.cpp:239] Iteration 3900 (0.408433 iter/s, 244.838s/100 iters), loss = 0.0207766
I0630 19:29:38.508002 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 19:29:38.508023 28406 solver.cpp:258]     Train net output #1: loss = 0.0207766 (* 1 = 0.0207766 loss)
I0630 19:29:38.508029 28406 sgd_solver.cpp:112] Iteration 3900, lr = 0.0001
I0630 19:33:22.452186 28406 solver.cpp:464] Snapshotting to binary proto file models/mobilenet_finetune_iter_4000.caffemodel
I0630 19:33:22.478862 28406 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/mobilenet_finetune_iter_4000.solverstate
I0630 19:33:22.501704 28406 solver.cpp:347] Iteration 4000, Testing net (#0)
I0630 19:33:40.892956 28406 solver.cpp:414]     Test net output #0: acc = 0.951875
I0630 19:33:40.892982 28406 solver.cpp:414]     Test net output #1: loss = 0.169319 (* 1 = 0.169319 loss)
I0630 19:33:43.159271 28406 solver.cpp:239] Iteration 4000 (0.408734 iter/s, 244.658s/100 iters), loss = 0.0336994
I0630 19:33:43.159308 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 19:33:43.159329 28406 solver.cpp:258]     Train net output #1: loss = 0.0336994 (* 1 = 0.0336994 loss)
I0630 19:33:43.159335 28406 sgd_solver.cpp:112] Iteration 4000, lr = 0.0001
I0630 19:37:27.338646 28406 solver.cpp:347] Iteration 4100, Testing net (#0)
I0630 19:37:45.740974 28406 solver.cpp:414]     Test net output #0: acc = 0.9575
I0630 19:37:45.741003 28406 solver.cpp:414]     Test net output #1: loss = 0.149849 (* 1 = 0.149849 loss)
I0630 19:37:47.998502 28406 solver.cpp:239] Iteration 4100 (0.408421 iter/s, 244.845s/100 iters), loss = 0.00785884
I0630 19:37:47.998535 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 19:37:47.998556 28406 solver.cpp:258]     Train net output #1: loss = 0.00785882 (* 1 = 0.00785882 loss)
I0630 19:37:47.998564 28406 sgd_solver.cpp:112] Iteration 4100, lr = 0.0001
I0630 19:41:31.625000 28406 solver.cpp:347] Iteration 4200, Testing net (#0)
I0630 19:41:50.058764 28406 solver.cpp:414]     Test net output #0: acc = 0.948125
I0630 19:41:50.058791 28406 solver.cpp:414]     Test net output #1: loss = 0.19835 (* 1 = 0.19835 loss)
I0630 19:41:52.319947 28406 solver.cpp:239] Iteration 4200 (0.409287 iter/s, 244.327s/100 iters), loss = 0.0156421
I0630 19:41:52.319980 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 19:41:52.320000 28406 solver.cpp:258]     Train net output #1: loss = 0.015642 (* 1 = 0.015642 loss)
I0630 19:41:52.320008 28406 sgd_solver.cpp:112] Iteration 4200, lr = 0.0001
I0630 19:45:35.969188 28406 solver.cpp:347] Iteration 4300, Testing net (#0)
I0630 19:45:54.689888 28406 solver.cpp:414]     Test net output #0: acc = 0.945625
I0630 19:45:54.689916 28406 solver.cpp:414]     Test net output #1: loss = 0.215733 (* 1 = 0.215733 loss)
I0630 19:45:56.956750 28406 solver.cpp:239] Iteration 4300 (0.408772 iter/s, 244.635s/100 iters), loss = 0.00224393
I0630 19:45:56.956785 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 19:45:56.956806 28406 solver.cpp:258]     Train net output #1: loss = 0.00224388 (* 1 = 0.00224388 loss)
I0630 19:45:56.956812 28406 sgd_solver.cpp:112] Iteration 4300, lr = 0.0001
I0630 19:49:40.546583 28406 solver.cpp:347] Iteration 4400, Testing net (#0)
I0630 19:49:58.931092 28406 solver.cpp:414]     Test net output #0: acc = 0.9575
I0630 19:49:58.931118 28406 solver.cpp:414]     Test net output #1: loss = 0.167622 (* 1 = 0.167622 loss)
I0630 19:50:01.209764 28406 solver.cpp:239] Iteration 4400 (0.409413 iter/s, 244.252s/100 iters), loss = 0.0227511
I0630 19:50:01.209800 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 19:50:01.209820 28406 solver.cpp:258]     Train net output #1: loss = 0.0227511 (* 1 = 0.0227511 loss)
I0630 19:50:01.209827 28406 sgd_solver.cpp:112] Iteration 4400, lr = 0.0001
I0630 19:53:44.920717 28406 solver.cpp:347] Iteration 4500, Testing net (#0)
I0630 19:54:03.345772 28406 solver.cpp:414]     Test net output #0: acc = 0.944375
I0630 19:54:03.345801 28406 solver.cpp:414]     Test net output #1: loss = 0.190116 (* 1 = 0.190116 loss)
I0630 19:54:05.604728 28406 solver.cpp:239] Iteration 4500 (0.409172 iter/s, 244.396s/100 iters), loss = 0.0111035
I0630 19:54:05.604763 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 19:54:05.604784 28406 solver.cpp:258]     Train net output #1: loss = 0.0111035 (* 1 = 0.0111035 loss)
I0630 19:54:05.604789 28406 sgd_solver.cpp:112] Iteration 4500, lr = 0.0001
I0630 19:57:49.586377 28406 solver.cpp:347] Iteration 4600, Testing net (#0)
I0630 19:58:07.949635 28406 solver.cpp:414]     Test net output #0: acc = 0.95
I0630 19:58:07.949661 28406 solver.cpp:414]     Test net output #1: loss = 0.188211 (* 1 = 0.188211 loss)
I0630 19:58:10.216603 28406 solver.cpp:239] Iteration 4600 (0.408807 iter/s, 244.614s/100 iters), loss = 0.00576839
I0630 19:58:10.216636 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 19:58:10.216657 28406 solver.cpp:258]     Train net output #1: loss = 0.00576838 (* 1 = 0.00576838 loss)
I0630 19:58:10.216665 28406 sgd_solver.cpp:112] Iteration 4600, lr = 0.0001
I0630 20:01:53.922542 28406 solver.cpp:347] Iteration 4700, Testing net (#0)
I0630 20:02:12.339516 28406 solver.cpp:414]     Test net output #0: acc = 0.951875
I0630 20:02:12.339547 28406 solver.cpp:414]     Test net output #1: loss = 0.177061 (* 1 = 0.177061 loss)
I0630 20:02:14.614054 28406 solver.cpp:239] Iteration 4700 (0.409165 iter/s, 244.4s/100 iters), loss = 0.00966653
I0630 20:02:14.614094 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 20:02:14.614120 28406 solver.cpp:258]     Train net output #1: loss = 0.00966653 (* 1 = 0.00966653 loss)
I0630 20:02:14.614131 28406 sgd_solver.cpp:112] Iteration 4700, lr = 0.0001
I0630 20:05:58.321758 28406 solver.cpp:347] Iteration 4800, Testing net (#0)
I0630 20:06:16.783198 28406 solver.cpp:414]     Test net output #0: acc = 0.95375
I0630 20:06:16.783226 28406 solver.cpp:414]     Test net output #1: loss = 0.170426 (* 1 = 0.170426 loss)
I0630 20:06:19.042591 28406 solver.cpp:239] Iteration 4800 (0.409112 iter/s, 244.432s/100 iters), loss = 0.0102231
I0630 20:06:19.042627 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 20:06:19.042640 28406 solver.cpp:258]     Train net output #1: loss = 0.0102231 (* 1 = 0.0102231 loss)
I0630 20:06:19.042650 28406 sgd_solver.cpp:112] Iteration 4800, lr = 0.0001
I0630 20:10:02.615283 28406 solver.cpp:347] Iteration 4900, Testing net (#0)
I0630 20:10:20.988366 28406 solver.cpp:414]     Test net output #0: acc = 0.954375
I0630 20:10:20.988399 28406 solver.cpp:414]     Test net output #1: loss = 0.161688 (* 1 = 0.161688 loss)
I0630 20:10:23.255136 28406 solver.cpp:239] Iteration 4900 (0.409474 iter/s, 244.216s/100 iters), loss = 0.0102519
I0630 20:10:23.255172 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 20:10:23.255193 28406 solver.cpp:258]     Train net output #1: loss = 0.0102519 (* 1 = 0.0102519 loss)
I0630 20:10:23.255199 28406 sgd_solver.cpp:112] Iteration 4900, lr = 0.0001
I0630 20:14:07.242555 28406 solver.cpp:464] Snapshotting to binary proto file models/mobilenet_finetune_iter_5000.caffemodel
I0630 20:14:07.269445 28406 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/mobilenet_finetune_iter_5000.solverstate
I0630 20:14:07.292788 28406 solver.cpp:347] Iteration 5000, Testing net (#0)
I0630 20:14:25.773574 28406 solver.cpp:414]     Test net output #0: acc = 0.9475
I0630 20:14:25.773602 28406 solver.cpp:414]     Test net output #1: loss = 0.201817 (* 1 = 0.201817 loss)
I0630 20:14:28.026324 28406 solver.cpp:239] Iteration 5000 (0.408539 iter/s, 244.775s/100 iters), loss = 0.0317603
I0630 20:14:28.026358 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 20:14:28.026379 28406 solver.cpp:258]     Train net output #1: loss = 0.0317603 (* 1 = 0.0317603 loss)
I0630 20:14:28.026386 28406 sgd_solver.cpp:112] Iteration 5000, lr = 0.0001
I0630 20:18:12.219481 28406 solver.cpp:347] Iteration 5100, Testing net (#0)
I0630 20:18:30.591291 28406 solver.cpp:414]     Test net output #0: acc = 0.95625
I0630 20:18:30.591318 28406 solver.cpp:414]     Test net output #1: loss = 0.165528 (* 1 = 0.165528 loss)
I0630 20:18:32.857561 28406 solver.cpp:239] Iteration 5100 (0.408442 iter/s, 244.833s/100 iters), loss = 0.00717758
I0630 20:18:32.857605 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 20:18:32.857619 28406 solver.cpp:258]     Train net output #1: loss = 0.00717757 (* 1 = 0.00717757 loss)
I0630 20:18:32.857625 28406 sgd_solver.cpp:112] Iteration 5100, lr = 0.0001
I0630 20:22:16.799270 28406 solver.cpp:347] Iteration 5200, Testing net (#0)
I0630 20:22:35.201138 28406 solver.cpp:414]     Test net output #0: acc = 0.95
I0630 20:22:35.201189 28406 solver.cpp:414]     Test net output #1: loss = 0.190814 (* 1 = 0.190814 loss)
I0630 20:22:37.478667 28406 solver.cpp:239] Iteration 5200 (0.408794 iter/s, 244.622s/100 iters), loss = 0.0845318
I0630 20:22:37.478701 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 20:22:37.478721 28406 solver.cpp:258]     Train net output #1: loss = 0.0845318 (* 1 = 0.0845318 loss)
I0630 20:22:37.478729 28406 sgd_solver.cpp:112] Iteration 5200, lr = 0.0001
I0630 20:26:21.376591 28406 solver.cpp:347] Iteration 5300, Testing net (#0)
I0630 20:26:39.778103 28406 solver.cpp:414]     Test net output #0: acc = 0.95125
I0630 20:26:39.778131 28406 solver.cpp:414]     Test net output #1: loss = 0.189732 (* 1 = 0.189732 loss)
I0630 20:26:42.034098 28406 solver.cpp:239] Iteration 5300 (0.408902 iter/s, 244.557s/100 iters), loss = 0.0126979
I0630 20:26:42.034134 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 20:26:42.034154 28406 solver.cpp:258]     Train net output #1: loss = 0.0126979 (* 1 = 0.0126979 loss)
I0630 20:26:42.034162 28406 sgd_solver.cpp:112] Iteration 5300, lr = 0.0001
I0630 20:30:26.242130 28406 solver.cpp:347] Iteration 5400, Testing net (#0)
I0630 20:30:44.771652 28406 solver.cpp:414]     Test net output #0: acc = 0.95125
I0630 20:30:44.771687 28406 solver.cpp:414]     Test net output #1: loss = 0.190747 (* 1 = 0.190747 loss)
I0630 20:30:47.067203 28406 solver.cpp:239] Iteration 5400 (0.408104 iter/s, 245.035s/100 iters), loss = 0.191056
I0630 20:30:47.067237 28406 solver.cpp:258]     Train net output #0: acc = 0.9375
I0630 20:30:47.067250 28406 solver.cpp:258]     Train net output #1: loss = 0.191056 (* 1 = 0.191056 loss)
I0630 20:30:47.067256 28406 sgd_solver.cpp:112] Iteration 5400, lr = 0.0001
I0630 20:34:30.801407 28406 solver.cpp:347] Iteration 5500, Testing net (#0)
I0630 20:34:49.255653 28406 solver.cpp:414]     Test net output #0: acc = 0.948125
I0630 20:34:49.255686 28406 solver.cpp:414]     Test net output #1: loss = 0.203148 (* 1 = 0.203148 loss)
I0630 20:34:51.521122 28406 solver.cpp:239] Iteration 5500 (0.409071 iter/s, 244.457s/100 iters), loss = 0.00449046
I0630 20:34:51.521157 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 20:34:51.521178 28406 solver.cpp:258]     Train net output #1: loss = 0.00449048 (* 1 = 0.00449048 loss)
I0630 20:34:51.521188 28406 sgd_solver.cpp:112] Iteration 5500, lr = 0.0001
I0630 20:38:35.377543 28406 solver.cpp:347] Iteration 5600, Testing net (#0)
I0630 20:38:53.776037 28406 solver.cpp:414]     Test net output #0: acc = 0.958125
I0630 20:38:53.776063 28406 solver.cpp:414]     Test net output #1: loss = 0.164838 (* 1 = 0.164838 loss)
I0630 20:38:56.034415 28406 solver.cpp:239] Iteration 5600 (0.408971 iter/s, 244.516s/100 iters), loss = 0.00532923
I0630 20:38:56.034452 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 20:38:56.034473 28406 solver.cpp:258]     Train net output #1: loss = 0.00532924 (* 1 = 0.00532924 loss)
I0630 20:38:56.034479 28406 sgd_solver.cpp:112] Iteration 5600, lr = 0.0001
I0630 20:42:39.891631 28406 solver.cpp:347] Iteration 5700, Testing net (#0)
I0630 20:42:58.286715 28406 solver.cpp:414]     Test net output #0: acc = 0.95
I0630 20:42:58.286746 28406 solver.cpp:414]     Test net output #1: loss = 0.232165 (* 1 = 0.232165 loss)
I0630 20:43:00.564370 28406 solver.cpp:239] Iteration 5700 (0.408943 iter/s, 244.533s/100 iters), loss = 0.00622976
I0630 20:43:00.564405 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 20:43:00.564426 28406 solver.cpp:258]     Train net output #1: loss = 0.00622976 (* 1 = 0.00622976 loss)
I0630 20:43:00.564432 28406 sgd_solver.cpp:112] Iteration 5700, lr = 0.0001
I0630 20:46:44.799690 28406 solver.cpp:347] Iteration 5800, Testing net (#0)
I0630 20:47:03.388958 28406 solver.cpp:414]     Test net output #0: acc = 0.95625
I0630 20:47:03.388998 28406 solver.cpp:414]     Test net output #1: loss = 0.183017 (* 1 = 0.183017 loss)
I0630 20:47:05.785817 28406 solver.cpp:239] Iteration 5800 (0.407789 iter/s, 245.225s/100 iters), loss = 0.0358748
I0630 20:47:05.785874 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 20:47:05.785897 28406 solver.cpp:258]     Train net output #1: loss = 0.0358749 (* 1 = 0.0358749 loss)
I0630 20:47:05.785905 28406 sgd_solver.cpp:112] Iteration 5800, lr = 0.0001
I0630 20:50:49.764470 28406 solver.cpp:347] Iteration 5900, Testing net (#0)
I0630 20:51:08.191475 28406 solver.cpp:414]     Test net output #0: acc = 0.945625
I0630 20:51:08.191506 28406 solver.cpp:414]     Test net output #1: loss = 0.195211 (* 1 = 0.195211 loss)
I0630 20:51:10.455102 28406 solver.cpp:239] Iteration 5900 (0.408709 iter/s, 244.673s/100 iters), loss = 0.002187
I0630 20:51:10.455140 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 20:51:10.455162 28406 solver.cpp:258]     Train net output #1: loss = 0.00218701 (* 1 = 0.00218701 loss)
I0630 20:51:10.455168 28406 sgd_solver.cpp:112] Iteration 5900, lr = 0.0001
I0630 20:54:54.298363 28406 solver.cpp:464] Snapshotting to binary proto file models/mobilenet_finetune_iter_6000.caffemodel
I0630 20:54:54.326135 28406 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/mobilenet_finetune_iter_6000.solverstate
I0630 20:54:54.349524 28406 solver.cpp:347] Iteration 6000, Testing net (#0)
I0630 20:55:12.754786 28406 solver.cpp:414]     Test net output #0: acc = 0.948125
I0630 20:55:12.754812 28406 solver.cpp:414]     Test net output #1: loss = 0.20691 (* 1 = 0.20691 loss)
I0630 20:55:15.032480 28406 solver.cpp:239] Iteration 6000 (0.408856 iter/s, 244.585s/100 iters), loss = 0.0299733
I0630 20:55:15.032514 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 20:55:15.032536 28406 solver.cpp:258]     Train net output #1: loss = 0.0299733 (* 1 = 0.0299733 loss)
I0630 20:55:15.032542 28406 sgd_solver.cpp:112] Iteration 6000, lr = 0.0001
I0630 20:58:58.665884 28406 solver.cpp:347] Iteration 6100, Testing net (#0)
I0630 20:59:17.075711 28406 solver.cpp:414]     Test net output #0: acc = 0.9525
I0630 20:59:17.075737 28406 solver.cpp:414]     Test net output #1: loss = 0.179756 (* 1 = 0.179756 loss)
I0630 20:59:19.338873 28406 solver.cpp:239] Iteration 6100 (0.409312 iter/s, 244.312s/100 iters), loss = 0.00739438
I0630 20:59:19.338910 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 20:59:19.338923 28406 solver.cpp:258]     Train net output #1: loss = 0.00739438 (* 1 = 0.00739438 loss)
I0630 20:59:19.338930 28406 sgd_solver.cpp:112] Iteration 6100, lr = 0.0001
I0630 21:03:03.062041 28406 solver.cpp:347] Iteration 6200, Testing net (#0)
I0630 21:03:21.583417 28406 solver.cpp:414]     Test net output #0: acc = 0.959375
I0630 21:03:21.583464 28406 solver.cpp:414]     Test net output #1: loss = 0.163954 (* 1 = 0.163954 loss)
I0630 21:03:23.858883 28406 solver.cpp:239] Iteration 6200 (0.408956 iter/s, 244.525s/100 iters), loss = 0.00733886
I0630 21:03:23.858920 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 21:03:23.858932 28406 solver.cpp:258]     Train net output #1: loss = 0.00733886 (* 1 = 0.00733886 loss)
I0630 21:03:23.858939 28406 sgd_solver.cpp:112] Iteration 6200, lr = 0.0001
I0630 21:07:08.359719 28406 solver.cpp:347] Iteration 6300, Testing net (#0)
I0630 21:07:27.006652 28406 solver.cpp:414]     Test net output #0: acc = 0.94875
I0630 21:07:27.006681 28406 solver.cpp:414]     Test net output #1: loss = 0.212505 (* 1 = 0.212505 loss)
I0630 21:07:29.321259 28406 solver.cpp:239] Iteration 6300 (0.407387 iter/s, 245.467s/100 iters), loss = 0.0169176
I0630 21:07:29.321293 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 21:07:29.321313 28406 solver.cpp:258]     Train net output #1: loss = 0.0169176 (* 1 = 0.0169176 loss)
I0630 21:07:29.321321 28406 sgd_solver.cpp:112] Iteration 6300, lr = 0.0001
I0630 21:11:13.894940 28406 solver.cpp:347] Iteration 6400, Testing net (#0)
I0630 21:11:32.305092 28406 solver.cpp:414]     Test net output #0: acc = 0.955
I0630 21:11:32.305125 28406 solver.cpp:414]     Test net output #1: loss = 0.160268 (* 1 = 0.160268 loss)
I0630 21:11:34.577162 28406 solver.cpp:239] Iteration 6400 (0.40773 iter/s, 245.26s/100 iters), loss = 0.00413011
I0630 21:11:34.577220 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 21:11:34.577242 28406 solver.cpp:258]     Train net output #1: loss = 0.0041301 (* 1 = 0.0041301 loss)
I0630 21:11:34.577250 28406 sgd_solver.cpp:112] Iteration 6400, lr = 0.0001
I0630 21:15:18.676867 28406 solver.cpp:347] Iteration 6500, Testing net (#0)
I0630 21:15:37.047133 28406 solver.cpp:414]     Test net output #0: acc = 0.945625
I0630 21:15:37.047160 28406 solver.cpp:414]     Test net output #1: loss = 0.229921 (* 1 = 0.229921 loss)
I0630 21:15:39.314961 28406 solver.cpp:239] Iteration 6500 (0.408594 iter/s, 244.742s/100 iters), loss = 0.000745345
I0630 21:15:39.314994 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 21:15:39.315016 28406 solver.cpp:258]     Train net output #1: loss = 0.00074533 (* 1 = 0.00074533 loss)
I0630 21:15:39.315021 28406 sgd_solver.cpp:112] Iteration 6500, lr = 0.0001
I0630 21:19:22.859786 28406 solver.cpp:347] Iteration 6600, Testing net (#0)
I0630 21:19:41.305166 28406 solver.cpp:414]     Test net output #0: acc = 0.96
I0630 21:19:41.305205 28406 solver.cpp:414]     Test net output #1: loss = 0.180473 (* 1 = 0.180473 loss)
I0630 21:19:43.565376 28406 solver.cpp:239] Iteration 6600 (0.409409 iter/s, 244.254s/100 iters), loss = 0.0021601
I0630 21:19:43.565410 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 21:19:43.565430 28406 solver.cpp:258]     Train net output #1: loss = 0.00216009 (* 1 = 0.00216009 loss)
I0630 21:19:43.565438 28406 sgd_solver.cpp:112] Iteration 6600, lr = 0.0001
I0630 21:23:27.578136 28406 solver.cpp:347] Iteration 6700, Testing net (#0)
I0630 21:23:45.967993 28406 solver.cpp:414]     Test net output #0: acc = 0.95375
I0630 21:23:45.968024 28406 solver.cpp:414]     Test net output #1: loss = 0.187905 (* 1 = 0.187905 loss)
I0630 21:23:48.231024 28406 solver.cpp:239] Iteration 6700 (0.408714 iter/s, 244.67s/100 iters), loss = 0.00148061
I0630 21:23:48.231062 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 21:23:48.231083 28406 solver.cpp:258]     Train net output #1: loss = 0.00148059 (* 1 = 0.00148059 loss)
I0630 21:23:48.231091 28406 sgd_solver.cpp:112] Iteration 6700, lr = 0.0001
I0630 21:27:32.419200 28406 solver.cpp:347] Iteration 6800, Testing net (#0)
I0630 21:27:50.819977 28406 solver.cpp:414]     Test net output #0: acc = 0.953125
I0630 21:27:50.820005 28406 solver.cpp:414]     Test net output #1: loss = 0.181974 (* 1 = 0.181974 loss)
I0630 21:27:53.081001 28406 solver.cpp:239] Iteration 6800 (0.408401 iter/s, 244.857s/100 iters), loss = 0.00918255
I0630 21:27:53.081044 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 21:27:53.081056 28406 solver.cpp:258]     Train net output #1: loss = 0.00918253 (* 1 = 0.00918253 loss)
I0630 21:27:53.081063 28406 sgd_solver.cpp:112] Iteration 6800, lr = 0.0001
I0630 21:31:37.331774 28406 solver.cpp:347] Iteration 6900, Testing net (#0)
I0630 21:31:55.779177 28406 solver.cpp:414]     Test net output #0: acc = 0.953125
I0630 21:31:55.779204 28406 solver.cpp:414]     Test net output #1: loss = 0.19018 (* 1 = 0.19018 loss)
I0630 21:31:58.055868 28406 solver.cpp:239] Iteration 6900 (0.408193 iter/s, 244.982s/100 iters), loss = 0.0256294
I0630 21:31:58.055912 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 21:31:58.055925 28406 solver.cpp:258]     Train net output #1: loss = 0.0256294 (* 1 = 0.0256294 loss)
I0630 21:31:58.055932 28406 sgd_solver.cpp:112] Iteration 6900, lr = 0.0001
I0630 21:35:42.127542 28406 solver.cpp:464] Snapshotting to binary proto file models/mobilenet_finetune_iter_7000.caffemodel
I0630 21:35:42.154439 28406 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/mobilenet_finetune_iter_7000.solverstate
I0630 21:35:42.177058 28406 solver.cpp:347] Iteration 7000, Testing net (#0)
I0630 21:36:00.600179 28406 solver.cpp:414]     Test net output #0: acc = 0.9525
I0630 21:36:00.600208 28406 solver.cpp:414]     Test net output #1: loss = 0.211275 (* 1 = 0.211275 loss)
I0630 21:36:02.879608 28406 solver.cpp:239] Iteration 7000 (0.408447 iter/s, 244.83s/100 iters), loss = 0.00112638
I0630 21:36:02.879653 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 21:36:02.879667 28406 solver.cpp:258]     Train net output #1: loss = 0.00112636 (* 1 = 0.00112636 loss)
I0630 21:36:02.879674 28406 sgd_solver.cpp:112] Iteration 7000, lr = 0.0001
I0630 21:39:47.223562 28406 solver.cpp:347] Iteration 7100, Testing net (#0)
I0630 21:40:05.689426 28406 solver.cpp:414]     Test net output #0: acc = 0.961875
I0630 21:40:05.689453 28406 solver.cpp:414]     Test net output #1: loss = 0.156515 (* 1 = 0.156515 loss)
I0630 21:40:07.961002 28406 solver.cpp:239] Iteration 7100 (0.408019 iter/s, 245.087s/100 iters), loss = 0.0103387
I0630 21:40:07.961037 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 21:40:07.961057 28406 solver.cpp:258]     Train net output #1: loss = 0.0103387 (* 1 = 0.0103387 loss)
I0630 21:40:07.961063 28406 sgd_solver.cpp:112] Iteration 7100, lr = 0.0001
I0630 21:43:51.948468 28406 solver.cpp:347] Iteration 7200, Testing net (#0)
I0630 21:44:10.362198 28406 solver.cpp:414]     Test net output #0: acc = 0.949375
I0630 21:44:10.362226 28406 solver.cpp:414]     Test net output #1: loss = 0.223261 (* 1 = 0.223261 loss)
I0630 21:44:12.621335 28406 solver.cpp:239] Iteration 7200 (0.408721 iter/s, 244.665s/100 iters), loss = 0.0585181
I0630 21:44:12.621371 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 21:44:12.621384 28406 solver.cpp:258]     Train net output #1: loss = 0.058518 (* 1 = 0.058518 loss)
I0630 21:44:12.621392 28406 sgd_solver.cpp:112] Iteration 7200, lr = 0.0001
I0630 21:47:56.804668 28406 solver.cpp:347] Iteration 7300, Testing net (#0)
I0630 21:48:15.289758 28406 solver.cpp:414]     Test net output #0: acc = 0.955625
I0630 21:48:15.289788 28406 solver.cpp:414]     Test net output #1: loss = 0.191876 (* 1 = 0.191876 loss)
I0630 21:48:17.572871 28406 solver.cpp:239] Iteration 7300 (0.408236 iter/s, 244.956s/100 iters), loss = 0.00379092
I0630 21:48:17.572911 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 21:48:17.572932 28406 solver.cpp:258]     Train net output #1: loss = 0.0037909 (* 1 = 0.0037909 loss)
I0630 21:48:17.572937 28406 sgd_solver.cpp:112] Iteration 7300, lr = 0.0001
I0630 21:52:01.979023 28406 solver.cpp:347] Iteration 7400, Testing net (#0)
I0630 21:52:20.355607 28406 solver.cpp:414]     Test net output #0: acc = 0.953125
I0630 21:52:20.355635 28406 solver.cpp:414]     Test net output #1: loss = 0.185378 (* 1 = 0.185378 loss)
I0630 21:52:22.627688 28406 solver.cpp:239] Iteration 7400 (0.408064 iter/s, 245.06s/100 iters), loss = 0.00310059
I0630 21:52:22.627722 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 21:52:22.627743 28406 solver.cpp:258]     Train net output #1: loss = 0.00310057 (* 1 = 0.00310057 loss)
I0630 21:52:22.627750 28406 sgd_solver.cpp:112] Iteration 7400, lr = 0.0001
I0630 21:56:06.524092 28406 solver.cpp:347] Iteration 7500, Testing net (#0)
I0630 21:56:24.919706 28406 solver.cpp:414]     Test net output #0: acc = 0.95125
I0630 21:56:24.919734 28406 solver.cpp:414]     Test net output #1: loss = 0.213864 (* 1 = 0.213864 loss)
I0630 21:56:27.183965 28406 solver.cpp:239] Iteration 7500 (0.408896 iter/s, 244.561s/100 iters), loss = 0.00733405
I0630 21:56:27.184000 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 21:56:27.184020 28406 solver.cpp:258]     Train net output #1: loss = 0.00733404 (* 1 = 0.00733404 loss)
I0630 21:56:27.184027 28406 sgd_solver.cpp:112] Iteration 7500, lr = 0.0001
I0630 22:00:11.135165 28406 solver.cpp:347] Iteration 7600, Testing net (#0)
I0630 22:00:29.574586 28406 solver.cpp:414]     Test net output #0: acc = 0.949375
I0630 22:00:29.574614 28406 solver.cpp:414]     Test net output #1: loss = 0.227942 (* 1 = 0.227942 loss)
I0630 22:00:31.828737 28406 solver.cpp:239] Iteration 7600 (0.408751 iter/s, 244.648s/100 iters), loss = 0.0053238
I0630 22:00:31.828773 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 22:00:31.828794 28406 solver.cpp:258]     Train net output #1: loss = 0.00532381 (* 1 = 0.00532381 loss)
I0630 22:00:31.828800 28406 sgd_solver.cpp:112] Iteration 7600, lr = 0.0001
I0630 22:04:15.835582 28406 solver.cpp:347] Iteration 7700, Testing net (#0)
I0630 22:04:34.226567 28406 solver.cpp:414]     Test net output #0: acc = 0.95
I0630 22:04:34.226601 28406 solver.cpp:414]     Test net output #1: loss = 0.200991 (* 1 = 0.200991 loss)
I0630 22:04:36.487686 28406 solver.cpp:239] Iteration 7700 (0.40873 iter/s, 244.66s/100 iters), loss = 0.00404965
I0630 22:04:36.487722 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 22:04:36.487742 28406 solver.cpp:258]     Train net output #1: loss = 0.00404966 (* 1 = 0.00404966 loss)
I0630 22:04:36.487749 28406 sgd_solver.cpp:112] Iteration 7700, lr = 0.0001
I0630 22:08:20.533082 28406 solver.cpp:347] Iteration 7800, Testing net (#0)
I0630 22:08:38.924768 28406 solver.cpp:414]     Test net output #0: acc = 0.9525
I0630 22:08:38.924796 28406 solver.cpp:414]     Test net output #1: loss = 0.20568 (* 1 = 0.20568 loss)
I0630 22:08:41.179083 28406 solver.cpp:239] Iteration 7800 (0.408675 iter/s, 244.694s/100 iters), loss = 0.00909347
I0630 22:08:41.179119 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 22:08:41.179141 28406 solver.cpp:258]     Train net output #1: loss = 0.0090935 (* 1 = 0.0090935 loss)
I0630 22:08:41.179147 28406 sgd_solver.cpp:112] Iteration 7800, lr = 0.0001
I0630 22:12:24.972208 28406 solver.cpp:347] Iteration 7900, Testing net (#0)
I0630 22:12:43.355315 28406 solver.cpp:414]     Test net output #0: acc = 0.960625
I0630 22:12:43.355348 28406 solver.cpp:414]     Test net output #1: loss = 0.159792 (* 1 = 0.159792 loss)
I0630 22:12:45.637785 28406 solver.cpp:239] Iteration 7900 (0.409062 iter/s, 244.461s/100 iters), loss = 0.00591533
I0630 22:12:45.637830 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 22:12:45.637843 28406 solver.cpp:258]     Train net output #1: loss = 0.00591535 (* 1 = 0.00591535 loss)
I0630 22:12:45.637850 28406 sgd_solver.cpp:112] Iteration 7900, lr = 0.0001
I0630 22:16:29.556118 28406 solver.cpp:464] Snapshotting to binary proto file models/mobilenet_finetune_iter_8000.caffemodel
I0630 22:16:29.582947 28406 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/mobilenet_finetune_iter_8000.solverstate
I0630 22:16:29.605788 28406 solver.cpp:347] Iteration 8000, Testing net (#0)
I0630 22:16:48.006711 28406 solver.cpp:414]     Test net output #0: acc = 0.951875
I0630 22:16:48.006738 28406 solver.cpp:414]     Test net output #1: loss = 0.206196 (* 1 = 0.206196 loss)
I0630 22:16:50.264273 28406 solver.cpp:239] Iteration 8000 (0.408781 iter/s, 244.63s/100 iters), loss = 0.00344093
I0630 22:16:50.264307 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 22:16:50.264319 28406 solver.cpp:258]     Train net output #1: loss = 0.00344097 (* 1 = 0.00344097 loss)
I0630 22:16:50.264325 28406 sgd_solver.cpp:112] Iteration 8000, lr = 0.0001
I0630 22:20:34.164768 28406 solver.cpp:347] Iteration 8100, Testing net (#0)
I0630 22:20:52.566987 28406 solver.cpp:414]     Test net output #0: acc = 0.954375
I0630 22:20:52.567013 28406 solver.cpp:414]     Test net output #1: loss = 0.192082 (* 1 = 0.192082 loss)
I0630 22:20:54.844234 28406 solver.cpp:239] Iteration 8100 (0.408859 iter/s, 244.583s/100 iters), loss = 0.000912398
I0630 22:20:54.844269 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 22:20:54.844291 28406 solver.cpp:258]     Train net output #1: loss = 0.00091243 (* 1 = 0.00091243 loss)
I0630 22:20:54.844298 28406 sgd_solver.cpp:112] Iteration 8100, lr = 0.0001
I0630 22:24:38.840971 28406 solver.cpp:347] Iteration 8200, Testing net (#0)
I0630 22:24:57.268985 28406 solver.cpp:414]     Test net output #0: acc = 0.955625
I0630 22:24:57.269014 28406 solver.cpp:414]     Test net output #1: loss = 0.180619 (* 1 = 0.180619 loss)
I0630 22:24:59.535254 28406 solver.cpp:239] Iteration 8200 (0.408673 iter/s, 244.695s/100 iters), loss = 0.00727618
I0630 22:24:59.535288 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 22:24:59.535308 28406 solver.cpp:258]     Train net output #1: loss = 0.00727622 (* 1 = 0.00727622 loss)
I0630 22:24:59.535315 28406 sgd_solver.cpp:112] Iteration 8200, lr = 0.0001
I0630 22:28:43.450350 28406 solver.cpp:347] Iteration 8300, Testing net (#0)
I0630 22:29:01.848146 28406 solver.cpp:414]     Test net output #0: acc = 0.950625
I0630 22:29:01.848173 28406 solver.cpp:414]     Test net output #1: loss = 0.205742 (* 1 = 0.205742 loss)
I0630 22:29:04.103946 28406 solver.cpp:239] Iteration 8300 (0.408877 iter/s, 244.572s/100 iters), loss = 0.0110739
I0630 22:29:04.103983 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 22:29:04.104003 28406 solver.cpp:258]     Train net output #1: loss = 0.0110739 (* 1 = 0.0110739 loss)
I0630 22:29:04.104010 28406 sgd_solver.cpp:112] Iteration 8300, lr = 0.0001
I0630 22:32:48.056461 28406 solver.cpp:347] Iteration 8400, Testing net (#0)
I0630 22:33:06.448765 28406 solver.cpp:414]     Test net output #0: acc = 0.95625
I0630 22:33:06.448791 28406 solver.cpp:414]     Test net output #1: loss = 0.190327 (* 1 = 0.190327 loss)
I0630 22:33:08.715137 28406 solver.cpp:239] Iteration 8400 (0.408806 iter/s, 244.615s/100 iters), loss = 0.032979
I0630 22:33:08.715173 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 22:33:08.715193 28406 solver.cpp:258]     Train net output #1: loss = 0.0329791 (* 1 = 0.0329791 loss)
I0630 22:33:08.715199 28406 sgd_solver.cpp:112] Iteration 8400, lr = 0.0001
I0630 22:36:52.700779 28406 solver.cpp:347] Iteration 8500, Testing net (#0)
I0630 22:37:11.083622 28406 solver.cpp:414]     Test net output #0: acc = 0.95125
I0630 22:37:11.083653 28406 solver.cpp:414]     Test net output #1: loss = 0.210772 (* 1 = 0.210772 loss)
I0630 22:37:13.343106 28406 solver.cpp:239] Iteration 8500 (0.408776 iter/s, 244.633s/100 iters), loss = 0.000554923
I0630 22:37:13.343140 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 22:37:13.343161 28406 solver.cpp:258]     Train net output #1: loss = 0.000554935 (* 1 = 0.000554935 loss)
I0630 22:37:13.343168 28406 sgd_solver.cpp:112] Iteration 8500, lr = 0.0001
I0630 22:40:57.269857 28406 solver.cpp:347] Iteration 8600, Testing net (#0)
I0630 22:41:15.669005 28406 solver.cpp:414]     Test net output #0: acc = 0.959375
I0630 22:41:15.669032 28406 solver.cpp:414]     Test net output #1: loss = 0.18929 (* 1 = 0.18929 loss)
I0630 22:41:17.937633 28406 solver.cpp:239] Iteration 8600 (0.408832 iter/s, 244.599s/100 iters), loss = 0.0115814
I0630 22:41:17.937669 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 22:41:17.937690 28406 solver.cpp:258]     Train net output #1: loss = 0.0115814 (* 1 = 0.0115814 loss)
I0630 22:41:17.937695 28406 sgd_solver.cpp:112] Iteration 8600, lr = 0.0001
I0630 22:45:01.810092 28406 solver.cpp:347] Iteration 8700, Testing net (#0)
I0630 22:45:20.200507 28406 solver.cpp:414]     Test net output #0: acc = 0.95
I0630 22:45:20.200538 28406 solver.cpp:414]     Test net output #1: loss = 0.2036 (* 1 = 0.2036 loss)
I0630 22:45:22.492264 28406 solver.cpp:239] Iteration 8700 (0.408899 iter/s, 244.559s/100 iters), loss = 0.000745047
I0630 22:45:22.492301 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 22:45:22.492322 28406 solver.cpp:258]     Train net output #1: loss = 0.000745028 (* 1 = 0.000745028 loss)
I0630 22:45:22.492329 28406 sgd_solver.cpp:112] Iteration 8700, lr = 0.0001
I0630 22:49:06.993778 28406 solver.cpp:347] Iteration 8800, Testing net (#0)
I0630 22:49:25.419953 28406 solver.cpp:414]     Test net output #0: acc = 0.96125
I0630 22:49:25.419981 28406 solver.cpp:414]     Test net output #1: loss = 0.17552 (* 1 = 0.17552 loss)
I0630 22:49:27.677935 28406 solver.cpp:239] Iteration 8800 (0.407847 iter/s, 245.19s/100 iters), loss = 0.00314428
I0630 22:49:27.677970 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 22:49:27.677991 28406 solver.cpp:258]     Train net output #1: loss = 0.00314426 (* 1 = 0.00314426 loss)
I0630 22:49:27.677999 28406 sgd_solver.cpp:112] Iteration 8800, lr = 0.0001
I0630 22:53:12.049999 28406 solver.cpp:347] Iteration 8900, Testing net (#0)
I0630 22:53:30.482311 28406 solver.cpp:414]     Test net output #0: acc = 0.958125
I0630 22:53:30.482336 28406 solver.cpp:414]     Test net output #1: loss = 0.181307 (* 1 = 0.181307 loss)
I0630 22:53:32.745076 28406 solver.cpp:239] Iteration 8900 (0.408045 iter/s, 245.071s/100 iters), loss = 0.00125714
I0630 22:53:32.745115 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 22:53:32.745134 28406 solver.cpp:258]     Train net output #1: loss = 0.00125711 (* 1 = 0.00125711 loss)
I0630 22:53:32.745141 28406 sgd_solver.cpp:112] Iteration 8900, lr = 0.0001
I0630 22:57:16.931567 28406 solver.cpp:464] Snapshotting to binary proto file models/mobilenet_finetune_iter_9000.caffemodel
I0630 22:57:16.959249 28406 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/mobilenet_finetune_iter_9000.solverstate
I0630 22:57:16.982233 28406 solver.cpp:347] Iteration 9000, Testing net (#0)
I0630 22:57:35.390903 28406 solver.cpp:414]     Test net output #0: acc = 0.9525
I0630 22:57:35.390929 28406 solver.cpp:414]     Test net output #1: loss = 0.193176 (* 1 = 0.193176 loss)
I0630 22:57:37.681185 28406 solver.cpp:239] Iteration 9000 (0.408263 iter/s, 244.94s/100 iters), loss = 0.00311276
I0630 22:57:37.681221 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 22:57:37.681241 28406 solver.cpp:258]     Train net output #1: loss = 0.00311272 (* 1 = 0.00311272 loss)
I0630 22:57:37.681248 28406 sgd_solver.cpp:112] Iteration 9000, lr = 0.0001
I0630 23:01:22.498051 28406 solver.cpp:347] Iteration 9100, Testing net (#0)
I0630 23:01:40.849203 28406 solver.cpp:414]     Test net output #0: acc = 0.9575
I0630 23:01:40.849231 28406 solver.cpp:414]     Test net output #1: loss = 0.167734 (* 1 = 0.167734 loss)
I0630 23:01:43.110414 28406 solver.cpp:239] Iteration 9100 (0.407443 iter/s, 245.433s/100 iters), loss = 0.000692165
I0630 23:01:43.110448 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 23:01:43.110468 28406 solver.cpp:258]     Train net output #1: loss = 0.000692119 (* 1 = 0.000692119 loss)
I0630 23:01:43.110476 28406 sgd_solver.cpp:112] Iteration 9100, lr = 0.0001
I0630 23:05:26.920691 28406 solver.cpp:347] Iteration 9200, Testing net (#0)
I0630 23:05:45.357101 28406 solver.cpp:414]     Test net output #0: acc = 0.95
I0630 23:05:45.357134 28406 solver.cpp:414]     Test net output #1: loss = 0.2007 (* 1 = 0.2007 loss)
I0630 23:05:47.639720 28406 solver.cpp:239] Iteration 9200 (0.408942 iter/s, 244.533s/100 iters), loss = 0.00514671
I0630 23:05:47.639755 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 23:05:47.639775 28406 solver.cpp:258]     Train net output #1: loss = 0.00514665 (* 1 = 0.00514665 loss)
I0630 23:05:47.639782 28406 sgd_solver.cpp:112] Iteration 9200, lr = 0.0001
I0630 23:09:31.749509 28406 solver.cpp:347] Iteration 9300, Testing net (#0)
I0630 23:09:50.124449 28406 solver.cpp:414]     Test net output #0: acc = 0.959375
I0630 23:09:50.124477 28406 solver.cpp:414]     Test net output #1: loss = 0.170714 (* 1 = 0.170714 loss)
I0630 23:09:52.384865 28406 solver.cpp:239] Iteration 9300 (0.408577 iter/s, 244.752s/100 iters), loss = 0.00287134
I0630 23:09:52.384901 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 23:09:52.384922 28406 solver.cpp:258]     Train net output #1: loss = 0.00287129 (* 1 = 0.00287129 loss)
I0630 23:09:52.384928 28406 sgd_solver.cpp:112] Iteration 9300, lr = 0.0001
I0630 23:13:36.056499 28406 solver.cpp:347] Iteration 9400, Testing net (#0)
I0630 23:13:54.456650 28406 solver.cpp:414]     Test net output #0: acc = 0.95875
I0630 23:13:54.456681 28406 solver.cpp:414]     Test net output #1: loss = 0.151877 (* 1 = 0.151877 loss)
I0630 23:13:56.712397 28406 solver.cpp:239] Iteration 9400 (0.409274 iter/s, 244.335s/100 iters), loss = 0.00388958
I0630 23:13:56.712433 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 23:13:56.712453 28406 solver.cpp:258]     Train net output #1: loss = 0.00388952 (* 1 = 0.00388952 loss)
I0630 23:13:56.712460 28406 sgd_solver.cpp:112] Iteration 9400, lr = 0.0001
I0630 23:17:40.674088 28406 solver.cpp:347] Iteration 9500, Testing net (#0)
I0630 23:17:59.087363 28406 solver.cpp:414]     Test net output #0: acc = 0.956875
I0630 23:17:59.087389 28406 solver.cpp:414]     Test net output #1: loss = 0.186563 (* 1 = 0.186563 loss)
I0630 23:18:01.354815 28406 solver.cpp:239] Iteration 9500 (0.408749 iter/s, 244.649s/100 iters), loss = 0.00184116
I0630 23:18:01.354851 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 23:18:01.354871 28406 solver.cpp:258]     Train net output #1: loss = 0.0018411 (* 1 = 0.0018411 loss)
I0630 23:18:01.354877 28406 sgd_solver.cpp:112] Iteration 9500, lr = 0.0001
I0630 23:21:45.111145 28406 solver.cpp:347] Iteration 9600, Testing net (#0)
I0630 23:22:03.532943 28406 solver.cpp:414]     Test net output #0: acc = 0.960625
I0630 23:22:03.532971 28406 solver.cpp:414]     Test net output #1: loss = 0.1511 (* 1 = 0.1511 loss)
I0630 23:22:05.800709 28406 solver.cpp:239] Iteration 9600 (0.409079 iter/s, 244.451s/100 iters), loss = 0.0831794
I0630 23:22:05.800746 28406 solver.cpp:258]     Train net output #0: acc = 0.96875
I0630 23:22:05.800766 28406 solver.cpp:258]     Train net output #1: loss = 0.0831794 (* 1 = 0.0831794 loss)
I0630 23:22:05.800773 28406 sgd_solver.cpp:112] Iteration 9600, lr = 0.0001
I0630 23:25:49.791091 28406 solver.cpp:347] Iteration 9700, Testing net (#0)
I0630 23:26:08.162325 28406 solver.cpp:414]     Test net output #0: acc = 0.963125
I0630 23:26:08.162353 28406 solver.cpp:414]     Test net output #1: loss = 0.1647 (* 1 = 0.1647 loss)
I0630 23:26:10.427757 28406 solver.cpp:239] Iteration 9700 (0.408777 iter/s, 244.632s/100 iters), loss = 0.00740258
I0630 23:26:10.427803 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 23:26:10.427815 28406 solver.cpp:258]     Train net output #1: loss = 0.00740253 (* 1 = 0.00740253 loss)
I0630 23:26:10.427822 28406 sgd_solver.cpp:112] Iteration 9700, lr = 0.0001
I0630 23:29:54.305398 28406 solver.cpp:347] Iteration 9800, Testing net (#0)
I0630 23:30:12.686112 28406 solver.cpp:414]     Test net output #0: acc = 0.9525
I0630 23:30:12.686141 28406 solver.cpp:414]     Test net output #1: loss = 0.190596 (* 1 = 0.190596 loss)
I0630 23:30:14.942484 28406 solver.cpp:239] Iteration 9800 (0.408965 iter/s, 244.52s/100 iters), loss = 0.0349316
I0630 23:30:14.942519 28406 solver.cpp:258]     Train net output #0: acc = 0.984375
I0630 23:30:14.942539 28406 solver.cpp:258]     Train net output #1: loss = 0.0349315 (* 1 = 0.0349315 loss)
I0630 23:30:14.942546 28406 sgd_solver.cpp:112] Iteration 9800, lr = 0.0001
I0630 23:33:58.830742 28406 solver.cpp:347] Iteration 9900, Testing net (#0)
I0630 23:34:17.281036 28406 solver.cpp:414]     Test net output #0: acc = 0.960625
I0630 23:34:17.281076 28406 solver.cpp:414]     Test net output #1: loss = 0.171115 (* 1 = 0.171115 loss)
I0630 23:34:19.548949 28406 solver.cpp:239] Iteration 9900 (0.408812 iter/s, 244.611s/100 iters), loss = 0.0011051
I0630 23:34:19.548985 28406 solver.cpp:258]     Train net output #0: acc = 1
I0630 23:34:19.549005 28406 solver.cpp:258]     Train net output #1: loss = 0.00110504 (* 1 = 0.00110504 loss)
I0630 23:34:19.549012 28406 sgd_solver.cpp:112] Iteration 9900, lr = 0.0001
I0630 23:38:03.552393 28406 solver.cpp:464] Snapshotting to binary proto file models/mobilenet_finetune_iter_10000.caffemodel
I0630 23:38:03.579250 28406 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/mobilenet_finetune_iter_10000.solverstate
I0630 23:38:04.333885 28406 solver.cpp:327] Iteration 10000, loss = 0.000369329
I0630 23:38:04.333914 28406 solver.cpp:347] Iteration 10000, Testing net (#0)
I0630 23:38:22.726600 28406 solver.cpp:414]     Test net output #0: acc = 0.955
I0630 23:38:22.726639 28406 solver.cpp:414]     Test net output #1: loss = 0.195052 (* 1 = 0.195052 loss)
I0630 23:38:22.726645 28406 solver.cpp:332] Optimization Done.
I0630 23:38:22.726649 28406 caffe.cpp:250] Optimization Done.
